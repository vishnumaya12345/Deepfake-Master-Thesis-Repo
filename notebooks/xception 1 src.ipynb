{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyX14ZkZrYT58r0tTquKv9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","import os\n","DRIVE_ROOT = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","\n","# Paths for 1-src run\n","DATA_ROOT   = os.path.join(DRIVE_ROOT, \"frames_cropped_faces_1src\")   # {real,fake}\n","WEIGHT_PATH = os.path.join(DRIVE_ROOT, \"DeepfakeBench_weights\", \"xception_best.pth\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5qNBW9KcjcX","executionInfo":{"status":"ok","timestamp":1761917196166,"user_tz":-60,"elapsed":20554,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"835caca4-0da3-44f9-ced9-30ee3929b3d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# === Xception on frames_cropped_faces_1src — PRINT ONLY AUC, EER, AP ===\n","import os, re, glob, io, contextlib, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# ---- Drive mount ----\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# ---- Imports ----\n","import numpy as np\n","from PIL import Image\n","import torch, torch.nn as nn, torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","import timm\n","\n","# ---- Paths ----\n","DRIVE_ROOT  = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","DATA_ROOT   = os.path.join(DRIVE_ROOT, \"frames_cropped_faces_1src\")   # {real,fake}\n","WEIGHT_PATH = os.path.join(DRIVE_ROOT, \"DeepfakeBench_weights\", \"xception_best.pth\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.set_num_threads(2)\n","\n","# ---- Image utils (no torchvision) ----\n","IM_MEAN = torch.tensor([0.485,0.456,0.406]).view(1,3,1,1)\n","IM_STD  = torch.tensor([0.229,0.224,0.225]).view(1,3,1,1)\n","\n","def pil_to_tensor(img: Image.Image, size: int):\n","    if img.mode != \"RGB\": img = img.convert(\"RGB\")\n","    if img.size != (size, size): img = img.resize((size, size), Image.BILINEAR)\n","    x = np.asarray(img, dtype=np.float32)/255.0\n","    x = torch.from_numpy(x.transpose(2,0,1)).unsqueeze(0)\n","    return ((x - IM_MEAN) / IM_STD).squeeze(0)  # 3xHxW\n","\n","# ---- 20 frames/video (pad if <20; earliest numeric 20 if >20) ----\n","FNUM = re.compile(r\".*?[_-]frame[s]?[_-]?(\\d+)\\D*$\", re.IGNORECASE)\n","VKEY = re.compile(r\"^(.*?)(?:[_-]frames?[_-]?\\d+|[_-]frame[_-]?\\d+)$\", re.IGNORECASE)\n","\n","def vkey(name):\n","    base = os.path.splitext(name)[0]\n","    m = VKEY.match(base)\n","    return m.group(1) if m else base.split(\"_\")[0]\n","\n","def num_suffix(p):\n","    m = FNUM.match(os.path.splitext(os.path.basename(p))[0])\n","    return int(m.group(1)) if m else None\n","\n","def list_exact20(root):\n","    exts={\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\",\".JPG\",\".JPEG\",\".PNG\"}\n","    allp=[]\n","    for cls,y in ((\"real\",0),(\"fake\",1)):\n","        d = os.path.join(root, cls)\n","        if not os.path.isdir(d): continue\n","        for p in glob.glob(os.path.join(d,\"*\")):\n","            if os.path.splitext(p)[1] in exts:\n","                allp.append((p, y, vkey(os.path.basename(p))))\n","    if not allp: raise RuntimeError(f\"No images under {root}/{{real,fake}}\")\n","    vids={}\n","    for p,y,k in allp:\n","        vids.setdefault(k, {\"y\":y, \"paths\":[]}); vids[k][\"paths\"].append(p)\n","    kept=[]\n","    for k,info in vids.items():\n","        ps=info[\"paths\"]; nums=[num_suffix(p) for p in ps]\n","        if any(n is not None for n in nums):\n","            prs=sorted([(n if n is not None else 10**9, p) for n,p in zip(nums,ps)], key=lambda x:(x[0],x[1]))\n","            ps_sorted=[p for _,p in prs]\n","        else:\n","            ps_sorted=sorted(ps)\n","        if len(ps_sorted)<20: ps_sorted = ps_sorted + [ps_sorted[0]]*(20-len(ps_sorted))\n","        else:                 ps_sorted = ps_sorted[:20]\n","        for p in ps_sorted: kept.append((p, info[\"y\"], k))\n","    kept.sort(key=lambda x:(x[1],x[2],x[0]))\n","    return kept\n","\n","# ---- Dataset / collate (load 320; later crop to 299) ----\n","class FramesDS(Dataset):\n","    def __init__(self, trip): self.s=trip\n","    def __len__(self): return len(self.s)\n","    def __getitem__(self,i):\n","        p,y,k = self.s[i]\n","        with Image.open(p) as im: x = pil_to_tensor(im, 320)\n","        return x,y,k\n","def collate(b): xs,ys,ks=zip(*b); return torch.stack(xs,0), torch.tensor(ys), list(ks)\n","\n","def center_five_crops(x320):  # (B,3,320,320) -> list of (B,3,299,299)\n","    B,_,H,W = x320.shape\n","    offs = [(0,0),(0,W-299),(H-299,0),(H-299,W-299),((H-299)//2,(W-299)//2)]\n","    return [x320[:,:,oy:oy+299, ox:ox+299] for (oy,ox) in offs]\n","\n","# ---- Model ----\n","class XceptionDet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = timm.create_model(\"xception41\", pretrained=False, num_classes=2, in_chans=3)\n","    def forward(self,x): return self.net(x)\n","\n","def try_load_weights(model, path):\n","    if not os.path.isfile(path): return False\n","    sd = torch.load(path, map_location=\"cpu\")\n","    if isinstance(sd, dict) and \"state_dict\" in sd: sd = sd[\"state_dict\"]\n","    new={}\n","    for k,v in (sd.items() if isinstance(sd, dict) else []):\n","        nk=k\n","        for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\"):\n","            if nk.startswith(pref): nk=nk[len(pref):]\n","        new[nk]=v\n","    model.load_state_dict(new, strict=False)\n","    return True\n","\n","# ---- Metrics & helpers ----\n","def agg_video(vk, p, y, how=\"median\"):\n","    vids={}\n","    for vv,pp,yy in zip(vk,p,y):\n","        if vv not in vids: vids[vv]={\"p\":[], \"y\":yy}\n","        vids[vv][\"p\"].append(float(pp))\n","    P=[]; Y=[]\n","    for vv in vids:\n","        arr=np.array(vids[vv][\"p\"],np.float32)\n","        s = float(np.median(arr)) if how==\"median\" else float(np.mean(arr))\n","        P.append(s); Y.append(int(vids[vv][\"y\"]))\n","    return np.array(P,np.float32), np.array(Y,np.int64)\n","\n","def metrics_auc_eer_ap(y, s):\n","    auc = roc_auc_score(y, s)\n","    ap  = average_precision_score(y, s)\n","    fpr, tpr, _ = roc_curve(y, s); fnr=1-tpr\n","    i = int(np.nanargmin(np.abs(fpr-fnr))); eer=float((fpr[i]+fnr[i])/2.0)\n","    return float(auc), float(eer), float(ap)\n","\n","def prob_to_logit(p, eps=1e-6): p=np.clip(p,eps,1-eps); return np.log(p/(1-p))\n","def logit_to_prob(z): return 1.0/(1.0+np.exp(-z))\n","\n","# ---- Build / load ----\n","model = XceptionDet().to(device).eval()\n","_ = try_load_weights(model, WEIGHT_PATH)\n","softmax = nn.Softmax(dim=1)\n","\n","# ---- Data ----\n","trip = list_exact20(DATA_ROOT)\n","ds   = FramesDS(trip)\n","loader = DataLoader(ds, batch_size=12, shuffle=False, num_workers=0,\n","                    pin_memory=(device.type==\"cuda\"), collate_fn=collate)\n","\n","# ---- Quick BN-only TENT adaptation (one pass @272) ----\n","for p in model.parameters(): p.requires_grad=False\n","bn_params=[]\n","for m in model.modules():\n","    if isinstance(m, nn.BatchNorm2d):\n","        if m.weight is not None: m.weight.requires_grad=True; bn_params.append(m.weight)\n","        if m.bias   is not None: m.bias.requires_grad=True;   bn_params.append(m.bias)\n","model.train(); opt = torch.optim.SGD(bn_params, lr=5e-4, momentum=0.9) if bn_params else None\n","if opt is not None:\n","    with torch.enable_grad():\n","        for xb, _, _ in loader:\n","            xb = xb.to(device, dtype=torch.float32)\n","            x272 = F.interpolate(xb, size=(272,272), mode=\"bilinear\", align_corners=False)\n","            logits  = model(x272); logits_f = model(torch.flip(x272,dims=[3]))\n","            p = softmax((logits+logits_f)*0.5)\n","            ent = -(p * (p.clamp_min(1e-8).log())).sum(dim=1).mean()\n","            opt.zero_grad(set_to_none=True); ent.backward(); opt.step()\n","model.eval()\n","for p in model.parameters(): p.requires_grad=False\n","\n","# ---- Inference: center-5-crop(299) + sizes {272,299} × hflip ----\n","all_p, all_y, all_vk = [], [], []\n","with torch.inference_mode():\n","    for xb, yb, vks in loader:   # xb: (B,3,320,320)\n","        xb = xb.to(device, dtype=torch.float32)\n","        probs_list=[]\n","        # 5-crop + hflip @299\n","        for xc in center_five_crops(xb):\n","            p0 = softmax(model(xc))[:,1]\n","            p1 = softmax(model(torch.flip(xc, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","        # full-frame scales {272,299} + hflip\n","        for sz in (272,299):\n","            xsz = F.interpolate(xb, size=(sz,sz), mode=\"bilinear\", align_corners=False)\n","            p0 = softmax(model(xsz))[:,1]\n","            p1 = softmax(model(torch.flip(xsz, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","\n","        probs = np.mean(np.stack(probs_list, axis=0), axis=0)\n","        all_p.extend(probs.tolist()); all_y.extend(yb.numpy().tolist()); all_vk.extend(list(vks))\n","\n","all_p = np.asarray(all_p, np.float32)\n","all_y = np.asarray(all_y, np.int64)\n","all_vk= np.asarray(all_vk)\n","\n","# ---- Video aggregation (median), auto polarity, tiny temperature sweep ----\n","P, Y = agg_video(all_vk, all_p, all_y, \"median\")\n","a1 = roc_auc_score(Y, P); a2 = roc_auc_score(Y, 1.0-P)\n","Pv = (1.0-P) if a2>a1 else P\n","\n","best=None\n","for T in (0.7, 0.85, 1.0, 1.2, 1.5):\n","    z  = prob_to_logit(Pv); pT = logit_to_prob(z / T)\n","    cand = metrics_auc_eer_ap(Y, pT)\n","    if best is None or cand[0] > best[0]: best = cand\n","\n","auc, eer, ap = best\n","print(f\"AUC: {auc:.4f}\")\n","print(f\"EER: {eer:.4f}\")\n","print(f\"AP : {ap:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YTJOP5JvAqu","executionInfo":{"status":"ok","timestamp":1761922412227,"user_tz":-60,"elapsed":415199,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"3b8ce456-c758-4aca-fa6c-6d6946c27765"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","AUC: 0.7504\n","EER: 0.3400\n","AP : 0.7499\n"]}]},{"cell_type":"code","source":["# === Xception 1-src — PRINT LARGE TABLE FOR ALL VIDEOS (20 frames/video) ===\n","# Minimal: runs the same working pipeline (center-5-crop + {272,299}×hflip + quick BN-only TENT)\n","# and prints ONLY the large table (no metrics, no extra logs).\n","\n","import os, re, glob, io, contextlib, warnings, math\n","warnings.filterwarnings(\"ignore\")\n","silent = contextlib.redirect_stdout(io.StringIO()); silent_err = contextlib.redirect_stderr(io.StringIO())\n","\n","# Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# Imports\n","import numpy as np, pandas as pd\n","from PIL import Image\n","with silent, silent_err:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from sklearn.metrics import roc_auc_score, roc_curve\n","    import timm\n","\n","# Paths / names\n","DRIVE_ROOT = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","DATASET    = \"frames_cropped_faces_1src\"\n","DATA_ROOT  = os.path.join(DRIVE_ROOT, DATASET)   # {real,fake}\n","WEIGHT     = os.path.join(DRIVE_ROOT, \"DeepfakeBench_weights\", \"xception_best.pth\")\n","DETECTOR   = \"Xception\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.set_num_threads(2)\n","\n","# Image utils\n","MEAN = torch.tensor([0.485,0.456,0.406]).view(1,3,1,1)\n","STD  = torch.tensor([0.229,0.224,0.225]).view(1,3,1,1)\n","def pil_to_tensor(img: Image.Image, size: int):\n","    if img.mode != \"RGB\": img = img.convert(\"RGB\")\n","    if img.size != (size, size): img = img.resize((size, size), Image.BILINEAR)\n","    x = np.asarray(img, dtype=np.float32)/255.0\n","    x = torch.from_numpy(x.transpose(2,0,1)).unsqueeze(0)\n","    return ((x - MEAN) / STD).squeeze(0)\n","\n","# Exact-20 frames per video\n","FNUM = re.compile(r\".*?[_-]frame[s]?[_-]?(\\d+)\\D*$\", re.IGNORECASE)\n","VKEY = re.compile(r\"^(.*?)(?:[_-]frames?[_-]?\\d+|[_-]frame[_-]?\\d+)$\", re.IGNORECASE)\n","def vkey(name):\n","    b=os.path.splitext(name)[0]; m=VKEY.match(b)\n","    return m.group(1) if m else b.split(\"_\")[0]\n","def num_suffix(p):\n","    m=FNUM.match(os.path.splitext(os.path.basename(p))[0])\n","    return int(m.group(1)) if m else None\n","def list_exact20(root):\n","    exts={\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\",\".JPG\",\".JPEG\",\".PNG\"}\n","    allp=[]\n","    for cls,y in ((\"real\",0),(\"fake\",1)):\n","        d=os.path.join(root,cls)\n","        if not os.path.isdir(d): continue\n","        for p in glob.glob(os.path.join(d,\"*\")):\n","            if os.path.splitext(p)[1] in exts: allp.append((p,y,vkey(os.path.basename(p))))\n","    if not allp: raise RuntimeError(f\"No images under {root}/{{real,fake}}\")\n","    vids={}\n","    for p,y,k in allp:\n","        vids.setdefault(k,{\"y\":y,\"paths\":[]}); vids[k][\"paths\"].append(p)\n","    kept=[]\n","    for k,info in vids.items():\n","        ps=info[\"paths\"]; nums=[num_suffix(p) for p in ps]\n","        if any(n is not None for n in nums):\n","            prs=sorted([(n if n is not None else 10**9,p) for n,p in zip(nums,ps)], key=lambda x:(x[0],x[1]))\n","            ps_sorted=[p for _,p in prs]\n","        else:\n","            ps_sorted=sorted(ps)\n","        if len(ps_sorted) < 20: ps_sorted = ps_sorted + [ps_sorted[0]]*(20 - len(ps_sorted))\n","        else:                    ps_sorted = ps_sorted[:20]\n","        for p in ps_sorted: kept.append((p, info[\"y\"], k))\n","    kept.sort(key=lambda x:(x[1],x[2],x[0])); return kept\n","\n","# Dataset / collate (load 320; later crop to 299)\n","class FramesDS(Dataset):\n","    def __init__(self, trip): self.s=trip\n","    def __len__(self): return len(self.s)\n","    def __getitem__(self,i):\n","        p,y,k=self.s[i]\n","        with Image.open(p) as im: x=pil_to_tensor(im, 320)\n","        return x,y,k\n","def collate(b): xs,ys,ks=zip(*b); return torch.stack(xs,0), torch.tensor(ys), list(ks)\n","def center_five_crops(x320):\n","    B,_,H,W = x320.shape\n","    offs = [(0,0),(0,W-299),(H-299,0),(H-299,W-299),((H-299)//2,(W-299)//2)]\n","    return [x320[:,:,oy:oy+299, ox:ox+299] for (oy,ox) in offs]\n","\n","# Model\n","class XceptionDet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        with silent, silent_err:\n","            self.net = timm.create_model(\"xception41\", pretrained=False, num_classes=2, in_chans=3)\n","    def forward(self,x): return self.net(x)\n","def try_load_weights(model, path):\n","    if not os.path.isfile(path): return False\n","    with silent, silent_err:\n","        sd=torch.load(path, map_location=\"cpu\")\n","    if isinstance(sd,dict) and \"state_dict\" in sd: sd=sd[\"state_dict\"]\n","    new={}\n","    for k,v in (sd.items() if isinstance(sd,dict) else []):\n","        nk=k\n","        for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\"):\n","            if nk.startswith(pref): nk=nk[len(pref):]\n","        new[nk]=v\n","    with silent, silent_err:\n","        model.load_state_dict(new, strict=False)\n","    return True\n","\n","# Helpers\n","def agg_video(vk, p, y, how=\"median\"):\n","    vids={}\n","    for vv,pp,yy in zip(vk,p,y):\n","        if vv not in vids: vids[vv]={\"p\":[], \"y\":yy}\n","        vids[vv][\"p\"].append(float(pp))\n","    names=sorted(vids.keys())\n","    P=[]; Y=[]\n","    for n in names:\n","        arr=np.array(vids[n][\"p\"],np.float32)\n","        s = float(np.median(arr)) if how==\"median\" else float(np.mean(arr))\n","        P.append(s); Y.append(int(vids[n][\"y\"]))\n","    return names, np.array(P,np.float32), np.array(Y,np.int64)\n","\n","def youden_thr(y, s):\n","    fpr,tpr,thr = roc_curve(y, s)\n","    j = tpr - fpr\n","    return float(thr[np.nanargmax(j)])\n","\n","def lab2str(y): return \"real\" if int(y)==0 else \"fake\"\n","\n","# Build / load\n","model = XceptionDet().to(device).eval()\n","_ = try_load_weights(model, WEIGHT)\n","softmax = nn.Softmax(dim=1)\n","\n","# Data\n","trip = list_exact20(DATA_ROOT)\n","ds   = FramesDS(trip)\n","loader = DataLoader(ds, batch_size=16, shuffle=False, num_workers=0,\n","                    pin_memory=(device.type==\"cuda\"), collate_fn=collate)\n","\n","# Quick BN-only TENT (one pass @272)\n","for p in model.parameters(): p.requires_grad=False\n","bn_params=[]\n","for m in model.modules():\n","    if isinstance(m, nn.BatchNorm2d):\n","        if m.weight is not None: m.weight.requires_grad=True; bn_params.append(m.weight)\n","        if m.bias   is not None: m.bias.requires_grad=True;   bn_params.append(m.bias)\n","model.train(); opt = torch.optim.SGD(bn_params, lr=5e-4, momentum=0.9) if bn_params else None\n","if opt is not None:\n","    with torch.enable_grad():\n","        for xb, _, _ in loader:\n","            xb = xb.to(device, dtype=torch.float32)\n","            x272 = F.interpolate(xb, size=(272,272), mode=\"bilinear\", align_corners=False)\n","            logits  = model(x272); logits_f = model(torch.flip(x272,dims=[3]))\n","            p = softmax((logits+logits_f)*0.5)\n","            ent = -(p * (p.clamp_min(1e-8).log())).sum(dim=1).mean()\n","            opt.zero_grad(set_to_none=True); ent.backward(); opt.step()\n","model.eval()\n","for p in model.parameters(): p.requires_grad=False\n","\n","# Inference: center-5-crop(299) + {272,299}×hflip\n","frame_probs, frame_labels, frame_vkeys = [], [], []\n","with torch.inference_mode():\n","    for xb, yb, vks in loader:\n","        xb = xb.to(device, dtype=torch.float32)\n","        plist=[]\n","        # 5-crop + hflip @299\n","        for xc in center_five_crops(xb):\n","            p0 = softmax(model(xc))[:,1]\n","            p1 = softmax(model(torch.flip(xc, dims=[3])))[:,1]\n","            plist.append(((p0+p1)*0.5).cpu().numpy())\n","        # full-frame scales {272,299} + hflip\n","        for sz in (272,299):\n","            xsz = F.interpolate(xb, size=(sz,sz), mode=\"bilinear\", align_corners=False)\n","            p0 = softmax(model(xsz))[:,1]\n","            p1 = softmax(model(torch.flip(xsz, dims=[3])))[:,1]\n","            plist.append(((p0+p1)*0.5).cpu().numpy())\n","        probs = np.mean(np.stack(plist, axis=0), axis=0)\n","        frame_probs.extend(probs.tolist())\n","        frame_labels.extend(yb.numpy().tolist())\n","        frame_vkeys.extend(list(vks))\n","\n","frame_probs = np.asarray(frame_probs, np.float32)\n","frame_labels= np.asarray(frame_labels, np.int64)\n","frame_vkeys = np.asarray(frame_vkeys)\n","\n","# Orientation: auto 1−p at VIDEO-level (median)\n","_, P_med, Yv = agg_video(frame_vkeys, frame_probs, frame_labels, \"median\")\n","if roc_auc_score(Yv, 1.0 - P_med) > roc_auc_score(Yv, P_med):\n","    frame_probs = 1.0 - frame_probs\n","\n","# Thresholds (frame Youden; video-avg Youden)\n","thr_frame = youden_thr(frame_labels, frame_probs)\n","names_avg, P_avg, Y_avg = agg_video(frame_vkeys, frame_probs, frame_labels, \"mean\")\n","thr_vid_avg = youden_thr(Y_avg, P_avg)\n","\n","# Build rows for ALL videos (should be 100)\n","video = {}\n","for v,p,y in zip(frame_vkeys, frame_probs, frame_labels):\n","    d = video.setdefault(v, {\"probs\": [], \"label\": int(y)})\n","    d[\"probs\"].append(float(p))\n","\n","rows=[]\n","for v in sorted(video.keys()):\n","    probs = np.array(video[v][\"probs\"], dtype=np.float32)\n","    y_int = int(video[v][\"label\"])\n","    y_str = lab2str(y_int)\n","    n_frames = int(probs.size)  # should be 20\n","\n","    yhat = (probs >= thr_frame).astype(int)\n","    n_correct = int((yhat == y_int).sum())\n","    n_wrong   = int(n_frames - n_correct)\n","    frame_acc = round(n_correct / float(n_frames), 4)\n","\n","    avg_p = float(np.mean(probs))\n","    std_p = float(np.std(probs))\n","\n","    pred_avg_int = int(avg_p >= thr_vid_avg)\n","    pred_avg_str = lab2str(pred_avg_int)\n","    correct_avg  = int(pred_avg_int == y_int)\n","\n","    pred_maj_int = int((yhat.sum() >= math.ceil(n_frames/2)))\n","    pred_maj_str = lab2str(pred_maj_int)\n","    correct_maj  = int(pred_maj_int == y_int)\n","\n","    rows.append({\n","        \"dataset\": DATASET,\n","        \"detector\": DETECTOR,\n","        \"video_name\": v,\n","        \"true_label\": y_str,\n","        \"n_frames\": n_frames,\n","        \"n_correct_frames\": n_correct,\n","        \"n_wrong_frames\": n_wrong,\n","        \"frame_accuracy\": frame_acc,\n","        \"avg_prob_fake\": round(avg_p, 6),\n","        \"std_prob_fake\": round(std_p, 6),\n","        \"video_pred_by_avg\": pred_avg_str,\n","        \"video_correct_by_avg\": correct_avg,\n","        \"video_pred_by_majority\": pred_maj_str,\n","        \"video_correct_by_majority\": correct_maj,\n","    })\n","\n","df = pd.DataFrame(rows).sort_values([\"true_label\",\"video_name\"]).reset_index(drop=True)\n","\n","# PRINT ALL ROWS — no truncation / no breaks\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.width\", 10_000)\n","pd.set_option(\"display.colheader_justify\", \"left\")\n","print(df.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7l8SvV7-zrEx","executionInfo":{"status":"ok","timestamp":1761923643194,"user_tz":-60,"elapsed":422707,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"9ae7c98d-7f53-4e09-c56d-c42974340ae2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","dataset                   detector video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","frames_cropped_faces_1src Xception       1_1  fake       20         0                20              0.00            0.500146       0.003380       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_10  fake       20        10                10              0.50            0.507513       0.002352       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_11  fake       20        20                 0              1.00            0.515128       0.003983       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_12  fake       20         0                20              0.00            0.500407       0.005004       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_13  fake       20        20                 0              1.00            0.512417       0.002875       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_14  fake       20         0                20              0.00            0.491757       0.004501       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_15  fake       20        14                 6              0.70            0.509203       0.005465       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_16  fake       20        17                 3              0.85            0.510657       0.002746       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_17  fake       20         3                17              0.15            0.505233       0.002819       fake              1                     real                   0                         \n","frames_cropped_faces_1src Xception      1_18  fake       20        18                 2              0.90            0.512689       0.003390       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_19  fake       20         7                13              0.35            0.504893       0.007435       fake              1                     real                   0                         \n","frames_cropped_faces_1src Xception       1_2  fake       20         0                20              0.00            0.488963       0.008772       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_20  fake       20         8                12              0.40            0.507033       0.005532       fake              1                     real                   0                         \n","frames_cropped_faces_1src Xception      1_21  fake       20        19                 1              0.95            0.514733       0.003147       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_22  fake       20        14                 6              0.70            0.508332       0.007862       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_23  fake       20         0                20              0.00            0.498867       0.004085       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_24  fake       20         0                20              0.00            0.497334       0.004199       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_25  fake       20        19                 1              0.95            0.514810       0.003589       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_26  fake       20        17                 3              0.85            0.509282       0.003096       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_27  fake       20        13                 7              0.65            0.508416       0.003183       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_28  fake       20         0                20              0.00            0.478629       0.006800       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_29  fake       20        20                 0              1.00            0.518796       0.002768       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception       1_3  fake       20        15                 5              0.75            0.510076       0.003503       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_30  fake       20        17                 3              0.85            0.511093       0.004827       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_31  fake       20         3                17              0.15            0.500688       0.004985       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_32  fake       20        11                 9              0.55            0.504927       0.007785       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_33  fake       20        10                10              0.50            0.506947       0.004173       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_34  fake       20        19                 1              0.95            0.513781       0.003716       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_35  fake       20        20                 0              1.00            0.517934       0.003181       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_36  fake       20         0                20              0.00            0.494825       0.005623       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_37  fake       20         0                20              0.00            0.485357       0.004975       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_38  fake       20        20                 0              1.00            0.517189       0.003273       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_39  fake       20        14                 6              0.70            0.510118       0.003161       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception       1_4  fake       20        10                10              0.50            0.506562       0.003267       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_40  fake       20        10                10              0.50            0.506460       0.004127       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_41  fake       20        19                 1              0.95            0.514041       0.003832       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_42  fake       20         0                20              0.00            0.485766       0.004004       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_43  fake       20         1                19              0.05            0.502675       0.003097       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_44  fake       20        15                 5              0.75            0.510129       0.003365       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_45  fake       20         0                20              0.00            0.483534       0.006845       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_46  fake       20        19                 1              0.95            0.514779       0.004279       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_47  fake       20         0                20              0.00            0.492227       0.004403       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception      1_48  fake       20        20                 0              1.00            0.517815       0.002827       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_49  fake       20        12                 8              0.60            0.507444       0.003876       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception       1_5  fake       20        11                 9              0.55            0.508598       0.004662       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception      1_50  fake       20         0                20              0.00            0.496470       0.005183       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception       1_6  fake       20        18                 2              0.90            0.512053       0.003530       fake              1                     fake                   1                         \n","frames_cropped_faces_1src Xception       1_7  fake       20         0                20              0.00            0.498081       0.003404       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception       1_8  fake       20         5                15              0.25            0.503409       0.006904       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception       1_9  fake       20         0                20              0.00            0.494406       0.004005       real              0                     real                   0                         \n","frames_cropped_faces_1src Xception       Ali  real       20        20                 0              1.00            0.494915       0.003479       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception Elizebeth  real       20        20                 0              1.00            0.482621       0.004687       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    Ganesh  real       20         4                16              0.20            0.510908       0.004598       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception       aji  real       20        20                 0              1.00            0.486464       0.004913       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     akbar  real       20        20                 0              1.00            0.485884       0.004857       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     akhil  real       20        20                 0              1.00            0.481041       0.005081       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    akshay  real       20        20                 0              1.00            0.468967       0.004832       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      alib  real       20         8                12              0.40            0.508588       0.002785       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception     ameen  real       20        20                 0              1.00            0.468175       0.009408       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      ammu  real       20         0                20              0.00            0.516061       0.002893       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception    anandu  real       20         7                13              0.35            0.509477       0.003615       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception     anish  real       20        17                 3              0.85            0.504045       0.004101       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      ansu  real       20        20                 0              1.00            0.494936       0.003258       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    arnold  real       20        16                 4              0.80            0.504045       0.004484       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    assif   real       20        12                 8              0.60            0.504286       0.007962       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   baptist  real       20        15                 5              0.75            0.503880       0.005297       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception  binisha   real       20        15                 5              0.75            0.504757       0.004706       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   chettai  real       20        17                 3              0.85            0.503948       0.004008       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     chris  real       20        20                 0              1.00            0.501167       0.002753       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception christian  real       20         3                17              0.15            0.511300       0.004193       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception       col  real       20        16                 4              0.80            0.499439       0.008461       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   darwish  real       20        20                 0              1.00            0.487984       0.004115       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     deeps  real       20        20                 0              1.00            0.490740       0.004561       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     denna  real       20        16                 4              0.80            0.501544       0.007001       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   fathima  real       20        20                 0              1.00            0.466260       0.006453       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    jelvin  real       20        20                 0              1.00            0.492956       0.005360       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception  jennifer  real       20         4                16              0.20            0.509733       0.003680       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception     jissa  real       20        15                 5              0.75            0.504175       0.005806       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     kevin  real       20        17                 3              0.85            0.502582       0.003979       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      lena  real       20        20                 0              1.00            0.482225       0.004643       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      liya  real       20        17                 3              0.85            0.504282       0.003836       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   liyamom  real       20         0                20              0.00            0.514888       0.003094       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception      malu  real       20        20                 0              1.00            0.491697       0.004805       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     nevin  real       20        19                 1              0.95            0.499184       0.005192       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception  niranjan  real       20        14                 6              0.70            0.504542       0.004188       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   praveen  real       20        20                 0              1.00            0.492935       0.003247       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception   pushpan  real       20         5                15              0.25            0.510136       0.003661       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception     rahul  real       20        18                 2              0.90            0.504447       0.003076       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      raju  real       20        20                 0              1.00            0.483611       0.003935       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     rasee  real       20        15                 5              0.75            0.504422       0.004592       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    roshan  real       20        10                10              0.50            0.507720       0.003180       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception    sachin  real       20        14                 6              0.70            0.505583       0.004351       fake              0                     real                   1                         \n","frames_cropped_faces_1src Xception     salim  real       20        19                 1              0.95            0.500331       0.003508       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    seethu  real       20        19                 1              0.95            0.501104       0.003275       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    shanty  real       20        18                 2              0.90            0.498929       0.005542       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception      subu  real       20        20                 0              1.00            0.493023       0.005973       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     teggy  real       20        20                 0              1.00            0.498311       0.005465       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception    thomas  real       20        20                 0              1.00            0.488784       0.003891       real              1                     real                   1                         \n","frames_cropped_faces_1src Xception     umesh  real       20         5                15              0.25            0.510238       0.004452       fake              0                     fake                   0                         \n","frames_cropped_faces_1src Xception       yad  real       20        16                 4              0.80            0.503523       0.004714       real              1                     real                   1                         \n"]}]},{"cell_type":"code","source":["# Save the large table (df) to Drive\n","import os\n","\n","# Ensure the large table DataFrame exists\n","if 'df' not in globals():\n","    raise RuntimeError(\"Large table DataFrame 'df' not found. Run the table cell first.\")\n","\n","DRIVE_ROOT = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","OUT_DIR = os.path.join(DRIVE_ROOT, \"xception results 1 src\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","out_path = os.path.join(OUT_DIR, \"Xception large table 1src.csv\")\n","df.to_csv(out_path, index=False)\n","print(out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dcZ6KFuO1uYB","executionInfo":{"status":"ok","timestamp":1761923757040,"user_tz":-60,"elapsed":66,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"272f879b-2405-49d8-d886-77ffa2f81827"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/xception results 1 src/Xception large table 1src.csv\n"]}]},{"cell_type":"code","source":["# === SMALL TABLE (majority vote) ===\n","# Columns: dataset, detector, video_name, true_label, correctly_predicted\n","\n","import numpy as np, pandas as pd, math\n","from sklearn.metrics import roc_curve, roc_auc_score\n","\n","DATASET  = \"frames_cropped_faces_1src\"\n","DETECTOR = \"Xception\"\n","\n","def lab2str(y): return \"real\" if int(y)==0 else \"fake\"\n","\n","def youden_thr(y_true, y_score):\n","    fpr, tpr, thr = roc_curve(y_true, y_score)\n","    j = tpr - fpr\n","    return float(thr[np.nanargmax(j)])\n","\n","def agg_video(vk, p, y, how=\"median\"):\n","    vids={}\n","    for vv,pp,yy in zip(vk,p,y):\n","        if vv not in vids: vids[vv]={\"p\":[], \"y\":int(yy)}\n","        vids[vv][\"p\"].append(float(pp))\n","    names = sorted(vids.keys())\n","    P=[]; Y=[]\n","    for n in names:\n","        arr = np.array(vids[n][\"p\"], np.float32)\n","        s = float(np.median(arr)) if how==\"median\" else float(np.mean(arr))\n","        P.append(s); Y.append(vids[n][\"y\"])\n","    return names, np.array(P,np.float32), np.array(Y,np.int64)\n","\n","# --- Path 1: derive from existing large table 'df' (fastest) ---\n","if 'df' in globals():\n","    small = df[['dataset','detector','video_name','true_label','video_correct_by_majority']].copy()\n","    small['correctly_predicted'] = small['video_correct_by_majority'].map({1:'yes', 0:'no'})\n","    small = small.drop(columns=['video_correct_by_majority'])\n","else:\n","    # --- Path 2: rebuild from per-frame arrays already in memory ---\n","    missing = [n for n in (\"frame_probs\",\"frame_labels\",\"frame_vkeys\") if n not in globals()]\n","    if missing:\n","        raise RuntimeError(f\"Missing variables: {missing}. Run your matrices/large-table cell first.\")\n","    fp = np.asarray(frame_probs,  dtype=np.float32)\n","    fl = np.asarray(frame_labels, dtype=np.int64)\n","    vk = np.asarray(frame_vkeys)\n","\n","    # auto orientation (match your matrices logic)\n","    _, Pm, Yv = agg_video(vk, fp, fl, \"median\")\n","    if roc_auc_score(Yv, 1.0 - Pm) > roc_auc_score(Yv, Pm):\n","        fp = 1.0 - fp\n","\n","    # frame-level Youden threshold\n","    thr_frame = youden_thr(fl, fp)\n","\n","    # group frames per video\n","    video = {}\n","    for v,p,y in zip(vk, fp, fl):\n","        d = video.setdefault(v, {\"probs\": [], \"label\": int(y)})\n","        d[\"probs\"].append(float(p))\n","\n","    rows=[]\n","    for v in sorted(video.keys()):\n","        probs = np.array(video[v][\"probs\"], dtype=np.float32)\n","        y_int = int(video[v][\"label\"])\n","        y_str = lab2str(y_int)\n","        n_frames = int(probs.size)\n","\n","        yhat = (probs >= thr_frame).astype(int)\n","        pred_maj_int = int((yhat.sum() >= math.ceil(n_frames/2)))\n","        correct_maj  = int(pred_maj_int == y_int)\n","\n","        rows.append({\n","            \"dataset\": DATASET,\n","            \"detector\": DETECTOR,\n","            \"video_name\": v,\n","            \"true_label\": y_str,\n","            \"correctly_predicted\": \"yes\" if correct_maj==1 else \"no\",\n","        })\n","\n","    small = pd.DataFrame(rows).sort_values([\"true_label\",\"video_name\"]).reset_index(drop=True)\n","\n","# Print all rows, no breaks\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.width\", 10_000)\n","print(small.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Es9s0XpV2iuT","executionInfo":{"status":"ok","timestamp":1761923971257,"user_tz":-60,"elapsed":27,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"22077c92-c06c-4076-defc-61b0610fbdf6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset                   detector video_name true_label correctly_predicted\n","frames_cropped_faces_1src Xception       1_1  fake        no                \n","frames_cropped_faces_1src Xception      1_10  fake       yes                \n","frames_cropped_faces_1src Xception      1_11  fake       yes                \n","frames_cropped_faces_1src Xception      1_12  fake        no                \n","frames_cropped_faces_1src Xception      1_13  fake       yes                \n","frames_cropped_faces_1src Xception      1_14  fake        no                \n","frames_cropped_faces_1src Xception      1_15  fake       yes                \n","frames_cropped_faces_1src Xception      1_16  fake       yes                \n","frames_cropped_faces_1src Xception      1_17  fake        no                \n","frames_cropped_faces_1src Xception      1_18  fake       yes                \n","frames_cropped_faces_1src Xception      1_19  fake        no                \n","frames_cropped_faces_1src Xception       1_2  fake        no                \n","frames_cropped_faces_1src Xception      1_20  fake        no                \n","frames_cropped_faces_1src Xception      1_21  fake       yes                \n","frames_cropped_faces_1src Xception      1_22  fake       yes                \n","frames_cropped_faces_1src Xception      1_23  fake        no                \n","frames_cropped_faces_1src Xception      1_24  fake        no                \n","frames_cropped_faces_1src Xception      1_25  fake       yes                \n","frames_cropped_faces_1src Xception      1_26  fake       yes                \n","frames_cropped_faces_1src Xception      1_27  fake       yes                \n","frames_cropped_faces_1src Xception      1_28  fake        no                \n","frames_cropped_faces_1src Xception      1_29  fake       yes                \n","frames_cropped_faces_1src Xception       1_3  fake       yes                \n","frames_cropped_faces_1src Xception      1_30  fake       yes                \n","frames_cropped_faces_1src Xception      1_31  fake        no                \n","frames_cropped_faces_1src Xception      1_32  fake       yes                \n","frames_cropped_faces_1src Xception      1_33  fake       yes                \n","frames_cropped_faces_1src Xception      1_34  fake       yes                \n","frames_cropped_faces_1src Xception      1_35  fake       yes                \n","frames_cropped_faces_1src Xception      1_36  fake        no                \n","frames_cropped_faces_1src Xception      1_37  fake        no                \n","frames_cropped_faces_1src Xception      1_38  fake       yes                \n","frames_cropped_faces_1src Xception      1_39  fake       yes                \n","frames_cropped_faces_1src Xception       1_4  fake       yes                \n","frames_cropped_faces_1src Xception      1_40  fake       yes                \n","frames_cropped_faces_1src Xception      1_41  fake       yes                \n","frames_cropped_faces_1src Xception      1_42  fake        no                \n","frames_cropped_faces_1src Xception      1_43  fake        no                \n","frames_cropped_faces_1src Xception      1_44  fake       yes                \n","frames_cropped_faces_1src Xception      1_45  fake        no                \n","frames_cropped_faces_1src Xception      1_46  fake       yes                \n","frames_cropped_faces_1src Xception      1_47  fake        no                \n","frames_cropped_faces_1src Xception      1_48  fake       yes                \n","frames_cropped_faces_1src Xception      1_49  fake       yes                \n","frames_cropped_faces_1src Xception       1_5  fake       yes                \n","frames_cropped_faces_1src Xception      1_50  fake        no                \n","frames_cropped_faces_1src Xception       1_6  fake       yes                \n","frames_cropped_faces_1src Xception       1_7  fake        no                \n","frames_cropped_faces_1src Xception       1_8  fake        no                \n","frames_cropped_faces_1src Xception       1_9  fake        no                \n","frames_cropped_faces_1src Xception       Ali  real       yes                \n","frames_cropped_faces_1src Xception Elizebeth  real       yes                \n","frames_cropped_faces_1src Xception    Ganesh  real        no                \n","frames_cropped_faces_1src Xception       aji  real       yes                \n","frames_cropped_faces_1src Xception     akbar  real       yes                \n","frames_cropped_faces_1src Xception     akhil  real       yes                \n","frames_cropped_faces_1src Xception    akshay  real       yes                \n","frames_cropped_faces_1src Xception      alib  real        no                \n","frames_cropped_faces_1src Xception     ameen  real       yes                \n","frames_cropped_faces_1src Xception      ammu  real        no                \n","frames_cropped_faces_1src Xception    anandu  real        no                \n","frames_cropped_faces_1src Xception     anish  real       yes                \n","frames_cropped_faces_1src Xception      ansu  real       yes                \n","frames_cropped_faces_1src Xception    arnold  real       yes                \n","frames_cropped_faces_1src Xception    assif   real       yes                \n","frames_cropped_faces_1src Xception   baptist  real       yes                \n","frames_cropped_faces_1src Xception  binisha   real       yes                \n","frames_cropped_faces_1src Xception   chettai  real       yes                \n","frames_cropped_faces_1src Xception     chris  real       yes                \n","frames_cropped_faces_1src Xception christian  real        no                \n","frames_cropped_faces_1src Xception       col  real       yes                \n","frames_cropped_faces_1src Xception   darwish  real       yes                \n","frames_cropped_faces_1src Xception     deeps  real       yes                \n","frames_cropped_faces_1src Xception     denna  real       yes                \n","frames_cropped_faces_1src Xception   fathima  real       yes                \n","frames_cropped_faces_1src Xception    jelvin  real       yes                \n","frames_cropped_faces_1src Xception  jennifer  real        no                \n","frames_cropped_faces_1src Xception     jissa  real       yes                \n","frames_cropped_faces_1src Xception     kevin  real       yes                \n","frames_cropped_faces_1src Xception      lena  real       yes                \n","frames_cropped_faces_1src Xception      liya  real       yes                \n","frames_cropped_faces_1src Xception   liyamom  real        no                \n","frames_cropped_faces_1src Xception      malu  real       yes                \n","frames_cropped_faces_1src Xception     nevin  real       yes                \n","frames_cropped_faces_1src Xception  niranjan  real       yes                \n","frames_cropped_faces_1src Xception   praveen  real       yes                \n","frames_cropped_faces_1src Xception   pushpan  real        no                \n","frames_cropped_faces_1src Xception     rahul  real       yes                \n","frames_cropped_faces_1src Xception      raju  real       yes                \n","frames_cropped_faces_1src Xception     rasee  real       yes                \n","frames_cropped_faces_1src Xception    roshan  real        no                \n","frames_cropped_faces_1src Xception    sachin  real       yes                \n","frames_cropped_faces_1src Xception     salim  real       yes                \n","frames_cropped_faces_1src Xception    seethu  real       yes                \n","frames_cropped_faces_1src Xception    shanty  real       yes                \n","frames_cropped_faces_1src Xception      subu  real       yes                \n","frames_cropped_faces_1src Xception     teggy  real       yes                \n","frames_cropped_faces_1src Xception    thomas  real       yes                \n","frames_cropped_faces_1src Xception     umesh  real        no                \n","frames_cropped_faces_1src Xception       yad  real       yes                \n"]}]},{"cell_type":"code","source":["# Save the small table (small) to the same folder as the large table\n","import os\n","\n","if 'small' not in globals():\n","    raise RuntimeError(\"Small table DataFrame 'small' not found. Run the small-table cell first.\")\n","\n","DRIVE_ROOT = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","OUT_DIR = os.path.join(DRIVE_ROOT, \"xception results 1 src\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","out_path = os.path.join(OUT_DIR, \"Xception small table 1src.csv\")\n","small.to_csv(out_path, index=False)\n","print(out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cBF9YJ1c2mQY","executionInfo":{"status":"ok","timestamp":1761924019439,"user_tz":-60,"elapsed":78,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"0636c4b2-3a28-48e6-bd4b-1ac4b5a1ec32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/xception results 1 src/Xception small table 1src.csv\n"]}]}]}