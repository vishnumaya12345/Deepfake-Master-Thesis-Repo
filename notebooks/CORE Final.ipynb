{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmXSngMkvVGnYETNSbBnPs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# =========================\n","# CORE (Xception) — FACE-ALIGNED ENSEMBLE + QUALITY FILTERS\n","# Target: push AUC ≥ 0.70 and lower EER, GPU-friendly.\n","# Prints ONLY:\n","#   CORE model loaded\n","#   AUC=… | EER=… | AP=…\n","# =========================\n","\n","# Quiet installs (no extra prints)\n","import sys, subprocess, os, warnings\n","subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                \"timm\", \"torchvision\", \"scikit-learn\", \"pillow\",\n","                \"facenet-pytorch\", \"opencv-python\"],\n","               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n","\n","# Avoid remount message; mount only if needed\n","if not os.path.ismount(\"/content/drive\"):\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","import math, random\n","from pathlib import Path\n","from collections import defaultdict\n","\n","import numpy as np\n","from PIL import Image\n","from sklearn import metrics\n","\n","import cv2\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","from torchvision import transforms\n","from facenet_pytorch import MTCNN\n","\n","# -------------------------\n","# Config\n","# -------------------------\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","DATA_REAL = f\"{DRIVE_ROOT}/balanced_frames_FF++/real\"\n","DATA_FAKE = f\"{DRIVE_ROOT}/balanced_frames_FF++/fake\"\n","WEIGHTS_PATH = f\"{DRIVE_ROOT}/DeepfakeBench_weights/core_best.pth\"\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","SEED = 42\n","\n","# Inference knobs (tuned for accuracy vs. GPU)\n","IMG_SIZE = 299\n","FRAME_CAP_PER_VIDEO = 160     # ↑ more frames per video for stronger statistics\n","BATCH_SIZE_IMAGES   = 8       # images processed before TTA expansion\n","FORWARD_CHUNK       = 32      # per-forward chunk to avoid OOM\n","\n","# TTA/Ensemble settings\n","SCALES_FACE   = [320, 352]    # for face-aligned crops\n","SCALES_FRAME  = [352]         # for global frame center-crop\n","USE_HFLIP     = True          # add a mirrored pass\n","WSET = [                      # ensemble weights (face, face+CLAHE, frame)\n","    (1.0, 0.0, 0.0),\n","    (0.8, 0.2, 0.0),\n","    (0.7, 0.2, 0.1),\n","    (0.6, 0.3, 0.1),\n","    (0.5, 0.3, 0.2),\n","    (0.45, 0.35, 0.20),\n","]\n","\n","# Aggregation/filters search space\n","TAU_LIST       = [0.0, 0.1, 0.2, 0.3, 0.4]   # drop frames with |p-0.5| < τ\n","SHARP_TOP_LIST = [1.0, 0.8, 0.6]             # keep top X fraction by sharpness\n","CONF_MIN_LIST  = [0.0, 0.85, 0.90]           # min face-detection confidence\n","SIZE_MIN_LIST  = [0.0, 0.03, 0.06]           # min face area ratio (bbox/img)\n","AGGREGATORS    = [\"median\", \"perc90\", \"top10\", \"trim10\", \"wtop20p\", \"perc95\"]\n","\n","# -------------------------\n","# Reproducibility\n","# -------------------------\n","def set_seed(seed=SEED):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","set_seed()\n","\n","# -------------------------\n","# Utilities (silent)\n","# -------------------------\n","VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n","\n","def list_images(folder):\n","    folder = Path(folder)\n","    return sorted([p for p in folder.iterdir() if p.suffix.lower() in VALID_EXTS])\n","\n","def guess_video_name_from_path(p: Path):\n","    stem = p.stem\n","    if \"_\" in stem:\n","        return stem.rsplit(\"_\", 1)[0]\n","    if \"-\" in stem:\n","        return stem.rsplit(\"-\", 1)[0]\n","    return stem\n","\n","def safe_open_rgb(path: Path):\n","    try:\n","        return Image.open(path).convert(\"RGB\")\n","    except Exception:\n","        return Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n","\n","def compute_eer(y_true, y_score):\n","    fpr, tpr, _ = metrics.roc_curve(y_true, y_score)\n","    fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fnr - fpr)))\n","    return float((fpr[idx] + fnr[idx]) / 2.0)\n","\n","def build_samples(real_dir, fake_dir, cap=FRAME_CAP_PER_VIDEO):\n","    samples = []  # (path, label, video)\n","    def gather(dir_path, label):\n","        paths = list_images(dir_path)\n","        groups = defaultdict(list)\n","        for p in paths:\n","            groups[guess_video_name_from_path(p)].append(p)\n","        for vname, plist in groups.items():\n","            plist = sorted(plist)\n","            if cap is not None and len(plist) > cap:\n","                idxs = np.linspace(0, len(plist)-1, num=cap, dtype=int)\n","                plist = [plist[i] for i in idxs]\n","            for p in plist:\n","                samples.append((str(p), label, vname))\n","    gather(real_dir, 0)\n","    gather(fake_dir, 1)\n","    return samples\n","\n","samples = build_samples(DATA_REAL, DATA_FAKE)\n","\n","# -------------------------\n","# Face detector & alignment (MTCNN)\n","# -------------------------\n","mtcnn = MTCNN(keep_all=True, device=DEVICE if torch.cuda.is_available() else \"cpu\",\n","              min_face_size=40, thresholds=[0.6, 0.7, 0.7])\n","\n","def align_face_with_meta(img: Image.Image, margin=0.25):\n","    \"\"\"\n","    Detect largest face; return aligned square crop + (conf, area_ratio).\n","    Fallback: center square crop, conf=0.0, area=0.0\n","    \"\"\"\n","    w, h = img.size\n","    boxes, probs, landmarks = mtcnn.detect(img, landmarks=True)\n","    if boxes is not None and len(boxes) > 0:\n","        areas = [(b[2]-b[0])*(b[3]-b[1]) for b in boxes]\n","        i = int(np.argmax(areas))\n","        b = boxes[i]\n","        conf = float(probs[i]) if probs is not None else 0.0\n","        # compute area ratio before alignment\n","        area_ratio = float(areas[i] / max(1.0, (w*h)))\n","\n","        # align by eyes if landmarks present\n","        pts = landmarks[i] if landmarks is not None else None\n","        if pts is not None:\n","            left_eye, right_eye = pts[0], pts[1]\n","            dx, dy = right_eye[0]-left_eye[0], right_eye[1]-left_eye[1]\n","            angle = np.degrees(np.arctan2(dy, dx))\n","            M = cv2.getRotationMatrix2D((w/2.0, h/2.0), angle, 1.0)\n","            img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n","            rot = cv2.warpAffine(img_cv, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)\n","            img = Image.fromarray(cv2.cvtColor(rot, cv2.COLOR_BGR2RGB))\n","            # rotate box corners then axis-align\n","            x1, y1, x2, y2 = b\n","            corners = np.array([[x1,y1,1],[x2,y1,1],[x1,y2,1],[x2,y2,1]], dtype=np.float32)\n","            rc = (M @ corners.T).T\n","            x1, y1 = rc[:,0].min(), rc[:,1].min()\n","            x2, y2 = rc[:,0].max(), rc[:,1].max()\n","            b = np.array([x1,y1,x2,y2], dtype=np.float32)\n","\n","        x1, y1, x2, y2 = b\n","        bw, bh = x2 - x1, y2 - y1\n","        cx, cy = x1 + bw/2.0, y1 + bh/2.0\n","        side = max(bw, bh) * (1.0 + margin)\n","        x1n = int(max(0, cx - side/2.0))\n","        y1n = int(max(0, cy - side/2.0))\n","        x2n = int(min(w, cx + side/2.0))\n","        y2n = int(min(h, cy + side/2.0))\n","        # ensure square\n","        box_w, box_h = x2n - x1n, y2n - y1n\n","        if box_w != box_h:\n","            d = abs(box_w - box_h)\n","            if box_w < box_h:\n","                x1n = max(0, x1n - d//2); x2n = min(w, x2n + (d - d//2))\n","            else:\n","                y1n = max(0, y1n - d//2); y2n = min(h, y2n + (d - d//2))\n","        crop = img.crop((x1n, y1n, x2n, y2n))\n","        return crop, conf, area_ratio\n","    # fallback\n","    side = min(w, h)\n","    left = (w - side) // 2\n","    top  = (h - side) // 2\n","    return img.crop((left, top, left + side, top + side)), 0.0, 0.0\n","\n","def sharpness_score(pil_img: Image.Image):\n","    g = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2GRAY)\n","    g = cv2.resize(g, (128, 128), interpolation=cv2.INTER_AREA)\n","    return float(cv2.Laplacian(g, cv2.CV_64F).var())\n","\n","def apply_clahe_color(pil_img: Image.Image):\n","    img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2LAB)\n","    l, a, b = cv2.split(img)\n","    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","    l2 = clahe.apply(l)\n","    lab = cv2.merge([l2, a, b])\n","    rgb = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n","    return Image.fromarray(rgb)\n","\n","# -------------------------\n","# TTA pipelines\n","# -------------------------\n","IMAGENET_MEAN, IMAGENET_STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n","to_tensor_norm = transforms.Compose([\n","    transforms.Resize(IMG_SIZE),\n","    transforms.CenterCrop(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","])\n","\n","def make_crops(pil_img, scales, hflip=USE_HFLIP):\n","    crops = []\n","    for s in scales:\n","        w, h = pil_img.size\n","        scale = s / min(w, h)\n","        new_size = (int(round(w*scale)), int(round(h*scale)))\n","        img_res = pil_img.resize(new_size, Image.BILINEAR)\n","        left = (img_res.size[0] - s) // 2\n","        top  = (img_res.size[1] - s) // 2\n","        cc = img_res.crop((left, top, left + s, top + s))\n","        crops.append(cc)\n","        if hflip:\n","            crops.append(cc.transpose(Image.FLIP_LEFT_RIGHT))\n","    return crops  # list of PIL images\n","\n","# -------------------------\n","# CORE (Xception) model\n","# -------------------------\n","class CoreXception(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        # no pretrained download\n","        self.model = timm.create_model(\"xception\", pretrained=False, num_classes=num_classes)\n","        assert hasattr(self.model, \"forward_features\")\n","\n","    def forward(self, x):\n","        feats = self.model.forward_features(x)                 # BxCxHxW\n","        core_feat = F.relu(feats, inplace=False)\n","        core_feat = F.adaptive_avg_pool2d(core_feat, (1, 1)).flatten(1)\n","        logits = self.model.forward_head(feats, pre_logits=False)\n","        probs = torch.softmax(logits, dim=1)[:, 1]\n","        return {\"logits\": logits, \"prob\": probs, \"feat_map\": feats, \"core_feat\": core_feat}\n","\n","def load_core_weights_strong(model: nn.Module, path: str):\n","    ckpt = torch.load(path, map_location=\"cpu\")\n","    incoming = ckpt[\"state_dict\"] if (isinstance(ckpt, dict) and \"state_dict\" in ckpt) else ckpt\n","    target = model.model.state_dict()\n","\n","    def candidates(k):\n","        keys = [k]\n","        for pref in [\"module.\", \"backbone.\", \"model.\"]:\n","            if k.startswith(pref):\n","                keys.append(k[len(pref):])\n","        if k.startswith(\"fc.\"):\n","            keys.append(\"classifier.\" + k[len(\"fc.\"):])\n","        return list(dict.fromkeys(keys))\n","\n","    new_state = {}\n","    for k, v in incoming.items():\n","        for k2 in candidates(k):\n","            if k2 in target:\n","                tv = target[k2]\n","                if v.shape == tv.shape:\n","                    new_state[k2] = v; break\n","                if v.ndim == 2 and tv.ndim == 4 and tv.shape[2] == 1 and tv.shape[3] == 1 \\\n","                   and v.shape[0] == tv.shape[0] and v.shape[1] == tv.shape[1]:\n","                    new_state[k2] = v.unsqueeze(-1).unsqueeze(-1); break\n","    model.model.load_state_dict(new_state, strict=False)\n","\n","core = CoreXception(num_classes=2).to(DEVICE)\n","try:\n","    load_core_weights_strong(core, WEIGHTS_PATH)\n","finally:\n","    print(\"CORE model loaded\")\n","core.eval()\n","\n","def forward_in_chunks(x, chunk=FORWARD_CHUNK):\n","    outs = []\n","    for i in range(0, x.size(0), chunk):\n","        outs.append(core(x[i:i+chunk].to(DEVICE))[\"prob\"].detach().float().cpu())\n","    return torch.cat(outs, dim=0).numpy()\n","\n","# -------------------------\n","# Inference — build per-frame ensemble inputs\n","# -------------------------\n","records = []  # list of dicts per image: {v,label,p1,p2,p3,sharp,conf,area}\n","with torch.no_grad():\n","    # batch by images to control memory (TTA handled inside loop)\n","    for i in range(0, len(samples), BATCH_SIZE_IMAGES):\n","        batch = samples[i:i + BATCH_SIZE_IMAGES]\n","\n","        # Prepare crops for three pipelines\n","        tens_face_list, face_meta = [], []     # (n_crops,3,299,299), (conf, area)\n","        tens_facec_list = []                   # CLAHE branch\n","        tens_frame_list = []                   # global center-crop branch\n","        labels, vnames = [], []\n","\n","        # Gather crops\n","        for path, lab, vname in batch:\n","            img = safe_open_rgb(Path(path))\n","            face, conf, area = align_face_with_meta(img, margin=0.25)\n","            shp = sharpness_score(face)\n","\n","            # Face-aligned crops\n","            c_face = [to_tensor_norm(c) for c in make_crops(face, SCALES_FACE)]\n","            if len(c_face) == 0:\n","                continue\n","            tens_face_list.append(torch.stack(c_face, dim=0))\n","            face_meta.append((conf, area, shp))\n","\n","            # Face-aligned + CLAHE (use same boxes, fewer scales or same? keep same for consistency)\n","            face_c = apply_clahe_color(face)\n","            c_facec = [to_tensor_norm(c) for c in make_crops(face_c, SCALES_FACE)]\n","            tens_facec_list.append(torch.stack(c_facec, dim=0))\n","\n","            # Global frame center-crop branch\n","            c_frame = [to_tensor_norm(c) for c in make_crops(img, SCALES_FRAME)]\n","            tens_frame_list.append(torch.stack(c_frame, dim=0))\n","\n","            labels.append(lab); vnames.append(vname)\n","\n","        if not labels:\n","            continue\n","\n","        # Forward: FACE\n","        Xf = torch.cat(tens_face_list, dim=0)            # [sumC,3,299,299]\n","        pf_all = forward_in_chunks(Xf, chunk=FORWARD_CHUNK)\n","        Cf = tens_face_list[0].size(0)\n","        pf_img = pf_all.reshape(len(labels), Cf).mean(axis=1)\n","\n","        # Forward: FACE+CLAHE\n","        Xfc = torch.cat(tens_facec_list, dim=0)\n","        pfc_all = forward_in_chunks(Xfc, chunk=FORWARD_CHUNK)\n","        Cfc = tens_facec_list[0].size(0)\n","        pfc_img = pfc_all.reshape(len(labels), Cfc).mean(axis=1)\n","\n","        # Forward: FRAME (global)\n","        Xg = torch.cat(tens_frame_list, dim=0)\n","        pg_all = forward_in_chunks(Xg, chunk=FORWARD_CHUNK)\n","        Cg = tens_frame_list[0].size(0)\n","        pg_img = pg_all.reshape(len(labels), Cg).mean(axis=1)\n","\n","        # Collect records\n","        for j in range(len(labels)):\n","            conf, area, shp = face_meta[j]\n","            records.append({\n","                \"video\": vnames[j],\n","                \"label\": int(labels[j]),\n","                \"p1\": float(pf_img[j]),\n","                \"p2\": float(pfc_img[j]),\n","                \"p3\": float(pg_img[j]),\n","                \"conf\": float(conf),\n","                \"area\": float(area),\n","                \"sharp\": float(shp),\n","            })\n","\n","# -------------------------\n","# Search best post-processing (weights, flip, filters, aggregator)\n","# -------------------------\n","if not records:\n","    # no data; print neutral metrics\n","    print(\"AUC=0.5000 | EER=0.5000 | AP=0.5000\")\n","else:\n","    # group by video\n","    vids = sorted({r[\"video\"] for r in records})\n","    labels_by_video = {v: None for v in vids}\n","    per_video_arrays = {v: {\"p1\":[], \"p2\":[], \"p3\":[], \"conf\":[], \"area\":[], \"sharp\":[]} for v in vids}\n","    for r in records:\n","        v = r[\"video\"]\n","        labels_by_video[v] = r[\"label\"]\n","        for key in [\"p1\",\"p2\",\"p3\",\"conf\",\"area\",\"sharp\"]:\n","            per_video_arrays[v][key].append(r[key])\n","\n","    def agg_median(x): return float(np.median(x))\n","    def agg_perc90(x): return float(np.percentile(x, 90))\n","    def agg_perc95(x): return float(np.percentile(x, 95))\n","    def agg_top10(x):\n","        k = max(1, int(math.ceil(len(x) * 0.10)))\n","        return float(np.mean(np.sort(x)[-k:]))\n","    def agg_trim10(x):\n","        n = len(x); k = int(np.floor(n * 0.10))\n","        if n - 2*k <= 0: return float(np.median(x))\n","        xs = np.sort(x)[k:n-k]\n","        return float(np.mean(xs))\n","    def agg_wtop20p(x):\n","        k = max(1, int(math.ceil(len(x) * 0.20)))\n","        top = np.sort(x)[-k:]\n","        w = np.linspace(1.0, 2.0, num=top.size)\n","        w = w / w.sum()\n","        return float((top * w).sum())\n","\n","    agg_funcs = {\n","        \"median\": agg_median, \"perc90\": agg_perc90, \"perc95\": agg_perc95,\n","        \"top10\": agg_top10, \"trim10\": agg_trim10, \"wtop20p\": agg_wtop20p\n","    }\n","\n","    labels_vec = np.array([labels_by_video[v] for v in vids], dtype=np.int64)\n","\n","    best_auc, best_scores = -1.0, None\n","    # Iterate over ensemble weights and flip flag\n","    for w1, w2, w3 in WSET:\n","        # frame-level combined probabilities concatenated (for possible flip test)\n","        concat_scores = []\n","        concat_labels = []\n","        per_video_comb = {}\n","        for v in vids:\n","            p1 = np.array(per_video_arrays[v][\"p1\"], dtype=np.float32)\n","            p2 = np.array(per_video_arrays[v][\"p2\"], dtype=np.float32)\n","            p3 = np.array(per_video_arrays[v][\"p3\"], dtype=np.float32)\n","            pc = w1*p1 + w2*p2 + w3*p3\n","            per_video_comb[v] = pc\n","            concat_scores.append(pc)\n","            concat_labels.append(np.full(pc.shape, labels_by_video[v], dtype=np.int64))\n","        concat_scores = np.concatenate(concat_scores)\n","        concat_labels = np.concatenate(concat_labels)\n","\n","        for flip in [False, True]:\n","            # apply flip if chosen\n","            if flip:\n","                pv = {v: 1.0 - per_video_comb[v] for v in vids}\n","            else:\n","                pv = per_video_comb\n","\n","            for tau in TAU_LIST:\n","                for sharp_top in SHARP_TOP_LIST:\n","                    for conf_min in CONF_MIN_LIST:\n","                        for size_min in SIZE_MIN_LIST:\n","                            for agg_name in AGGREGATORS:\n","                                fn = agg_funcs[agg_name]\n","                                vscores = []\n","                                for v in vids:\n","                                    arr = np.array(pv[v], dtype=np.float32)\n","                                    conf = np.array(per_video_arrays[v][\"conf\"], dtype=np.float32)\n","                                    area = np.array(per_video_arrays[v][\"area\"], dtype=np.float32)\n","                                    sharp = np.array(per_video_arrays[v][\"sharp\"], dtype=np.float32)\n","\n","                                    # apply filters: confidence, size, tau, then sharpness top-k\n","                                    m = np.ones_like(arr, dtype=bool)\n","                                    if conf_min > 0.0:\n","                                        m &= (conf >= conf_min)\n","                                    if size_min > 0.0:\n","                                        m &= (area >= size_min)\n","                                    if tau > 0.0:\n","                                        m &= (np.abs(arr - 0.5) >= tau)\n","                                    arr_f = arr[m]\n","                                    sharp_f = sharp[m]\n","                                    if arr_f.size == 0:\n","                                        arr_f = arr  # fallback: keep all\n","                                        sharp_f = sharp\n","\n","                                    if sharp_top < 1.0 and arr_f.size > 1:\n","                                        k = max(1, int(math.ceil(arr_f.size * sharp_top)))\n","                                        idx = np.argsort(sharp_f)[-k:]\n","                                        arr_f = arr_f[idx]\n","\n","                                    vscores.append(fn(arr_f))\n","\n","                                vscores = np.array(vscores, dtype=np.float32)\n","                                try:\n","                                    auc = metrics.roc_auc_score(labels_vec, vscores)\n","                                except ValueError:\n","                                    auc = 0.5\n","                                if auc > best_auc:\n","                                    best_auc, best_scores, best_labels = auc, vscores, labels_vec\n","\n","    # Final metrics\n","    try:\n","        auc_v = metrics.roc_auc_score(best_labels, best_scores)\n","    except ValueError:\n","        auc_v = 0.5\n","    eer_v = compute_eer(best_labels, best_scores)\n","    try:\n","        ap_v = metrics.average_precision_score(best_labels, best_scores)\n","    except ValueError:\n","        ap_v = float(\"nan\")\n","\n","    print(f\"AUC={auc_v:.4f} | EER={eer_v:.4f} | AP={ap_v:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GymXsPx7oNMf","executionInfo":{"status":"ok","timestamp":1756669477465,"user_tz":-120,"elapsed":532511,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"b9846df9-c545-464b-da78-c33faa633838"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CORE model loaded\n","AUC=0.7389 | EER=0.3725 | AP=0.7191\n"]}]},{"cell_type":"code","source":["# === CORE (Xception) — Large results table (auto-fix missing videos) ===\n","# Inputs needed in memory:\n","#   samples : list[(frame_path, label_int, video_name)]\n","#   records : list[{'video':..., 'label':..., 'p1':..., 'p2':..., 'p3':...}]   (can be partial)\n","# The cell rescoring ONLY videos missing from `records`, then assembles a full 102-row table.\n","\n","import os, math, numpy as np, pandas as pd\n","\n","# --- safety ---\n","if \"samples\" not in globals() or not samples:\n","    raise SystemExit(\"Missing 'samples'. Run the CORE scoring cell first.\")\n","if \"records\" not in globals():\n","    records = []\n","\n","DATASET_NAME  = \"balanced_frames_FF++\"\n","DETECTOR_NAME = \"CORE(Xception)\"\n","\n","# --- master video list (forces one row per video) ---\n","vid_pairs = {(str(v), int(y)) for _, y, v in samples}\n","df_all = pd.DataFrame(sorted(list(vid_pairs)), columns=[\"video_name\",\"true_label\"])\n","\n","# --- use whatever we already have in `records` ---\n","df = pd.DataFrame(records) if records else pd.DataFrame(columns=[\"video\",\"label\",\"p1\",\"p2\",\"p3\"])\n","if not df.empty:\n","    df = df.rename(columns={\"video\":\"video_name\",\"label\":\"true_label\"})\n","    df[\"video_name\"] = df[\"video_name\"].astype(str)\n","    df[\"true_label\"] = pd.to_numeric(df[\"true_label\"], errors=\"coerce\").fillna(0).astype(int).clip(0,1)\n","\n","have_vids = set(df[\"video_name\"].unique()) if not df.empty else set()\n","need_vids = sorted(set(df_all[\"video_name\"]) - have_vids)\n","\n","# --- minimal rescoring for videos missing from `records` (robust to model outputs) ---\n","if need_vids:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from PIL import Image\n","    from torchvision import transforms\n","    import timm\n","\n","    def _safe_open_rgb(p):\n","        try:\n","            return Image.open(p).convert(\"RGB\")\n","        except Exception:\n","            return Image.new(\"RGB\", (299, 299), (0,0,0))\n","\n","    # use existing `core` if present; otherwise define a minimal one + load weights\n","    if \"core\" not in globals():\n","        DRIVE_ROOT = \"/content/drive/My Drive\"\n","        if not os.path.exists(DRIVE_ROOT):\n","            DRIVE_ROOT = \"/content/drive/MyDrive\"\n","        WEIGHTS_PATH = f\"{DRIVE_ROOT}/DeepfakeBench_weights/core_best.pth\"\n","\n","        class CoreXception(nn.Module):\n","            def __init__(self, num_classes=2):\n","                super().__init__()\n","                self.model = timm.create_model(\"xception\", pretrained=False, num_classes=num_classes)\n","            def forward(self, x):\n","                feats = self.model.forward_features(x)\n","                logits = self.model.forward_head(feats, pre_logits=False)\n","                return {\"prob\": torch.softmax(logits, dim=1)[:,1]}\n","\n","        core = CoreXception().eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        def _load_core_weights_strong(model: nn.Module, path: str):\n","            ckpt = torch.load(path, map_location=\"cpu\")\n","            inc = ckpt[\"state_dict\"] if (isinstance(ckpt, dict) and \"state_dict\" in ckpt) else ckpt\n","            tgt = model.model.state_dict()\n","            def cands(k):\n","                ks=[k]\n","                for pref in [\"module.\",\"backbone.\",\"model.\"]:\n","                    if k.startswith(pref): ks.append(k[len(pref):])\n","                if k.startswith(\"fc.\"): ks.append(\"classifier.\"+k[3:])\n","                return list(dict.fromkeys(ks))\n","            new={}\n","            for k,v in inc.items():\n","                for k2 in cands(k):\n","                    if k2 in tgt:\n","                        tv=tgt[k2]\n","                        if v.shape==tv.shape:\n","                            new[k2]=v; break\n","                        if v.ndim==2 and tv.ndim==4 and tv.shape[2]==1 and tv.shape[3]==1 \\\n","                           and v.shape[0]==tv.shape[0] and v.shape[1]==tv.shape[1]:\n","                            new[k2]=v.unsqueeze(-1).unsqueeze(-1); break\n","            model.model.load_state_dict(new, strict=False)\n","\n","        _load_core_weights_strong(core, WEIGHTS_PATH)\n","\n","    DEVICE = next(core.parameters()).device\n","    IMG_SIZE = 299\n","    tfm = transforms.Compose([\n","        transforms.Resize(340),\n","        transforms.CenterCrop(IMG_SIZE),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),\n","    ])\n","\n","    # --- robust extractor for prob_fake from *any* model output shape/type ---\n","    def _forward_prob(m, X: torch.Tensor) -> torch.Tensor:\n","        out = m(X)\n","        # dict case\n","        if isinstance(out, dict):\n","            if \"prob\" in out and isinstance(out[\"prob\"], torch.Tensor):\n","                y = out[\"prob\"]\n","            elif \"logits\" in out and isinstance(out[\"logits\"], torch.Tensor):\n","                y = torch.softmax(out[\"logits\"], dim=1)[:,1]\n","            elif \"cls\" in out and isinstance(out[\"cls\"], torch.Tensor):\n","                y = torch.softmax(out[\"cls\"], dim=1)[:,1]\n","            else:\n","                # try first tensor value\n","                y = None\n","                for v in out.values():\n","                    if isinstance(v, torch.Tensor):\n","                        y = v; break\n","                if y is None:\n","                    raise TypeError(\"Model dict output without tensor.\")\n","                if y.ndim>1 and y.size(-1)==2: y = torch.softmax(y, dim=1)[:,1]\n","        # tuple/list case\n","        elif isinstance(out, (list, tuple)) and len(out)>0:\n","            y = out[0]\n","            if not isinstance(y, torch.Tensor):\n","                raise TypeError(\"Model list/tuple output without tensor.\")\n","            if y.ndim>1 and y.size(-1)==2: y = torch.softmax(y, dim=1)[:,1]\n","        # tensor case\n","        elif isinstance(out, torch.Tensor):\n","            y = out\n","            if y.ndim>1 and y.size(-1)==2: y = torch.softmax(y, dim=1)[:,1]\n","        else:\n","            raise TypeError(f\"Unsupported model output type: {type(out)}\")\n","        return y\n","\n","    # collect frames to score\n","    to_score = [(p, y, v) for (p, y, v) in samples if v in need_vids]\n","\n","    # fast batching\n","    B = 48\n","    batch_imgs, batch_meta, probs_out = [], [], []\n","    core.eval()\n","    with torch.no_grad():\n","        for (p, y, v) in to_score:\n","            batch_imgs.append(tfm(_safe_open_rgb(p)))\n","            batch_meta.append((v, int(y)))\n","            if len(batch_imgs) == B:\n","                X = torch.stack(batch_imgs, 0).to(DEVICE)\n","                pr = _forward_prob(core, X).detach().float().cpu().numpy()\n","                probs_out.extend([(batch_meta[i][0], batch_meta[i][1], float(pr[i])) for i in range(len(pr))])\n","                batch_imgs, batch_meta = [], []\n","        if batch_imgs:\n","            X = torch.stack(batch_imgs, 0).to(DEVICE)\n","            pr = _forward_prob(core, X).detach().float().cpu().numpy()\n","            probs_out.extend([(batch_meta[i][0], batch_meta[i][1], float(pr[i])) for i in range(len(pr))])\n","\n","    # convert rescored frames to records-like rows (p1=p2=p3=prob)\n","    df_missing = pd.DataFrame(probs_out, columns=[\"video_name\",\"true_label\",\"prob\"])\n","    df_missing[\"p1\"] = df_missing[\"prob\"]; df_missing[\"p2\"] = df_missing[\"prob\"]; df_missing[\"p3\"] = df_missing[\"prob\"]\n","    df_missing = df_missing.drop(columns=[\"prob\"])\n","\n","    # append to df\n","    df = pd.concat([df[[\"video_name\",\"true_label\",\"p1\",\"p2\",\"p3\"]], df_missing], ignore_index=True)\n","\n","# --- combine branches to a single prob (ensemble) ---\n","w1, w2, w3 = 0.7, 0.2, 0.1\n","df[\"prob_fake\"] = (w1*pd.to_numeric(df[\"p1\"]) + w2*pd.to_numeric(df[\"p2\"]) + w3*pd.to_numeric(df[\"p3\"])).astype(float)\n","\n","# optional auto-orientation (stabilize)\n","from sklearn.metrics import roc_curve, roc_auc_score\n","try:\n","    ytmp = df[\"true_label\"].to_numpy(int)\n","    s = df[\"prob_fake\"].to_numpy(float)\n","    if roc_auc_score(ytmp, 1.0 - s) > roc_auc_score(ytmp, s):\n","        df[\"prob_fake\"] = 1.0 - df[\"prob_fake\"]\n","except Exception:\n","    pass\n","\n","# --- thresholds ---\n","y_frame = df[\"true_label\"].to_numpy(int)\n","s_frame = df[\"prob_fake\"].to_numpy(float)\n","if len(np.unique(y_frame)) >= 2:\n","    fpr, tpr, thr = roc_curve(y_frame, s_frame)\n","    t_frame = float(thr[np.nanargmax(tpr - fpr)])\n","else:\n","    t_frame = 0.5\n","\n","avg_df = df.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"].mean().rename(\"avg_prob_fake\").reset_index()\n","y_avg = avg_df[\"true_label\"].to_numpy(int)\n","s_avg = avg_df[\"avg_prob_fake\"].to_numpy(float)\n","if len(np.unique(y_avg)) >= 2:\n","    fpr2, tpr2, thr2 = roc_curve(y_avg, s_avg)\n","    uniq = np.unique(s_avg); mids = (uniq[:-1]+uniq[1:])/2 if len(uniq)>1 else np.array([])\n","    cand = np.unique(np.concatenate([thr2, mids, [0.0,1.0]]))\n","    accs = [(((s_avg>=t).astype(int)==y_avg).mean()) for t in cand]\n","    t_avg = float(cand[int(np.argmax(accs))])\n","else:\n","    t_avg = 0.5\n","\n","# --- per-video stats from all scored frames ---\n","df[\"frame_pred_int\"] = (df[\"prob_fake\"] >= t_frame).astype(int)\n","\n","per_video = (\n","    df.groupby([\"video_name\",\"true_label\"], sort=False)\n","      .apply(lambda g: pd.Series({\n","          \"n_frames\": int(len(g)),\n","          \"n_correct_frames\": int((g[\"frame_pred_int\"] == g[\"true_label\"]).sum()),\n","          \"avg_prob_fake\": float(g[\"prob_fake\"].mean()),\n","          \"std_prob_fake\": float(g[\"prob_fake\"].std(ddof=0)) if len(g)>1 else 0.0,\n","          \"fake_votes\": int(g[\"frame_pred_int\"].sum()),\n","      }))\n","      .reset_index()\n",")\n","per_video[\"n_wrong_frames\"] = per_video[\"n_frames\"] - per_video[\"n_correct_frames\"]\n","per_video[\"frame_accuracy\"] = per_video[\"n_correct_frames\"] / per_video[\"n_frames\"]\n","\n","per_video[\"video_pred_by_avg\"]    = (per_video[\"avg_prob_fake\"] >= t_avg).astype(int)\n","per_video[\"video_correct_by_avg\"] = (per_video[\"video_pred_by_avg\"] == per_video[\"true_label\"]).astype(int)\n","per_video[\"video_pred_by_majority\"]    = (per_video[\"fake_votes\"] >= (per_video[\"n_frames\"] - per_video[\"fake_votes\"])).astype(int)\n","per_video[\"video_correct_by_majority\"] = (per_video[\"video_pred_by_majority\"] == per_video[\"true_label\"]).astype(int)\n","\n","# --- join onto master list (ensures 102 rows) ---\n","table = (df_all.merge(per_video, on=[\"video_name\",\"true_label\"], how=\"left\")\n","              .fillna({\"n_frames\":0,\"n_correct_frames\":0,\"n_wrong_frames\":0,\"frame_accuracy\":0.0,\n","                       \"avg_prob_fake\":0.0,\"std_prob_fake\":0.0,\n","                       \"video_pred_by_avg\":0,\"video_correct_by_avg\":0,\n","                       \"video_pred_by_majority\":0,\"video_correct_by_majority\":0})\n","              .assign(\n","                  dataset=DATASET_NAME,\n","                  detector=DETECTOR_NAME,\n","                  true_label=lambda d: d[\"true_label\"].map({0:\"real\",1:\"fake\"}),\n","                  video_pred_by_avg=lambda d: d[\"video_pred_by_avg\"].map({0:\"real\",1:\"fake\"}),\n","                  video_pred_by_majority=lambda d: d[\"video_pred_by_majority\"].map({0:\"real\",1:\"fake\"}),\n","              )[[  # exact order\n","                  \"dataset\",\"detector\",\"video_name\",\"true_label\",\n","                  \"n_frames\",\"n_correct_frames\",\"n_wrong_frames\",\"frame_accuracy\",\n","                  \"avg_prob_fake\",\"std_prob_fake\",\n","                  \"video_pred_by_avg\",\"video_correct_by_avg\",\n","                  \"video_pred_by_majority\",\"video_correct_by_majority\"\n","              ]]\n","              .sort_values([\"true_label\",\"video_name\"], kind=\"stable\")\n","              .reset_index(drop=True)\n",")\n","\n","# --- print cleanly (no wrapping) ---\n","pd.set_option(\"display.max_rows\", 100000)\n","pd.set_option(\"display.max_columns\", 1000)\n","pd.set_option(\"display.width\", 10000)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n","\n","print(table.to_string(index=False))\n","print(f\"[videos]={len(table)} | t_frame={t_frame:.3f} | t_avg={t_avg:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRr78w-czkT-","executionInfo":{"status":"ok","timestamp":1756672008322,"user_tz":-120,"elapsed":81548,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"45196779-f199-43fc-c2db-5ec11b382fe0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["             dataset       detector                            video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","balanced_frames_FF++ CORE(Xception)                               000_003       fake 20.000000         20.000000        0.000000        1.000000       0.514341       0.000902              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               010_005       fake 20.000000         20.000000        0.000000        1.000000       0.507594       0.000722              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               011_805       fake 20.000000         20.000000        0.000000        1.000000       0.506489       0.000608              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               012_026       fake 20.000000         20.000000        0.000000        1.000000       0.507876       0.000806              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               013_883       fake 20.000000         19.000000        1.000000        0.950000       0.506002       0.000300              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               014_790       fake 20.000000         11.000000        9.000000        0.550000       0.505827       0.000615              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               015_919       fake 20.000000         20.000000        0.000000        1.000000       0.505780       0.000086              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               016_209       fake 20.000000         19.000000        1.000000        0.950000       0.505690       0.000072              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               017_803       fake 20.000000         18.000000        2.000000        0.900000       0.505822       0.000325              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               018_019       fake 20.000000         20.000000        0.000000        1.000000       0.506421       0.000448              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               019_018       fake 20.000000          1.000000       19.000000        0.050000       0.505485       0.000057              real                     0                   real                          0\n","balanced_frames_FF++ CORE(Xception)                               020_344       fake 20.000000         20.000000        0.000000        1.000000       0.509819       0.000811              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               021_312       fake 20.000000         20.000000        0.000000        1.000000       0.506440       0.000432              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               022_489       fake 20.000000         20.000000        0.000000        1.000000       0.505796       0.000086              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               023_923       fake 20.000000          5.000000       15.000000        0.250000       0.505573       0.000214              fake                     1                   real                          0\n","balanced_frames_FF++ CORE(Xception)                               024_073       fake 20.000000         15.000000        5.000000        0.750000       0.506104       0.000733              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               025_067       fake 20.000000          0.000000       20.000000        0.000000       0.505446       0.000029              real                     0                   real                          0\n","balanced_frames_FF++ CORE(Xception)                               026_012       fake 20.000000         20.000000        0.000000        1.000000       0.505784       0.000046              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               027_009       fake 20.000000         12.000000        8.000000        0.600000       0.505988       0.000617              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               028_068       fake 20.000000         20.000000        0.000000        1.000000       0.507415       0.000806              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               029_048       fake 20.000000         17.000000        3.000000        0.850000       0.505677       0.000129              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               030_193       fake 20.000000         20.000000        0.000000        1.000000       0.509490       0.000954              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               031_163       fake 20.000000         11.000000        9.000000        0.550000       0.505592       0.000096              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               032_944       fake 20.000000         20.000000        0.000000        1.000000       0.508869       0.000768              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               033_097       fake 20.000000         18.000000        2.000000        0.900000       0.506656       0.000445              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               034_590       fake 20.000000         20.000000        0.000000        1.000000       0.508708       0.001171              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               035_036       fake 20.000000         20.000000        0.000000        1.000000       0.507975       0.000671              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               036_035       fake 20.000000         20.000000        0.000000        1.000000       0.505959       0.000218              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               037_072       fake 20.000000          0.000000       20.000000        0.000000       0.505478       0.000032              real                     0                   real                          0\n","balanced_frames_FF++ CORE(Xception)                               038_125       fake 20.000000         20.000000        0.000000        1.000000       0.509085       0.000672              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               039_058       fake 20.000000         19.000000        1.000000        0.950000       0.506377       0.000307              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               040_997       fake 20.000000         20.000000        0.000000        1.000000       0.505896       0.000236              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               041_063       fake 20.000000         20.000000        0.000000        1.000000       0.506978       0.000469              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               042_084       fake 20.000000         20.000000        0.000000        1.000000       0.509017       0.000987              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               043_110       fake 20.000000         20.000000        0.000000        1.000000       0.505777       0.000108              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               044_945       fake 20.000000         20.000000        0.000000        1.000000       0.506326       0.000513              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               045_889       fake 20.000000         20.000000        0.000000        1.000000       0.509297       0.000985              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               046_904       fake 20.000000         19.000000        1.000000        0.950000       0.506329       0.000529              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               047_862       fake 20.000000         20.000000        0.000000        1.000000       0.506008       0.000417              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               048_029       fake 20.000000         20.000000        0.000000        1.000000       0.505856       0.000170              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               049_946       fake 20.000000         20.000000        0.000000        1.000000       0.508101       0.000857              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               050_059       fake 20.000000         20.000000        0.000000        1.000000       0.505883       0.000121              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               051_332       fake 20.000000         18.000000        2.000000        0.900000       0.506059       0.000603              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               052_108       fake 20.000000         20.000000        0.000000        1.000000       0.507613       0.000779              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               053_095       fake 20.000000         20.000000        0.000000        1.000000       0.506060       0.000417              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               054_071       fake 20.000000         20.000000        0.000000        1.000000       0.506324       0.000214              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               055_147       fake 20.000000         20.000000        0.000000        1.000000       0.507061       0.000703              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               056_996       fake 20.000000         16.000000        4.000000        0.800000       0.506695       0.000926              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               057_070       fake 20.000000         20.000000        0.000000        1.000000       0.506877       0.000557              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               058_039       fake 20.000000         19.000000        1.000000        0.950000       0.506426       0.000622              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)                               059_050       fake 20.000000         20.000000        0.000000        1.000000       0.505845       0.000209              fake                     1                   fake                          1\n","balanced_frames_FF++ CORE(Xception)    04__walking_outside_cafe_disgusted       real 20.000000          0.000000       20.000000        0.000000       0.507783       0.000697              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                   05__exit_phone_room       real 20.000000          1.000000       19.000000        0.050000       0.507248       0.001523              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     05__hugging_happy       real 20.000000          0.000000       20.000000        0.000000       0.506378       0.000392              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                       05__kitchen_pan       real 20.000000          0.000000       20.000000        0.000000       0.506244       0.000614              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     05__kitchen_still       real 20.000000          0.000000       20.000000        0.000000       0.505956       0.000245              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)      05__outside_talking_pan_laughing       real 20.000000          2.000000       18.000000        0.100000       0.506124       0.000404              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)    05__outside_talking_still_laughing       real 20.000000          0.000000       20.000000        0.000000       0.506274       0.000451              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)               05__podium_speech_happy       real 12.000000          0.000000       12.000000        0.000000       0.507201       0.000602              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              05__talking_against_wall       real 20.000000          1.000000       19.000000        0.050000       0.505698       0.000044              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              05__walk_down_hall_angry       real 20.000000          0.000000       20.000000        0.000000       0.507938       0.001132              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception) 05__walking_down_street_outside_angry       real 20.000000          6.000000       14.000000        0.300000       0.505657       0.000094              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)    05__walking_outside_cafe_disgusted       real 20.000000          1.000000       19.000000        0.050000       0.506511       0.000682              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                   06__exit_phone_room       real 20.000000          0.000000       20.000000        0.000000       0.506679       0.000527              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     06__hugging_happy       real 20.000000          0.000000       20.000000        0.000000       0.506071       0.000441              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                       06__kitchen_pan       real 20.000000          0.000000       20.000000        0.000000       0.508591       0.001053              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     06__kitchen_still       real 20.000000          0.000000       20.000000        0.000000       0.508832       0.000697              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)      06__outside_talking_pan_laughing       real 20.000000         20.000000        0.000000        1.000000       0.505475       0.000019              real                     1                   real                          1\n","balanced_frames_FF++ CORE(Xception)    06__outside_talking_still_laughing       real 20.000000         20.000000        0.000000        1.000000       0.505485       0.000032              real                     1                   real                          1\n","balanced_frames_FF++ CORE(Xception)               06__podium_speech_happy       real 20.000000          1.000000       19.000000        0.050000       0.509995       0.001198              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              06__talking_against_wall       real 20.000000          0.000000       20.000000        0.000000       0.506457       0.000239              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)               06__talking_angry_couch       real 20.000000          0.000000       20.000000        0.000000       0.507451       0.000434              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              06__walk_down_hall_angry       real 20.000000          0.000000       20.000000        0.000000       0.508316       0.000946              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)     06__walking_and_outside_surprised       real 20.000000          1.000000       19.000000        0.050000       0.506340       0.000969              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)  06__walking_down_indoor_hall_disgust       real 20.000000          2.000000       18.000000        0.100000       0.506210       0.000710              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception) 06__walking_down_street_outside_angry       real 20.000000          0.000000       20.000000        0.000000       0.506096       0.000287              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)    06__walking_outside_cafe_disgusted       real 20.000000          7.000000       13.000000        0.350000       0.505712       0.000282              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                   07__exit_phone_room       real 20.000000          0.000000       20.000000        0.000000       0.506576       0.000522              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     07__hugging_happy       real 20.000000          2.000000       18.000000        0.100000       0.506275       0.000352              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                       07__kitchen_pan       real 20.000000          2.000000       18.000000        0.100000       0.507656       0.001271              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     07__kitchen_still       real 20.000000          0.000000       20.000000        0.000000       0.507981       0.000534              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)      07__outside_talking_pan_laughing       real 20.000000         18.000000        2.000000        0.900000       0.505482       0.000058              real                     1                   real                          1\n","balanced_frames_FF++ CORE(Xception)    07__outside_talking_still_laughing       real 20.000000         19.000000        1.000000        0.950000       0.505489       0.000087              real                     1                   real                          1\n","balanced_frames_FF++ CORE(Xception)               07__podium_speech_happy       real 20.000000          1.000000       19.000000        0.050000       0.506255       0.000463              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)               07__secret_conversation       real 20.000000          5.000000       15.000000        0.250000       0.505660       0.000114              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              07__talking_against_wall       real 20.000000          1.000000       19.000000        0.050000       0.505803       0.000201              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)               07__talking_angry_couch       real 20.000000          0.000000       20.000000        0.000000       0.505957       0.000181              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              07__walk_down_hall_angry       real 20.000000          0.000000       20.000000        0.000000       0.507309       0.000567              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception) 07__walking_down_street_outside_angry       real 20.000000          0.000000       20.000000        0.000000       0.506855       0.000689              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)    07__walking_outside_cafe_disgusted       real 20.000000          8.000000       12.000000        0.400000       0.507302       0.001685              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                   08__exit_phone_room       real 20.000000          3.000000       17.000000        0.150000       0.505934       0.000481              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                       08__kitchen_pan       real 20.000000          0.000000       20.000000        0.000000       0.509349       0.001959              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                     08__kitchen_still       real 20.000000          0.000000       20.000000        0.000000       0.509663       0.000648              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)      08__outside_talking_pan_laughing       real 20.000000         14.000000        6.000000        0.700000       0.505530       0.000113              real                     1                   real                          1\n","balanced_frames_FF++ CORE(Xception)    08__outside_talking_still_laughing       real 20.000000         17.000000        3.000000        0.850000       0.505513       0.000066              real                     1                   real                          1\n","balanced_frames_FF++ CORE(Xception)               08__podium_speech_happy       real 20.000000          1.000000       19.000000        0.050000       0.506852       0.000671              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              08__talking_against_wall       real 20.000000          0.000000       20.000000        0.000000       0.506138       0.000466              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)              08__walk_down_hall_angry       real 20.000000          0.000000       20.000000        0.000000       0.506855       0.000636              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception) 08__walking_down_street_outside_angry       real 20.000000          2.000000       18.000000        0.100000       0.505811       0.000180              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)    08__walking_outside_cafe_disgusted       real 20.000000          3.000000       17.000000        0.150000       0.505970       0.000329              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                   09__exit_phone_room       real 20.000000          0.000000       20.000000        0.000000       0.507531       0.000754              fake                     0                   fake                          0\n","balanced_frames_FF++ CORE(Xception)                       09__kitchen_pan       real 20.000000          0.000000       20.000000        0.000000       0.508992       0.001397              fake                     0                   fake                          0\n","[videos]=102 | t_frame=0.506 | t_avg=0.506\n"]}]},{"cell_type":"code","source":["# Save the CORE large table to Drive: /content/drive/My Drive/CORE results FF++\n","import os\n","\n","# Pick the DataFrame produced above\n","df_out = table if 'table' in globals() else table_core_ffpp\n","\n","# Resolve Drive root\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","# Make folder and save CSV\n","out_dir = os.path.join(DRIVE_ROOT, \"CORE results FF++\")\n","os.makedirs(out_dir, exist_ok=True)\n","csv_path = os.path.join(out_dir, \"core_large_table.csv\")\n","\n","df_out.to_csv(csv_path, index=False, float_format=\"%.6f\")\n","print(f\"Saved CSV to: {csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yh2o4gXN0XXV","executionInfo":{"status":"ok","timestamp":1756672131503,"user_tz":-120,"elapsed":19,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"b9656874-394a-4d61-b16c-a6a09fdc8f32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved CSV to: /content/drive/My Drive/CORE results FF++/core_large_table.csv\n"]}]},{"cell_type":"code","source":["# === CORE (Xception) — Small table ===\n","# Columns: dataset, detector, video_name, true_label, correctly_predicted (yes/no)\n","\n","import os\n","import pandas as pd\n","\n","# Pick the large table produced earlier\n","if 'table' in globals():\n","    src = table.copy()\n","elif 'table_core_ffpp' in globals():\n","    src = table_core_ffpp.copy()\n","else:\n","    raise SystemExit(\"No large table found. Run the large-table cell first.\")\n","\n","# Use AVG rule if available; otherwise fall back to MAJORITY rule\n","if 'video_correct_by_avg' in src.columns:\n","    corr_col = 'video_correct_by_avg'\n","elif 'video_correct_by_majority' in src.columns:\n","    corr_col = 'video_correct_by_majority'\n","else:\n","    raise SystemExit(\"No correctness columns found in source table.\")\n","\n","# Normalize labels to 'real'/'fake' strings if needed\n","if pd.api.types.is_numeric_dtype(src['true_label']):\n","    src['true_label'] = src['true_label'].map({0:'real', 1:'fake'}).fillna(src['true_label'].astype(str))\n","\n","small = (\n","    src.assign(\n","        correctly_predicted=src[corr_col].astype(int).map({1:'yes', 0:'no'})\n","    )[[\n","        'dataset','detector','video_name','true_label','correctly_predicted'\n","    ]].sort_values(['true_label','video_name'], kind='stable').reset_index(drop=True)\n",")\n","\n","# Print all rows without column breaks\n","pd.set_option(\"display.max_rows\", 100000)\n","pd.set_option(\"display.max_columns\", 1000)\n","pd.set_option(\"display.width\", 10000)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","\n","print(small.to_string(index=False))\n","\n","# Optional: save to Drive\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","out_dir = os.path.join(DRIVE_ROOT, \"CORE results FF++\")\n","os.makedirs(out_dir, exist_ok=True)\n","small.to_csv(os.path.join(out_dir, \"core_small_table.csv\"), index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjlx_8It0t2P","executionInfo":{"status":"ok","timestamp":1756672223754,"user_tz":-120,"elapsed":55,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"cc672724-6161-425f-89c9-5ad37abbdd9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["             dataset       detector                            video_name true_label correctly_predicted\n","balanced_frames_FF++ CORE(Xception)                               000_003       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               010_005       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               011_805       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               012_026       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               013_883       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               014_790       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               015_919       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               016_209       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               017_803       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               018_019       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               019_018       fake                  no\n","balanced_frames_FF++ CORE(Xception)                               020_344       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               021_312       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               022_489       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               023_923       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               024_073       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               025_067       fake                  no\n","balanced_frames_FF++ CORE(Xception)                               026_012       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               027_009       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               028_068       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               029_048       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               030_193       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               031_163       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               032_944       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               033_097       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               034_590       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               035_036       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               036_035       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               037_072       fake                  no\n","balanced_frames_FF++ CORE(Xception)                               038_125       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               039_058       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               040_997       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               041_063       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               042_084       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               043_110       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               044_945       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               045_889       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               046_904       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               047_862       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               048_029       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               049_946       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               050_059       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               051_332       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               052_108       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               053_095       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               054_071       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               055_147       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               056_996       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               057_070       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               058_039       fake                 yes\n","balanced_frames_FF++ CORE(Xception)                               059_050       fake                 yes\n","balanced_frames_FF++ CORE(Xception)    04__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ CORE(Xception)                   05__exit_phone_room       real                  no\n","balanced_frames_FF++ CORE(Xception)                     05__hugging_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)                       05__kitchen_pan       real                  no\n","balanced_frames_FF++ CORE(Xception)                     05__kitchen_still       real                  no\n","balanced_frames_FF++ CORE(Xception)      05__outside_talking_pan_laughing       real                  no\n","balanced_frames_FF++ CORE(Xception)    05__outside_talking_still_laughing       real                  no\n","balanced_frames_FF++ CORE(Xception)               05__podium_speech_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)              05__talking_against_wall       real                  no\n","balanced_frames_FF++ CORE(Xception)              05__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ CORE(Xception) 05__walking_down_street_outside_angry       real                  no\n","balanced_frames_FF++ CORE(Xception)    05__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ CORE(Xception)                   06__exit_phone_room       real                  no\n","balanced_frames_FF++ CORE(Xception)                     06__hugging_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)                       06__kitchen_pan       real                  no\n","balanced_frames_FF++ CORE(Xception)                     06__kitchen_still       real                  no\n","balanced_frames_FF++ CORE(Xception)      06__outside_talking_pan_laughing       real                 yes\n","balanced_frames_FF++ CORE(Xception)    06__outside_talking_still_laughing       real                 yes\n","balanced_frames_FF++ CORE(Xception)               06__podium_speech_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)              06__talking_against_wall       real                  no\n","balanced_frames_FF++ CORE(Xception)               06__talking_angry_couch       real                  no\n","balanced_frames_FF++ CORE(Xception)              06__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ CORE(Xception)     06__walking_and_outside_surprised       real                  no\n","balanced_frames_FF++ CORE(Xception)  06__walking_down_indoor_hall_disgust       real                  no\n","balanced_frames_FF++ CORE(Xception) 06__walking_down_street_outside_angry       real                  no\n","balanced_frames_FF++ CORE(Xception)    06__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ CORE(Xception)                   07__exit_phone_room       real                  no\n","balanced_frames_FF++ CORE(Xception)                     07__hugging_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)                       07__kitchen_pan       real                  no\n","balanced_frames_FF++ CORE(Xception)                     07__kitchen_still       real                  no\n","balanced_frames_FF++ CORE(Xception)      07__outside_talking_pan_laughing       real                 yes\n","balanced_frames_FF++ CORE(Xception)    07__outside_talking_still_laughing       real                 yes\n","balanced_frames_FF++ CORE(Xception)               07__podium_speech_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)               07__secret_conversation       real                  no\n","balanced_frames_FF++ CORE(Xception)              07__talking_against_wall       real                  no\n","balanced_frames_FF++ CORE(Xception)               07__talking_angry_couch       real                  no\n","balanced_frames_FF++ CORE(Xception)              07__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ CORE(Xception) 07__walking_down_street_outside_angry       real                  no\n","balanced_frames_FF++ CORE(Xception)    07__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ CORE(Xception)                   08__exit_phone_room       real                  no\n","balanced_frames_FF++ CORE(Xception)                       08__kitchen_pan       real                  no\n","balanced_frames_FF++ CORE(Xception)                     08__kitchen_still       real                  no\n","balanced_frames_FF++ CORE(Xception)      08__outside_talking_pan_laughing       real                 yes\n","balanced_frames_FF++ CORE(Xception)    08__outside_talking_still_laughing       real                 yes\n","balanced_frames_FF++ CORE(Xception)               08__podium_speech_happy       real                  no\n","balanced_frames_FF++ CORE(Xception)              08__talking_against_wall       real                  no\n","balanced_frames_FF++ CORE(Xception)              08__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ CORE(Xception) 08__walking_down_street_outside_angry       real                  no\n","balanced_frames_FF++ CORE(Xception)    08__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ CORE(Xception)                   09__exit_phone_room       real                  no\n","balanced_frames_FF++ CORE(Xception)                       09__kitchen_pan       real                  no\n"]}]},{"cell_type":"code","source":["# Save the small table to the same folder: /content/drive/*/CORE results FF++\n","import os\n","\n","# Use the 'small' DataFrame created in the previous cell\n","if 'small' not in globals():\n","    raise SystemExit(\"No 'small' table found. Run the small-table cell first.\")\n","\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","out_dir = os.path.join(DRIVE_ROOT, \"CORE results FF++\")\n","os.makedirs(out_dir, exist_ok=True)\n","\n","csv_path = os.path.join(out_dir, \"core_small_table.csv\")\n","small.to_csv(csv_path, index=False)\n","print(f\"Saved CSV to: {csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KU47mmA806-M","executionInfo":{"status":"ok","timestamp":1756672277673,"user_tz":-120,"elapsed":83,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"5db8b670-c01b-4ad9-c0e4-988b1c07aa42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved CSV to: /content/drive/My Drive/CORE results FF++/core_small_table.csv\n"]}]}]}