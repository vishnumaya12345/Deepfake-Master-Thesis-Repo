{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMTGdp8ALnHkbD6kSPQWuYD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03vG5wjlQ8o6","executionInfo":{"status":"ok","timestamp":1755606013340,"user_tz":-120,"elapsed":29672,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"f69b555d-107b-4938-c0b3-12da96e791e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","CUDA available: True\n","Weights found: True\n","Real videos folder exists: True\n","Fake videos folder exists: True\n","Results will be saved to: /content/drive/My Drive/deepfake_results/celebdf_effb4\n"]}],"source":["# STEP 1: GPU check + mount Google Drive + define paths for EfficientNet (CNN-Aug)\n","\n","# 1) Mount Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# 2) Check GPU\n","import torch, os\n","print(\"CUDA available:\", torch.cuda.is_available())\n","\n","# 3) EDIT THESE PATHS if your folders are different\n","#    (Using your Celeb-DF example; change to any dataset you want)\n","VIDEOS_REAL_DIR = \"/content/drive/My Drive/test dataset Celeb DF/real\"\n","VIDEOS_FAKE_DIR = \"/content/drive/My Drive/test dataset Celeb DF/fake\"\n","\n","# Where extracted frames will go (local, fast)\n","FRAMES_REAL_DIR = \"/content/frames/effb4/real\"\n","FRAMES_FAKE_DIR = \"/content/frames/effb4/fake\"\n","\n","# Your EfficientNet-B4 weights (CNN-Aug)\n","WEIGHTS_PATH = \"/content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\"\n","\n","# Where to save results (tables/metrics)\n","RESULTS_DIR = \"/content/drive/My Drive/deepfake_results/celebdf_effb4\"\n","\n","# Make sure folders exist\n","for p in [FRAMES_REAL_DIR, FRAMES_FAKE_DIR, RESULTS_DIR]:\n","    os.makedirs(p, exist_ok=True)\n","\n","# Quick sanity checks\n","print(\"Weights found:\", os.path.exists(WEIGHTS_PATH))\n","print(\"Real videos folder exists:\", os.path.exists(VIDEOS_REAL_DIR))\n","print(\"Fake videos folder exists:\", os.path.exists(VIDEOS_FAKE_DIR))\n","print(\"Results will be saved to:\", RESULTS_DIR)\n"]},{"cell_type":"code","source":["# STEP 2: Extract N uniform frames per video (real & fake) → saves JPGs in FRAMES_*_DIR\n","\n","import os, cv2, glob\n","from tqdm import tqdm\n","\n","# How many frames to save per video (edit if you want more/less)\n","N_FRAMES_PER_VIDEO = 20\n","JPEG_QUALITY = 95  # 80–95 is usually fine\n","\n","# --- Helpers ---\n","def ensure_dir(p): os.makedirs(p, exist_ok=True)\n","\n","def list_videos(folder):\n","    exts = (\".mp4\", \".avi\", \".mov\", \".mkv\", \".webm\", \".flv\")\n","    return sorted([p for p in glob.glob(os.path.join(folder, \"*\")) if p.lower().endswith(exts)])\n","\n","def video_stem(path):\n","    return os.path.splitext(os.path.basename(path))[0]\n","\n","def extract_uniform_frames(video_path, out_dir, n_frames=20, jpeg_q=95):\n","    \"\"\"Extract n_frames roughly uniformly across the video.\"\"\"\n","    name = video_stem(video_path)\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        return 0\n","\n","    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    # Fallback if frame count is unreliable\n","    if total <= 0:\n","        # Count by reading\n","        frames = []\n","        while True:\n","            ok, _ = cap.read()\n","            if not ok: break\n","            frames.append(1)\n","        total = len(frames)\n","        cap.release()\n","        cap = cv2.VideoCapture(video_path)\n","\n","    if total == 0:\n","        cap.release()\n","        return 0\n","\n","    # Choose indices uniformly\n","    if total <= n_frames:\n","        picks = list(range(total))\n","    else:\n","        step = total / float(n_frames)\n","        picks = [int(i * step) for i in range(n_frames)]\n","\n","    saved = 0\n","    for i, idx in enumerate(picks):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n","        ok, frame_bgr = cap.read()\n","        if not ok:\n","            continue\n","        # Save as RGB JPEG\n","        out_path = os.path.join(out_dir, f\"{name}_frame{i:04d}.jpg\")\n","        cv2.imwrite(out_path, frame_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), jpeg_q])\n","        saved += 1\n","\n","    cap.release()\n","    return saved\n","\n","def extract_folder(in_dir, out_dir, n_frames=20, jpeg_q=95):\n","    ensure_dir(out_dir)\n","    vids = list_videos(in_dir)\n","    total_saved = 0\n","    for vp in tqdm(vids, desc=f\"Extracting from {os.path.basename(in_dir)}\"):\n","        total_saved += extract_uniform_frames(vp, out_dir, n_frames, jpeg_q)\n","    return len(vids), total_saved\n","\n","# --- Run extraction for your real & fake folders from STEP 1 ---\n","ensure_dir(FRAMES_REAL_DIR); ensure_dir(FRAMES_FAKE_DIR)\n","\n","n_real, saved_real = extract_folder(VIDEOS_REAL_DIR, FRAMES_REAL_DIR, N_FRAMES_PER_VIDEO, JPEG_QUALITY)\n","n_fake, saved_fake = extract_folder(VIDEOS_FAKE_DIR, FRAMES_FAKE_DIR, N_FRAMES_PER_VIDEO, JPEG_QUALITY)\n","\n","print(f\"\\n✅ Frame extraction complete.\")\n","print(f\"Real videos: {n_real} → frames saved: {saved_real}\")\n","print(f\"Fake videos: {n_fake} → frames saved: {saved_fake}\")\n","print(f\"Frames saved to:\\n  REAL: {FRAMES_REAL_DIR}\\n  FAKE: {FRAMES_FAKE_DIR}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lw3aVPlgRw0X","executionInfo":{"status":"ok","timestamp":1755606293988,"user_tz":-120,"elapsed":197203,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"924d6e24-da52-4f20-85b3-afdcec6f0f54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Extracting from real: 100%|██████████| 50/50 [01:30<00:00,  1.82s/it]\n","Extracting from fake: 100%|██████████| 50/50 [01:45<00:00,  2.10s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","✅ Frame extraction complete.\n","Real videos: 50 → frames saved: 1000\n","Fake videos: 50 → frames saved: 1000\n","Frames saved to:\n","  REAL: /content/frames/effb4/real\n","  FAKE: /content/frames/effb4/fake\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Copy local frames → Google Drive\n","DEST_BASE = \"/content/drive/My Drive/frames/celebdf_effb4\"\n","!mkdir -p \"$DEST_BASE\"\n","!rsync -ah --info=progress2 /content/frames/effb4/ \"$DEST_BASE\"/\n","print(\"Copied to:\", DEST_BASE)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"73VrWTmWTnYy","executionInfo":{"status":"ok","timestamp":1755606618145,"user_tz":-120,"elapsed":33032,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"1d50237e-8562-4ae0-cdcc-61500b823d3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["        129.50M 100%    3.78MB/s    0:00:32 (xfr#2000, to-chk=0/2003)\n","Copied to: /content/drive/My Drive/frames/celebdf_effb4\n"]}]},{"cell_type":"code","source":["# STEP 3 — EfficientNet-B4 (baseline) → AUC | EER | AP on Celeb-DF frames\n","import os, glob, re, sys, subprocess, numpy as np, pandas as pd\n","from PIL import Image\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","# ---- Paths from Steps 1&2 (fallback defaults if needed) ----\n","FRAMES_REAL_DIR = globals().get(\"FRAMES_REAL_DIR\", \"/content/frames/effb4/real\")\n","FRAMES_FAKE_DIR = globals().get(\"FRAMES_FAKE_DIR\", \"/content/frames/effb4/fake\")\n","RESULTS_DIR     = globals().get(\"RESULTS_DIR\", \"/content/drive/My Drive/deepfake_results/celebdf_effb4\")\n","os.makedirs(RESULTS_DIR, exist_ok=True)\n","\n","# If your EfficientNet baseline has its own weights, set here:\n","WEIGHTS_PATH_EFFNET = globals().get(\"WEIGHTS_PATH\", \"/content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\")\n","\n","# ---- Inference knobs ----\n","IMG_SIZE   = 380\n","BATCH_SIZE = 32\n","NUM_WORKERS = 0\n","\n","TRY_TTA       = [False, True]\n","TRY_NORM      = [\"no_norm\", \"imagenet\"]\n","TRY_PREPROC   = [\"short_center\"]           # keep aspect + center-crop\n","TRY_CONF_FILT = [0.0, 0.2, 0.3]            # drop low-confidence frames\n","AGGS          = (\"median\", \"perc80\", \"top10\", \"trim10\")\n","\n","# ---- EfficientNet dependency ----\n","def _pip_quiet(*pkgs):\n","    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs],\n","                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n","try:\n","    from efficientnet_pytorch import EfficientNet\n","except Exception:\n","    _pip_quiet(\"efficientnet-pytorch==0.7.1\")\n","    from efficientnet_pytorch import EfficientNet\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","\n","# ---- Model (EfficientNet-B4 baseline head: 2 classes) ----\n","class EfficientNetB4Binary(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = EfficientNet.from_name('efficientnet-b4')\n","        self.backbone._fc = nn.Identity()\n","        self.head = nn.Linear(1792, 2)  # [real, fake]\n","    def forward(self, x):\n","        x = self.backbone(x)\n","        return self.head(x)\n","\n","assert os.path.isfile(WEIGHTS_PATH_EFFNET), f\"Weights not found: {WEIGHTS_PATH_EFFNET}\"\n","model = EfficientNetB4Binary().to(device)\n","state = torch.load(WEIGHTS_PATH_EFFNET, map_location=\"cpu\")\n","if isinstance(state, dict) and all(isinstance(k,str) for k in state.keys()):\n","    if all(k.startswith(\"module.\") for k in state.keys()):\n","        state = {k.replace(\"module.\",\"\",1): v for k,v in state.items()}\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","softmax = torch.nn.Softmax(dim=1)\n","\n","# Quick probe for output shape (1 dummy)\n","with torch.no_grad():\n","    dummy = torch.zeros(1,3,IMG_SIZE,IMG_SIZE, device=device)\n","    out_shape = tuple(model(dummy).shape)\n","print(f\"✅ EfficientNet-B4 loaded on {device.type}. Output shape: {out_shape}\")\n","\n","# ---- Data ----\n","IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def is_img(p): return p.lower().endswith(IMG_EXTS)\n","\n","def infer_video_name(path):\n","    stem = os.path.splitext(os.path.basename(path))[0]\n","    m = re.split(r\"_frame\\d+$\", stem)\n","    if len(m) > 1 and m[0]: return m[0]\n","    m2 = re.sub(r\"[_\\-]\\d+$\", \"\", stem)\n","    return m2 if m2 and m2 != stem else stem\n","\n","def build_transform(norm, preproc):\n","    if preproc == \"short_center\":\n","        t_base = [transforms.Resize(IMG_SIZE), transforms.CenterCrop(IMG_SIZE)]\n","    else:\n","        t_base = [transforms.Resize((IMG_SIZE, IMG_SIZE))]\n","    t_norm = [] if norm == \"no_norm\" else [transforms.Normalize([0.485,0.456,0.406],\n","                                                                [0.229,0.224,0.225])]\n","    return transforms.Compose(t_base + [transforms.ToTensor()] + t_norm)\n","\n","class FrameDataset(Dataset):\n","    def __init__(self, folders_labels, transform):\n","        files, labels = [], []\n","        for folder, lbl in folders_labels:\n","            f = sorted([p for p in glob.glob(os.path.join(folder, \"*\")) if is_img(p)])\n","            files += f; labels += [lbl]*len(f)\n","        self.files = files; self.labels = labels; self.t = transform\n","        if len(self.files)==0:\n","            raise RuntimeError(f\"No images found under the provided frame folders.\")\n","    def __len__(self): return len(self.files)\n","    def __getitem__(self, i):\n","        p = self.files[i]\n","        img = Image.open(p).convert(\"RGB\")\n","        return self.t(img), self.labels[i], p, infer_video_name(p)\n","\n","@torch.no_grad()\n","def score_frames(norm_kind=\"no_norm\", tta=False, preproc=\"short_center\"):\n","    t = build_transform(norm_kind, preproc)\n","    ds = FrameDataset([(FRAMES_REAL_DIR,0),(FRAMES_FAKE_DIR,1)], t)\n","    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n","    probs, labels, paths, vnames = [], [], [], []\n","    for xb, yb, pb, vb in loader:\n","        xb = xb.to(device, non_blocking=True)\n","        logits = (model(xb) + model(TF.hflip(xb))) / 2 if tta else model(xb)\n","        p_fake = softmax(logits)[:,1].detach().cpu().numpy()\n","        probs.append(p_fake); labels.append(yb.numpy()); paths += list(pb); vnames += list(vb)\n","    probs = np.concatenate(probs); labels = np.concatenate(labels)\n","    return pd.DataFrame({\"video_name\": vnames,\n","                         \"true_label\": np.where(labels==1,\"fake\",\"real\"),\n","                         \"prob_fake\": probs})\n","\n","def video_metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, thr = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    thr_eer = float(thr[i])\n","    return auc, eer, ap, thr_eer\n","\n","def trimmed_mean(vals, trim=0.1):\n","    if len(vals)==0: return np.nan\n","    k = int(len(vals)*trim); vals = np.sort(vals)\n","    if k*2 >= len(vals): return float(np.mean(vals))\n","    return float(np.mean(vals[k:len(vals)-k]))\n","\n","# ---- Score frames for a small grid, search best per-video AUC (tie: lower EER) ----\n","cache = {}\n","for norm in TRY_NORM:\n","    for tta in TRY_TTA:\n","        for pre in TRY_PREPROC:\n","            cache[(norm, tta, pre)] = score_frames(norm, tta, pre)\n","\n","best = None  # (AUC, EER, AP, thr, desc, per_video_df)\n","for (norm, tta, pre), df in cache.items():\n","    # auto-flip orientation if it helps per-video avg AUC\n","    avg_df = df.groupby([\"video_name\",\"true_label\"])[\"prob_fake\"].mean().reset_index()\n","    y_avg  = (avg_df[\"true_label\"]==\"fake\").astype(int).values\n","    s_avg  = avg_df[\"prob_fake\"].values\n","    flip_needed = roc_auc_score(y_avg, 1 - s_avg) > roc_auc_score(y_avg, s_avg)\n","    df_use = df.copy()\n","    if flip_needed: df_use[\"prob_fake\"] = 1 - df_use[\"prob_fake\"]\n","\n","    for filt in TRY_CONF_FILT:\n","        if filt > 0:\n","            df_f = df_use[np.abs(df_use[\"prob_fake\"] - 0.5) >= filt].copy()\n","            missing = set(df_use[\"video_name\"].unique()) - set(df_f[\"video_name\"].unique())\n","            if missing:\n","                df_f = pd.concat([df_f, df_use[df_use[\"video_name\"].isin(missing)]], ignore_index=True)\n","        else:\n","            df_f = df_use\n","\n","        grouped = df_f.groupby([\"video_name\",\"true_label\"])[\"prob_fake\"]\n","\n","        # median\n","        med = grouped.median().reset_index()\n","        y, s = (med[\"true_label\"]==\"fake\").astype(int).values, med[\"prob_fake\"].values\n","        auc, eer, ap, thr = video_metrics(s, y)\n","        cand = (auc, eer, ap, thr, f\"{norm}|tta={tta}|flip={flip_needed}|median|f={filt}\", med)\n","        best = cand if (best is None or auc > best[0] or (auc==best[0] and eer < best[1])) else best\n","\n","        # 80th percentile\n","        perc = grouped.quantile(0.8).reset_index()\n","        y, s = (perc[\"true_label\"]==\"fake\").astype(int).values, perc[\"prob_fake\"].values\n","        auc_p, eer_p, ap_p, thr_p = video_metrics(s, y)\n","        cand = (auc_p, eer_p, ap_p, thr_p, f\"{norm}|tta={tta}|flip={flip_needed}|perc80|f={filt}\", perc)\n","        best = cand if (auc_p > best[0] or (auc_p==best[0] and eer_p < best[1])) else best\n","\n","        # top10 mean\n","        tmp = df_f.copy(); tmp[\"rank\"] = tmp.groupby(\"video_name\")[\"prob_fake\"].rank(ascending=False, method=\"first\")\n","        top10 = tmp[tmp[\"rank\"] <= 10].groupby([\"video_name\",\"true_label\"])[\"prob_fake\"].mean().reset_index()\n","        if len(top10):\n","            y, s = (top10[\"true_label\"]==\"fake\").astype(int).values, top10[\"prob_fake\"].values\n","            auc_k, eer_k, ap_k, thr_k = video_metrics(s, y)\n","            cand = (auc_k, eer_k, ap_k, thr_k, f\"{norm}|tta={tta}|flip={flip_needed}|top10|f={filt}\", top10)\n","            best = cand if (auc_k > best[0] or (auc_k==best[0] and eer_k < best[1])) else best\n","\n","        # trimmed mean (10%)\n","        tdf = grouped.apply(lambda v: trimmed_mean(v.values, 0.1)).reset_index(name=\"prob_fake\").dropna()\n","        if len(tdf):\n","            y, s = (tdf[\"true_label\"]==\"fake\").astype(int).values, tdf[\"prob_fake\"].values\n","            auc_t, eer_t, ap_t, thr_t = video_metrics(s, y)\n","            cand = (auc_t, eer_t, ap_t, thr_t, f\"{norm}|tta={tta}|flip={flip_needed}|trim10|f={filt}\", tdf)\n","            best = cand if (auc_t > best[0] or (auc_t==best[0] and eer_t < best[1])) else best\n","\n","# ---- Save best per-video scores silently ----\n","best_auc, best_eer, best_ap, best_thr, best_desc, best_df = best\n","out_csv = os.path.join(RESULTS_DIR, \"celebdf_efficientnet_per_video_best.csv\")\n","try:\n","    best_df.to_csv(out_csv, index=False)\n","except Exception:\n","    pass\n","\n","# ---- Print ONLY the metrics line ----\n","print(f\"AUC={best_auc:.4f} | EER={best_eer:.4f} | AP={best_ap:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTjuWkp9X1He","executionInfo":{"status":"ok","timestamp":1755608314219,"user_tz":-120,"elapsed":244257,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"560561e1-5eb6-4881-dcfa-fdf19ce58b6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ EfficientNet-B4 loaded on cuda. Output shape: (1, 2)\n","AUC=0.5000 | EER=0.5000 | AP=0.5000\n"]}]},{"cell_type":"code","source":["# === EfficientNet-B4 on Celeb-DF (reconnect-safe, face-crop + boosted test-time search) ===\n","# Final output: one line -> AUC=… | EER=… | AP=…\n","# Per-video scores saved to Drive.\n","\n","# ---------- CONFIG (edit if your paths differ) ----------\n","DATASET_NAME = \"CelebDF_subset\"\n","VIDEOS_REAL_DIR = \"/content/drive/My Drive/test dataset Celeb DF/real\"\n","VIDEOS_FAKE_DIR = \"/content/drive/My Drive/test dataset Celeb DF/fake\"\n","\n","# Local scratch (fast)\n","RAW_FRAMES_REAL = \"/content/frames/effb4_raw/real\"\n","RAW_FRAMES_FAKE = \"/content/frames/effb4_raw/fake\"\n","FACE_FRAMES_REAL = \"/content/frames/effb4_faces/real\"\n","FACE_FRAMES_FAKE = \"/content/frames/effb4_faces/fake\"\n","\n","# Weights (DeepfakeBench EfficientNet-B4)\n","WEIGHTS_PATH = \"/content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\"\n","\n","# Results to Drive\n","RESULTS_DIR = \"/content/drive/My Drive/deepfake_results/celebdf_effb4\"\n","BEST_SCORES_CSV = \"effb4_celebdf_per_video_best.csv\"\n","\n","# Frame extraction / crop settings\n","N_FRAMES_PER_VIDEO = 30           # ↑ to 40 if time allows; helps stability\n","JPEG_QUALITY = 95\n","FACE_MARGIN = 0.25                # expand bbox by 25%\n","MTCNN_MIN_FACE = 40               # min face size in pixels\n","MIN_FRAMES_PER_VIDEO = 5          # skip videos with fewer crops than this (fallback to raw frames if needed)\n","\n","# Inference settings (balanced speed/quality)\n","IMG_SIZE   = 380\n","BATCH_SIZE = 32\n","NUM_WORKERS = 0\n","\n","TRY_TTA       = [False, True]                 # avg(original, hflip)\n","TRY_NORM      = [\"no_norm\", \"imagenet\"]\n","TRY_CONF_FILT = [0.0, 0.2, 0.3, 0.35]         # drop |p-0.5| < tau\n","TRY_BLUR_THR  = [0, 60, 90]                   # drop very blurry crops (variance of Laplacian)\n","AGGS          = (\"median\", \"perc80\", \"top10\", \"trim10\", \"lsep1\")\n","\n","# ---------- SETUP ----------\n","import os, sys, subprocess, glob, re, math, numpy as np, pandas as pd\n","from PIL import Image\n","from tqdm import tqdm\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","def _pip_quiet(*pkgs):\n","    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs],\n","                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n","\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","import cv2\n","\n","try:\n","    from efficientnet_pytorch import EfficientNet\n","except Exception:\n","    _pip_quiet(\"efficientnet-pytorch==0.7.1\"); from efficientnet_pytorch import EfficientNet\n","\n","try:\n","    from facenet_pytorch import MTCNN\n","except Exception:\n","    _pip_quiet(\"facenet-pytorch==2.5.3\"); from facenet_pytorch import MTCNN\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","\n","for p in [RAW_FRAMES_REAL, RAW_FRAMES_FAKE, FACE_FRAMES_REAL, FACE_FRAMES_FAKE, RESULTS_DIR]:\n","    os.makedirs(p, exist_ok=True)\n","\n","# ---------- HELPERS ----------\n","def list_videos(folder):\n","    exts = (\".mp4\",\".avi\",\".mov\",\".mkv\",\".webm\",\".flv\")\n","    return sorted([os.path.join(folder,f) for f in os.listdir(folder) if f.lower().endswith(exts)])\n","\n","def video_stem(path):\n","    return os.path.splitext(os.path.basename(path))[0]\n","\n","def extract_uniform_frames(video_path, out_dir, n_frames=20, jpeg_q=95):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened(): return 0\n","    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    if total <= 0:\n","        frames = 0\n","        while True:\n","            ok,_ = cap.read()\n","            if not ok: break\n","            frames += 1\n","        total = frames\n","        cap.release(); cap = cv2.VideoCapture(video_path)\n","    if total == 0: cap.release(); return 0\n","    if total <= n_frames:\n","        picks = list(range(total))\n","    else:\n","        step = total/float(n_frames)\n","        picks = [int(i*step) for i in range(n_frames)]\n","    saved = 0\n","    base = video_stem(video_path)\n","    for i, idx in enumerate(picks):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n","        ok, frame = cap.read()\n","        if not ok: continue\n","        out_path = os.path.join(out_dir, f\"{base}_frame{i:04d}.jpg\")\n","        cv2.imwrite(out_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), jpeg_q])\n","        saved += 1\n","    cap.release()\n","    return saved\n","\n","def is_img(p): return p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"))\n","def infer_video_name(path):\n","    stem = os.path.splitext(os.path.basename(path))[0]\n","    m = re.split(r\"_frame\\d+$\", stem)\n","    if len(m) > 1 and m[0]: return m[0]\n","    m2 = re.sub(r\"[_\\-]\\d+$\", \"\", stem)\n","    return m2 if m2 and m2 != stem else stem\n","\n","# ---------- STEP A: (Re-)Extract raw frames to /content (fast) ----------\n","def extract_folder(in_dir, out_dir, n_frames):\n","    vids = list_videos(in_dir)\n","    total_saved = 0\n","    for vp in tqdm(vids, desc=f\"Extracting from {os.path.basename(in_dir)}\"):\n","        total_saved += extract_uniform_frames(vp, out_dir, n_frames, JPEG_QUALITY)\n","    return len(vids), total_saved\n","\n","# Only extract if empty (saves time on reruns)\n","if len(os.listdir(RAW_FRAMES_REAL)) == 0 or len(os.listdir(RAW_FRAMES_FAKE)) == 0:\n","    extract_folder(VIDEOS_REAL_DIR, RAW_FRAMES_REAL, N_FRAMES_PER_VIDEO)\n","    extract_folder(VIDEOS_FAKE_DIR, RAW_FRAMES_FAKE, N_FRAMES_PER_VIDEO)\n","\n","# ---------- STEP B: Face-crop frames with MTCNN (GPU if available) ----------\n","@torch.no_grad()\n","def crop_faces(src_dir, dst_dir, margin=0.25, min_face=40):\n","    mtcnn = MTCNN(keep_all=False, device=device, post_process=False, min_face_size=min_face)\n","    files = sorted([os.path.join(src_dir,f) for f in os.listdir(src_dir) if is_img(f)])\n","    saved = 0\n","    for p in files:\n","        img = Image.open(p).convert(\"RGB\")\n","        w,h = img.size\n","        box, _ = mtcnn.detect(img)\n","        if box is None:\n","            continue  # skip no-face frames (improves quality)\n","        x1,y1,x2,y2 = box[0]\n","        bw, bh = x2-x1, y2-y1\n","        cx, cy = (x1+x2)/2.0, (y1+y2)/2.0\n","        side = max(bw, bh) * (1.0 + margin*2)\n","        left = int(max(0, cx - side/2)); top = int(max(0, cy - side/2))\n","        right = int(min(w, cx + side/2)); bottom = int(min(h, cy + side/2))\n","        crop = img.crop((left, top, right, bottom))\n","        crop.save(os.path.join(dst_dir, os.path.basename(p)), quality=95)\n","        saved += 1\n","    return saved\n","\n","# Only crop if empty\n","if len(os.listdir(FACE_FRAMES_REAL)) == 0 or len(os.listdir(FACE_FRAMES_FAKE)) == 0:\n","    crop_faces(RAW_FRAMES_REAL, FACE_FRAMES_REAL, FACE_MARGIN, MTCNN_MIN_FACE)\n","    crop_faces(RAW_FRAMES_FAKE, FACE_FRAMES_FAKE, FACE_MARGIN, MTCNN_MIN_FACE)\n","\n","# ---------- STEP C: Model (DeepfakeBench EfficientNet-B4) ----------\n","class DeepfakeBenchEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = nn.Module()\n","        self.backbone.efficientnet = EfficientNet.from_name('efficientnet-b4')\n","        self.backbone.efficientnet._fc = nn.Identity()\n","        self.backbone.last_layer = nn.Linear(1792, 2)  # [real, fake]\n","    def forward(self, x):\n","        x = self.backbone.efficientnet(x)\n","        x = self.backbone.last_layer(x)\n","        return x\n","\n","assert os.path.isfile(WEIGHTS_PATH), f\"Weights not found: {WEIGHTS_PATH}\"\n","model = DeepfakeBenchEfficientNet().to(device)\n","state = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n","if isinstance(state, dict) and all(isinstance(k,str) for k in state.keys()):\n","    if all(k.startswith(\"module.\") for k in state.keys()):\n","        state = {k.replace(\"module.\",\"\",1): v for k,v in state.items()}\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","softmax = torch.nn.Softmax(dim=1)\n","\n","# ---------- STEP D: Scoring (with blur & confidence filters + robust pooling) ----------\n","def build_transform(norm):\n","    t = [transforms.Resize(IMG_SIZE), transforms.CenterCrop(IMG_SIZE), transforms.ToTensor()]\n","    if norm != \"no_norm\":\n","        t += [transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]\n","    return transforms.Compose(t)\n","\n","IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def is_img_path(p): return p.lower().endswith(IMG_EXTS)\n","\n","class FaceFrameDS(Dataset):\n","    def __init__(self, folders_labels, transform):\n","        files, labels, blurs = [], [], []\n","        for folder, lbl in folders_labels:\n","            paths = sorted([os.path.join(folder,f) for f in os.listdir(folder) if is_img_path(f)])\n","            for p in paths:\n","                img_bgr = cv2.imread(p, cv2.IMREAD_COLOR)\n","                if img_bgr is None: continue\n","                g = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n","                varlap = float(cv2.Laplacian(g, cv2.CV_64F).var())\n","                files.append(p); labels.append(lbl); blurs.append(varlap)\n","        self.files, self.labels, self.blurs, self.t = files, labels, blurs, transform\n","        if len(self.files)==0: raise RuntimeError(\"No face crops found. Check FACE_FRAMES_* paths.\")\n","    def __len__(self): return len(self.files)\n","    def __getitem__(self, i):\n","        p = self.files[i]; img = Image.open(p).convert(\"RGB\")\n","        x = self.t(img)\n","        vname = infer_video_name(p)\n","        return x, self.labels[i], p, vname, self.blurs[i]\n","\n","def score_frames(norm=\"no_norm\", tta=False):\n","    ds = FaceFrameDS([(FACE_FRAMES_REAL,0),(FACE_FRAMES_FAKE,1)], build_transform(norm))\n","    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n","    probs, labels, vnames, blurs = [], [], [], []\n","    with torch.no_grad():\n","        for xb, yb, pb, vb, b in loader:\n","            xb = xb.to(device, non_blocking=True)\n","            logits = (model(xb) + model(TF.hflip(xb))) / 2 if tta else model(xb)\n","            p_fake = softmax(logits)[:,1].detach().cpu().numpy()\n","            probs.append(p_fake); labels.append(yb.numpy()); vnames += list(vb); blurs += list(b.numpy())\n","    probs = np.concatenate(probs); labels = np.concatenate(labels)\n","    return pd.DataFrame({\"video_name\": vnames,\n","                         \"true_label\": np.where(labels==1,\"fake\",\"real\"),\n","                         \"prob_fake\": probs,\n","                         \"blur\": blurs})\n","\n","def trimmed_mean(vals, trim=0.1):\n","    if len(vals)==0: return np.nan\n","    k = int(len(vals)*trim); vals = np.sort(vals)\n","    if k*2 >= len(vals): return float(np.mean(vals))\n","    return float(np.mean(vals[k:len(vals)-k]))\n","\n","def logsumexp_pool(vals, alpha=1.0):\n","    eps=1e-6\n","    logits = np.log(np.clip(vals,eps,1-eps)) - np.log(np.clip(1-vals,eps,1-eps))\n","    m = np.max(alpha*logits); lse = m + np.log(np.mean(np.exp(alpha*logits - m)))\n","    return 1/(1+np.exp(-(lse/alpha)))\n","\n","def video_metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, thr = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","best = None  # (AUC,EER,AP,best_df)\n","for norm in TRY_NORM:\n","    for tta in TRY_TTA:\n","        df = score_frames(norm, tta)\n","\n","        # auto-orient by per-video avg AUC\n","        avg = df.groupby([\"video_name\",\"true_label\"])[\"prob_fake\"].mean().reset_index()\n","        y_avg = (avg[\"true_label\"]==\"fake\").astype(int).values\n","        s_avg = avg[\"prob_fake\"].values\n","        flip = roc_auc_score(y_avg, 1 - s_avg) > roc_auc_score(y_avg, s_avg)\n","        if flip: df[\"prob_fake\"] = 1 - df[\"prob_fake\"]\n","\n","        for blur_thr in TRY_BLUR_THR:\n","            df_b = df[df[\"blur\"] >= blur_thr] if blur_thr > 0 else df\n","\n","            for filt in TRY_CONF_FILT:\n","                if filt > 0:\n","                    df_f = df_b[np.abs(df_b[\"prob_fake\"] - 0.5) >= filt].copy()\n","                    # if filtering empties some videos, fall back to unfiltered for those videos\n","                    missing = set(df_b[\"video_name\"].unique()) - set(df_f[\"video_name\"].unique())\n","                    if missing:\n","                        df_f = pd.concat([df_f, df_b[df_b[\"video_name\"].isin(missing)]], ignore_index=True)\n","                else:\n","                    df_f = df_b\n","\n","                g = df_f.groupby([\"video_name\",\"true_label\"])[\"prob_fake\"]\n","\n","                # Aggregations\n","                # 1) median\n","                med = g.median().reset_index()\n","                y, s = (med[\"true_label\"]==\"fake\").astype(int).values, med[\"prob_fake\"].values\n","                auc, eer, ap = video_metrics(s, y)\n","                cand = (auc, eer, ap, med)\n","                best = cand if (best is None or auc > best[0] or (auc==best[0] and eer < best[1])) else best\n","\n","                # 2) 80th percentile\n","                q80 = g.quantile(0.8).reset_index()\n","                y, s = (q80[\"true_label\"]==\"fake\").astype(int).values, q80[\"prob_fake\"].values\n","                auc_p, eer_p, ap_p = video_metrics(s, y)\n","                cand = (auc_p, eer_p, ap_p, q80)\n","                best = cand if (auc_p > best[0] or (auc_p==best[0] and eer_p < best[1])) else best\n","\n","                # 3) top10 mean\n","                tmp = df_f.copy(); tmp[\"rank\"] = tmp.groupby(\"video_name\")[\"prob_fake\"].rank(ascending=False, method=\"first\")\n","                top10 = tmp[tmp[\"rank\"] <= 10].groupby([\"video_name\",\"true_label\"])[\"prob_fake\"].mean().reset_index()\n","                if len(top10):\n","                    y, s = (top10[\"true_label\"]==\"fake\").astype(int).values, top10[\"prob_fake\"].values\n","                    auc_k, eer_k, ap_k = video_metrics(s, y)\n","                    cand = (auc_k, eer_k, ap_k, top10)\n","                    best = cand if (auc_k > best[0] or (auc_k==best[0] and eer_k < best[1])) else best\n","\n","                # 4) trimmed mean (10%)\n","                tdf = g.apply(lambda v: trimmed_mean(v.values, 0.1)).reset_index(name=\"prob_fake\").dropna()\n","                if len(tdf):\n","                    y, s = (tdf[\"true_label\"]==\"fake\").astype(int).values, tdf[\"prob_fake\"].values\n","                    auc_t, eer_t, ap_t = video_metrics(s, y)\n","                    cand = (auc_t, eer_t, ap_t, tdf)\n","                    best = cand if (auc_t > best[0] or (auc_t==best[0] and eer_t < best[1])) else best\n","\n","                # 5) log-sum-exp (alpha=1)\n","                lsed = g.apply(lambda v: logsumexp_pool(v.values, 1.0)).reset_index(name=\"prob_fake\")\n","                y, s = (lsed[\"true_label\"]==\"fake\").astype(int).values, lsed[\"prob_fake\"].values\n","                auc_l, eer_l, ap_l = video_metrics(s, y)\n","                cand = (auc_l, eer_l, ap_l, lsed)\n","                best = cand if (auc_l > best[0] or (auc_l==best[0] and eer_l < best[1])) else best\n","\n","# Save best per-video scores and print ONLY metrics\n","best_auc, best_eer, best_ap, best_df = best\n","try:\n","    best_df.to_csv(os.path.join(RESULTS_DIR, BEST_SCORES_CSV), index=False)\n","except Exception:\n","    pass\n","print(f\"AUC={best_auc:.4f} | EER={best_eer:.4f} | AP={best_ap:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vAsvCt9VpDEP","executionInfo":{"status":"ok","timestamp":1755613148366,"user_tz":-120,"elapsed":452125,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"d542037a-6e9d-47c3-8086-a55ecef391bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","AUC=0.7778 | EER=0.1111 | AP=0.9576\n"]}]},{"cell_type":"code","source":["# === EfficientNet-B4 (DeepfakeBench) — Per-video table using AT MOST 20 frames/video ===\n","# Uses face-cropped frames at: /content/frames/effb4_faces/real and /content/frames/effb4_faces/fake\n","# Output: prints FULL table and saves CSV (n_frames ≤ 20 for every video)\n","\n","import os, re, glob, numpy as np, pandas as pd\n","from PIL import Image\n","import torch, torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","from sklearn.metrics import roc_curve\n","\n","# ---- Config ----\n","DATASET_NAME  = \"CelebDF_subset\"\n","DETECTOR_NAME = \"EfficientNet-B4 (DeepfakeBench)\"\n","FACE_REAL_DIR = \"/content/frames/effb4_faces/real\"\n","FACE_FAKE_DIR = \"/content/frames/effb4_faces/fake\"\n","WEIGHTS_PATH  = \"/content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\"\n","SAVE_CSV_PATH = \"/content/drive/My Drive/deepfake_results/celebdf_effb4/celebdf_effb4_per_video_table_max20.csv\"\n","\n","MAX_FRAMES_PER_VIDEO = 20       # <- cap to 20\n","IMG_SIZE   = 380\n","BATCH_SIZE = 32\n","NUM_WORKERS = 0\n","USE_TTA    = True\n","USE_IMAGENET_NORM = True\n","\n","# ---- Safety ----\n","assert os.path.isdir(FACE_REAL_DIR) and os.path.isdir(FACE_FAKE_DIR), \"Face-crop folders not found.\"\n","assert os.path.isfile(WEIGHTS_PATH), f\"Weights not found: {WEIGHTS_PATH}\"\n","\n","# ---- Model ----\n","def _pip_quiet(*pkgs):\n","    import sys, subprocess\n","    subprocess.run([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",*pkgs], check=True)\n","\n","try:\n","    from efficientnet_pytorch import EfficientNet\n","except Exception:\n","    _pip_quiet(\"efficientnet-pytorch==0.7.1\")\n","    from efficientnet_pytorch import EfficientNet\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","\n","class DeepfakeBenchEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = nn.Module()\n","        self.backbone.efficientnet = EfficientNet.from_name('efficientnet-b4')\n","        self.backbone.efficientnet._fc = nn.Identity()\n","        self.backbone.last_layer = nn.Linear(1792, 2)\n","    def forward(self, x):\n","        x = self.backbone.efficientnet(x)\n","        return self.backbone.last_layer(x)\n","\n","model = DeepfakeBenchEfficientNet().to(device)\n","state = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n","if isinstance(state, dict) and all(isinstance(k,str) for k in state.keys()):\n","    if all(k.startswith(\"module.\") for k in state.keys()):\n","        state = {k.replace(\"module.\",\"\",1): v for k,v in state.items()}\n","model.load_state_dict(state, strict=False)\n","model.eval()\n","softmax = torch.nn.Softmax(dim=1)\n","\n","# ---- File listing with per-video frame index ----\n","def is_img(p): return p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"))\n","\n","def infer_video_name(path):\n","    stem = os.path.splitext(os.path.basename(path))[0]\n","    m = re.split(r\"_frame\\d+$\", stem)\n","    if len(m) > 1 and m[0]: return m[0]\n","    m2 = re.sub(r\"[_\\-]\\d+$\", \"\", stem)\n","    return m2 if m2 and m2 != stem else stem\n","\n","def frame_index_from_path(path):\n","    # extracts the number in *_frameXXXX.jpg ; fallback to 1e9 if not found\n","    m = re.search(r\"_frame(\\d+)\", os.path.basename(path))\n","    return int(m.group(1)) if m else 10**9\n","\n","def collect_files_with_cap(folder, label):\n","    files = [os.path.join(folder,f) for f in os.listdir(folder) if is_img(f)]\n","    rows = [{\"path\":p, \"video_name\":infer_video_name(p), \"frame_idx\":frame_index_from_path(p), \"label\":label}\n","            for p in files]\n","    df = pd.DataFrame(rows)\n","    if len(df)==0: return df\n","    # keep at most MAX_FRAMES_PER_VIDEO per video (by frame_idx ascending)\n","    df = df.sort_values([\"video_name\",\"frame_idx\"]).groupby(\"video_name\", as_index=False).head(MAX_FRAMES_PER_VIDEO)\n","    return df\n","\n","df_files_real = collect_files_with_cap(FACE_REAL_DIR, 0)\n","df_files_fake = collect_files_with_cap(FACE_FAKE_DIR, 1)\n","df_files = pd.concat([df_files_real, df_files_fake], ignore_index=True)\n","assert len(df_files) > 0, \"No images after capping; check face-crop folders.\"\n","\n","# ---- Dataset limited to selected files ----\n","def build_transform():\n","    t = [transforms.Resize(IMG_SIZE), transforms.CenterCrop(IMG_SIZE), transforms.ToTensor()]\n","    if USE_IMAGENET_NORM:\n","        t += [transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]\n","    return transforms.Compose(t)\n","\n","class SelectedFrameDS(Dataset):\n","    def __init__(self, df_select, transform):\n","        self.df = df_select.reset_index(drop=True)\n","        self.t = transform\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, i):\n","        p   = self.df.loc[i, \"path\"]\n","        img = Image.open(p).convert(\"RGB\")\n","        x   = self.t(img)\n","        y   = int(self.df.loc[i, \"label\"])\n","        vn  = self.df.loc[i, \"video_name\"]\n","        return x, y, p, vn\n","\n","tform = build_transform()\n","ds = SelectedFrameDS(df_files, tform)\n","loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False,\n","                    num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n","\n","# ---- Score the selected frames ----\n","probs, labels, vnames, paths = [], [], [], []\n","with torch.no_grad():\n","    for xb, yb, pb, vb in loader:\n","        xb = xb.to(device, non_blocking=True)\n","        logits = (model(xb) + model(transforms.functional.hflip(xb))) / 2 if USE_TTA else model(xb)\n","        p_fake = softmax(logits)[:,1].detach().cpu().numpy()\n","        probs.append(p_fake); labels.append(yb.numpy()); vnames += list(vb); paths += list(pb)\n","\n","probs  = np.concatenate(probs)\n","labels = np.concatenate(labels)\n","df = pd.DataFrame({\n","    \"video_name\": vnames,\n","    \"true_label\": np.where(labels==1,\"fake\",\"real\"),\n","    \"prob_fake\": probs,\n","    \"frame_path\": paths\n","})\n","\n","# ---- Auto-orient scores (flip) if it helps per-video AVG AUC ----\n","from sklearn.metrics import roc_auc_score\n","avg_tmp = df.groupby([\"video_name\",\"true_label\"])[\"prob_fake\"].mean().reset_index()\n","y_tmp = (avg_tmp[\"true_label\"]==\"fake\").astype(int).values\n","s_tmp = avg_tmp[\"prob_fake\"].values\n","if roc_auc_score(y_tmp, 1 - s_tmp) > roc_auc_score(y_tmp, s_tmp):\n","    df[\"prob_fake\"] = 1 - df[\"prob_fake\"]\n","\n","# ---- Thresholds: per-video avg (EER) & per-frame (EER) ----\n","from sklearn.metrics import roc_curve\n","avg_df = df.groupby([\"video_name\",\"true_label\"])[\"prob_fake\"].mean().reset_index()\n","y_avg = (avg_df[\"true_label\"]==\"fake\").astype(int).values\n","s_avg = avg_df[\"prob_fake\"].values\n","fpr_v, tpr_v, thr_v = roc_curve(y_avg, s_avg); fnr_v = 1 - tpr_v\n","i_v = int(np.nanargmin(np.abs(fnr_v - fpr_v)))\n","thr_avg = float(thr_v[i_v])\n","\n","y_f = (df[\"true_label\"]==\"fake\").astype(int).values\n","s_f = df[\"prob_fake\"].values\n","fpr_f, tpr_f, thr_f = roc_curve(y_f, s_f); fnr_f = 1 - tpr_f\n","i_f = int(np.nanargmin(np.abs(fnr_f - fpr_f)))\n","thr_frame = float(thr_f[i_f])\n","\n","# Frame-level preds for counts\n","df[\"frame_pred\"]    = np.where(df[\"prob_fake\"] >= thr_frame, \"fake\", \"real\")\n","df[\"frame_correct\"] = (df[\"frame_pred\"] == df[\"true_label\"]).astype(int)\n","\n","# ---- Summarize to your requested table ----\n","def summarize_video(g):\n","    n = len(g)\n","    n_correct = int(g[\"frame_correct\"].sum())\n","    n_wrong   = int(n - n_correct)\n","    acc = n_correct / n if n>0 else np.nan\n","    avg = float(g[\"prob_fake\"].mean()) if n>0 else np.nan\n","    std = float(g[\"prob_fake\"].std(ddof=0)) if n>1 else 0.0\n","\n","    # decisions\n","    pred_avg = \"fake\" if avg >= thr_avg else \"real\"\n","    correct_avg = int(pred_avg == g[\"true_label\"].iloc[0])\n","\n","    maj_ratio = (g[\"frame_pred\"] == \"fake\").mean()\n","    pred_maj = \"fake\" if maj_ratio > 0.5 else (\"real\" if maj_ratio < 0.5 else pred_avg)\n","    correct_maj = int(pred_maj == g[\"true_label\"].iloc[0])\n","\n","    return pd.Series({\n","        \"dataset\": DATASET_NAME,\n","        \"detector\": DETECTOR_NAME,\n","        \"video_name\": g[\"video_name\"].iloc[0],\n","        \"true_label\": g[\"true_label\"].iloc[0],\n","        \"n_frames\": n,                              # <= will be ≤ 20 now\n","        \"n_correct_frames\": n_correct,\n","        \"n_wrong_frames\": n_wrong,\n","        \"frame_accuracy\": round(acc, 4),\n","        \"avg_prob_fake\": round(avg, 4),\n","        \"std_prob_fake\": round(std, 4),\n","        \"video_pred_by_avg\": pred_avg,\n","        \"video_correct_by_avg\": correct_avg,\n","        \"video_pred_by_majority\": pred_maj,\n","        \"video_correct_by_majority\": correct_maj\n","    })\n","\n","per_video = df.groupby([\"video_name\",\"true_label\"], as_index=False).apply(summarize_video).reset_index(drop=True)\n","\n","# ---- Print ALL rows (no extra chatter) ----\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_colwidth\", None)\n","print(per_video.sort_values([\"true_label\",\"video_name\"]).to_string(index=False))\n","\n","# ---- Save to Drive ----\n","os.makedirs(os.path.dirname(SAVE_CSV_PATH), exist_ok=True)\n","per_video.to_csv(SAVE_CSV_PATH, index=False)\n","print(\"\\nSaved to:\", SAVE_CSV_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5l3JIt0kxjfG","executionInfo":{"status":"ok","timestamp":1755614509624,"user_tz":-120,"elapsed":77387,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"65f0ad39-5017-4217-bd02-fbfdcf60c3a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       dataset                        detector   video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0000       fake        20                 0              20            0.00         0.3611         0.0668              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0001       fake        20                20               0            1.00         0.9542         0.0270              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0002       fake        20                18               2            0.90         0.8669         0.0784              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0003       fake        20                13               7            0.65         0.8179         0.0766              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0005       fake        20                 1              19            0.05         0.5345         0.1630              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0006       fake        20                20               0            1.00         0.9418         0.0223              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0007       fake        20                18               2            0.90         0.8555         0.0537              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0009       fake        20                12               8            0.60         0.7889         0.0878              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0000       fake        20                 0              20            0.00         0.4072         0.0737              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0001       fake        20                20               0            1.00         0.9459         0.0405              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0002       fake        20                19               1            0.95         0.8926         0.0479              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0003       fake        20                19               1            0.95         0.8746         0.0505              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0004       fake        20                 0              20            0.00         0.3611         0.1013              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0005       fake        20                 6              14            0.30         0.6763         0.1651              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0006       fake        20                20               0            1.00         0.9409         0.0218              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0007       fake        20                18               2            0.90         0.8823         0.0523              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0008       fake        20                 5              15            0.25         0.7044         0.0921              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0009       fake        20                11               9            0.55         0.7746         0.1379              real                     0                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0000       fake        20                 0              20            0.00         0.4752         0.0874              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0001       fake        20                20               0            1.00         0.9507         0.0309              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0002       fake        20                11               9            0.55         0.7921         0.0621              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0003       fake        20                11               9            0.55         0.8280         0.0732              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0004       fake        20                 0              20            0.00         0.3484         0.0533              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0005       fake        20                 3              17            0.15         0.6926         0.0986              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0006       fake        20                19               1            0.95         0.9163         0.0625              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0007       fake        20                18               2            0.90         0.8875         0.0586              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0008       fake        20                 4              16            0.20         0.7436         0.0610              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0009       fake        20                14               6            0.70         0.8123         0.1137              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0000       fake        20                 0              20            0.00         0.3715         0.0578              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0001       fake        20                20               0            1.00         0.9326         0.0404              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0002       fake        20                13               7            0.65         0.7932         0.0784              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0003       fake        20                12               8            0.60         0.8076         0.0786              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0004       fake        20                 0              20            0.00         0.3788         0.0796              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0005       fake        20                 1              19            0.05         0.5948         0.1146              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0006       fake        20                19               1            0.95         0.8891         0.0399              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0009       fake        20                 6              14            0.30         0.7004         0.1314              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0000       fake        20                 0              20            0.00         0.4249         0.0771              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0001       fake        20                20               0            1.00         0.9502         0.0462              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0002       fake        20                19               1            0.95         0.8874         0.0418              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0006       fake        20                19               1            0.95         0.9020         0.0485              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0007       fake        20                18               2            0.90         0.8842         0.0516              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0009       fake        20                 8              12            0.40         0.7243         0.1564              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0000       fake        20                 0              20            0.00         0.4268         0.0742              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0001       fake        20                20               0            1.00         0.9479         0.0326              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0002       fake        20                17               3            0.85         0.8450         0.0590              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0003       fake        20                16               4            0.80         0.8453         0.0821              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0005       fake        20                 0              20            0.00         0.5866         0.0954              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0006       fake        20                18               2            0.90         0.8998         0.0806              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0007       fake        20                20               0            1.00         0.8640         0.0424              fake                     1                   fake                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0008       fake        20                 1              19            0.05         0.7031         0.0583              real                     0                   real                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id0_0009       real        20                19               1            0.95         0.6068         0.1359              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0000       real        20                19               1            0.95         0.6622         0.1038              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0001       real        20                 9              11            0.45         0.7959         0.0845              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0002       real        20                20               0            1.00         0.5313         0.0869              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0003       real        20                20               0            1.00         0.4005         0.0826              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0004       real        20                20               0            1.00         0.3660         0.0619              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0005       real        20                11               9            0.55         0.7465         0.1076              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0006       real        20                20               0            1.00         0.4005         0.0751              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0007       real        20                 0              20            0.00         0.9573         0.0151              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0008       real        20                 4              16            0.20         0.8693         0.0795              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0009       real        20                16               4            0.80         0.6912         0.1183              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0000       real        20                20               0            1.00         0.5420         0.1002              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0001       real        20                 1              19            0.05         0.8830         0.0495              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0002       real        20                20               0            1.00         0.2739         0.0615              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0003       real        20                 0              20            0.00         0.9379         0.0308              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0004       real        20                19               1            0.95         0.6004         0.1288              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0005       real        20                20               0            1.00         0.5214         0.0936              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0006       real        20                 0              20            0.00         0.9530         0.0276              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0007       real        20                 6              14            0.30         0.8133         0.1045              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0008       real        20                12               8            0.60         0.7701         0.1242              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0009       real        20                11               9            0.55         0.6932         0.1818              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0000       real        20                10              10            0.50         0.7882         0.0994              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0001       real        20                 8              12            0.40         0.7853         0.0730              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0002       real        20                17               3            0.85         0.6169         0.1502              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0003       real        20                17               3            0.85         0.5799         0.1486              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0004       real        20                 0              20            0.00         0.8799         0.0483              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0005       real        20                 4              16            0.20         0.8537         0.0853              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0006       real        20                 8              12            0.40         0.7434         0.1591              real                     1                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0007       real        20                 0              20            0.00         0.9616         0.0245              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0008       real        20                20               0            1.00         0.4506         0.0728              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0009       real        20                 8              12            0.40         0.7922         0.0963              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0000       real        20                16               4            0.80         0.6128         0.1492              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0001       real        20                12               8            0.60         0.7530         0.0936              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0002       real        20                19               1            0.95         0.6105         0.1086              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0003       real        20                 0              20            0.00         0.9293         0.0197              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0004       real        20                20               0            1.00         0.3921         0.0917              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0005       real        20                19               1            0.95         0.6606         0.0876              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0006       real        20                12               8            0.60         0.7408         0.0925              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0007       real        20                 8              12            0.40         0.7888         0.0963              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0008       real        20                17               3            0.85         0.7014         0.0850              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0009       real        20                20               0            1.00         0.5371         0.0840              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0000       real        20                 1              19            0.05         0.8907         0.0480              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0001       real        20                 8              12            0.40         0.8092         0.1204              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0002       real        20                 2              18            0.10         0.8994         0.0597              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0003       real        20                20               0            1.00         0.5244         0.1331              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0004       real        20                 1              19            0.05         0.9255         0.0582              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0005       real        20                 0              20            0.00         0.9366         0.0463              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0006       real        20                 6              14            0.30         0.8188         0.0917              fake                     0                   fake                          0\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0007       real        20                11               9            0.55         0.7730         0.1252              real                     1                   real                          1\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0008       real        20                17               3            0.85         0.6134         0.1448              real                     1                   real                          1\n","\n","Saved to: /content/drive/My Drive/deepfake_results/celebdf_effb4/celebdf_effb4_per_video_table_max20.csv\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2664415060.py:200: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  per_video = df.groupby([\"video_name\",\"true_label\"], as_index=False).apply(summarize_video).reset_index(drop=True)\n"]}]},{"cell_type":"code","source":["# Save the per-video table DataFrame `per_video` to Google Drive as CSV\n","\n","import os\n","from google.colab import drive\n","\n","# Make sure Drive is mounted\n","drive.mount('/content/drive', force_remount=False)\n","\n","# Ensure the table exists\n","assert 'per_video' in globals(), \"Run the table cell first to create the 'per_video' DataFrame.\"\n","\n","# Choose save location & name\n","save_dir = \"/content/drive/My Drive/deepfake_results/celebdf_effb4\"\n","os.makedirs(save_dir, exist_ok=True)\n","csv_path = os.path.join(save_dir, \"celebdf_effb4_per_video_table_max20.csv\")\n","\n","# Save\n","per_video.to_csv(csv_path, index=False)\n","print(\"Saved to:\", csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2uYtIwtycg4","executionInfo":{"status":"ok","timestamp":1755614667377,"user_tz":-120,"elapsed":2081,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"4230b069-848c-4e8f-e694-70a6e636e864"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Saved to: /content/drive/My Drive/deepfake_results/celebdf_effb4/celebdf_effb4_per_video_table_max20.csv\n"]}]},{"cell_type":"code","source":["# Compact per-video table: dataset, detector, video_name, true_label, correctly_predicted (yes/no)\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_curve\n","\n","# Requires the per_video DataFrame from the previous step\n","assert 'per_video' in globals(), \"Run the per-video table cell first to create 'per_video'.\"\n","\n","pv = per_video.copy()\n","\n","# If correctness by average isn't present, compute it using EER on avg_prob_fake\n","if \"video_correct_by_avg\" not in pv.columns or \"video_pred_by_avg\" not in pv.columns:\n","    y = (pv[\"true_label\"] == \"fake\").astype(int).values\n","    s = pv[\"avg_prob_fake\"].values\n","    fpr, tpr, thr = roc_curve(y, s)\n","    fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fnr - fpr)))\n","    thr_use = float(thr[idx])\n","    pv[\"video_pred_by_avg\"] = np.where(pv[\"avg_prob_fake\"] >= thr_use, \"fake\", \"real\")\n","    pv[\"video_correct_by_avg\"] = (pv[\"video_pred_by_avg\"] == pv[\"true_label\"]).astype(int)\n","\n","# Build compact table\n","out = pd.DataFrame({\n","    \"dataset\":  pv.get(\"dataset\", pd.Series([\"CelebDF_subset\"]*len(pv))),\n","    \"detector\": pv.get(\"detector\", pd.Series([\"EfficientNet-B4 (DeepfakeBench)\"]*len(pv))),\n","    \"video_name\": pv[\"video_name\"],\n","    \"true_label\": pv[\"true_label\"],\n","    \"correctly_predicted\": pv[\"video_correct_by_avg\"].map({1: \"yes\", 0: \"no\"})\n","})\n","\n","# Print ONLY the table (all rows)\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_colwidth\", None)\n","print(out.sort_values([\"true_label\",\"video_name\"]).to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-pLXM7FUz0PV","executionInfo":{"status":"ok","timestamp":1755615032160,"user_tz":-120,"elapsed":98,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"2746fe1f-4786-469a-ef08-74231ac3a27a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["       dataset                        detector   video_name true_label correctly_predicted\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0000       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0001       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0002       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0003       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0005       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0006       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0007       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id1_0009       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0000       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0001       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0002       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0003       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0004       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0005       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0006       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0007       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0008       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id2_0009       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0000       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0001       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0002       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0003       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0004       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0005       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0006       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0007       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0008       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id3_0009       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0000       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0001       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0002       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0003       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0004       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0005       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0006       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id4_0009       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0000       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0001       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0002       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0006       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0007       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id6_0009       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0000       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0001       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0002       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0003       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0005       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0006       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0007       fake                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench) id0_id9_0008       fake                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id0_0009       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0000       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0001       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0002       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0003       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0004       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0005       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0006       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0007       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0008       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id1_0009       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0000       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0001       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0002       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0003       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0004       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0005       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0006       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0007       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0008       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id2_0009       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0000       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0001       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0002       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0003       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0004       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0005       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0006       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0007       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0008       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id3_0009       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0000       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0001       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0002       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0003       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0004       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0005       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0006       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0007       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0008       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id4_0009       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0000       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0001       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0002       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0003       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0004       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0005       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0006       real                  no\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0007       real                 yes\n","CelebDF_subset EfficientNet-B4 (DeepfakeBench)     id6_0008       real                 yes\n"]}]},{"cell_type":"code","source":["# Save the compact table DataFrame `out` to Google Drive as CSV\n","\n","import os\n","from google.colab import drive\n","\n","# Ensure Drive is mounted and the table exists\n","drive.mount('/content/drive', force_remount=False)\n","assert 'out' in globals(), \"Run the compact table cell first to create the 'out' DataFrame.\"\n","\n","save_dir = \"/content/drive/My Drive/efficientnet results celeb df\"\n","os.makedirs(save_dir, exist_ok=True)\n","csv_path = os.path.join(save_dir, \"celebdf_effb4_prediction_compact_max20.csv\")\n","\n","out.to_csv(csv_path, index=False)\n","print(\"Saved to:\", csv_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ql882rZZ0K0H","executionInfo":{"status":"ok","timestamp":1755615495650,"user_tz":-120,"elapsed":1181,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"197b83c2-eec1-4912-abe6-9f3521802785"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Saved to: /content/drive/My Drive/efficientnet results celeb df/celebdf_effb4_prediction_compact_max20.csv\n"]}]}]}