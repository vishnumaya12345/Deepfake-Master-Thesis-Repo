{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNqVqNuRtcLQMKXOP2FWs5Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nmmn6SqKTxmY","executionInfo":{"status":"ok","timestamp":1762000084564,"user_tz":-60,"elapsed":1025856,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"74f30cd6-aa9c-43e9-91f9-468d68bd64ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","AUC: 0.7240\n","EER: 0.3300\n","AP : 0.7071\n"]}],"source":["# === FFD on frames_cropped_faces_1src — PRINT ONLY AUC, EER, AP (video-level) ===\n","# Recipe: exact 20 frames/video; load @320 → center-5-crop(299); {272→299,299} × hflip TTA;\n","#         mild photometric TTAs; quick BN-only TENT; quality-weighted aggregations;\n","#         auto 1−p polarity + temperature sweep; ONLY print matrices.\n","\n","import os, re, glob, io, contextlib, warnings, math\n","warnings.filterwarnings(\"ignore\")\n","silent = contextlib.redirect_stdout(io.StringIO()); silent_err = contextlib.redirect_stderr(io.StringIO())\n","\n","# --- Mount Drive ---\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# --- Imports (quiet where useful) ---\n","import numpy as np\n","from PIL import Image\n","with silent, silent_err:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","    import timm\n","\n","# --- Paths ---\n","DRIVE_ROOT  = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","DATA_ROOT   = os.path.join(DRIVE_ROOT, \"frames_cropped_faces_1src\")  # {real,fake}\n","WEIGHT_PATH = os.path.join(DRIVE_ROOT, \"DeepfakeBench_weights\", \"ffd_best.pth\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.set_num_threads(2)\n","\n","# --- Image utils (no torchvision) ---\n","IM_MEAN = torch.tensor([0.485,0.456,0.406]).view(1,3,1,1)\n","IM_STD  = torch.tensor([0.229,0.224,0.225]).view(1,3,1,1)\n","def pil_to_tensor(img: Image.Image, size: int):\n","    if img.mode != \"RGB\": img = img.convert(\"RGB\")\n","    if img.size != (size, size): img = img.resize((size, size), Image.BILINEAR)\n","    x = np.asarray(img, dtype=np.float32) / 255.0\n","    x = torch.from_numpy(x.transpose(2,0,1)).unsqueeze(0)  # 1x3xHxW\n","    return ((x - IM_MEAN) / IM_STD).squeeze(0)             # 3xHxW\n","\n","# --- Exact 20 frames/video selection ---\n","FNUM = re.compile(r\".*?[_-]frame[s]?[_-]?(\\d+)\\D*$\", re.IGNORECASE)\n","VKEY = re.compile(r\"^(.*?)(?:[_-]frames?[_-]?\\d+|[_-]frame[_-]?\\d+)$\", re.IGNORECASE)\n","def vkey(name):\n","    base = os.path.splitext(name)[0]; m = VKEY.match(base)\n","    return m.group(1) if m else base.split(\"_\")[0]\n","def num_suffix(p):\n","    m = FNUM.match(os.path.splitext(os.path.basename(p))[0])\n","    return int(m.group(1)) if m else None\n","def list_exact20(root):\n","    exts={\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\",\".JPG\",\".JPEG\",\".PNG\"}\n","    allp=[]\n","    for cls,y in ((\"real\",0),(\"fake\",1)):\n","        d=os.path.join(root,cls)\n","        if not os.path.isdir(d): continue\n","        for p in glob.glob(os.path.join(d,\"*\")):\n","            if os.path.splitext(p)[1] in exts: allp.append((p,y,vkey(os.path.basename(p))))\n","    if not allp: raise RuntimeError(f\"No images under {root}/{{real,fake}}\")\n","    vids={}\n","    for p,y,k in allp:\n","        vids.setdefault(k,{\"y\":y,\"paths\":[]}); vids[k][\"paths\"].append(p)\n","    kept=[]\n","    for k,info in vids.items():\n","        ps=info[\"paths\"]; nums=[num_suffix(p) for p in ps]\n","        if any(n is not None for n in nums):\n","            prs=sorted([(n if n is not None else 10**9,p) for n,p in zip(nums,ps)], key=lambda x:(x[0],x[1]))\n","            ps_sorted=[p for _,p in prs]\n","        else:\n","            ps_sorted=sorted(ps)\n","        if len(ps_sorted)<20: ps_sorted = ps_sorted + [ps_sorted[0]]*(20-len(ps_sorted))\n","        else:                 ps_sorted = ps_sorted[:20]\n","        for p in ps_sorted: kept.append((p, info[\"y\"], k))\n","    kept.sort(key=lambda x:(x[1],x[2],x[0])); return kept\n","\n","# --- Dataset / collate ---\n","class FramesDS(Dataset):\n","    def __init__(self, trip): self.s=trip\n","    def __len__(self): return len(self.s)\n","    def __getitem__(self,i):\n","        p,y,k=self.s[i]\n","        with Image.open(p) as im: x=pil_to_tensor(im, 320)\n","        return x,y,k\n","def collate(b): xs,ys,ks=zip(*b); return torch.stack(xs,0), torch.tensor(ys), list(ks)\n","\n","def center_five_crops(x320):  # -> list of (B,3,299,299)\n","    B,_,H,W=x320.shape\n","    offs=[(0,0),(0,W-299),(H-299,0),(H-299,W-299),((H-299)//2,(W-299)//2)]\n","    return [x320[:,:,oy:oy+299, ox:ox+299] for (oy,ox) in offs]\n","\n","# --- FFD backbone (timm Xception) ---\n","class FFDModel(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        with silent, silent_err:\n","            self.net = timm.create_model(\"xception41\", pretrained=False, num_classes=num_classes, in_chans=3)\n","        self.softmax = nn.Softmax(dim=1)\n","    def forward(self, x): return self.net(x)\n","\n","def try_load_weights(model, path):\n","    if not os.path.isfile(path): return False\n","    try:\n","        with silent, silent_err:\n","            sd=torch.load(path, map_location=\"cpu\")\n","        if isinstance(sd,dict) and \"state_dict\" in sd: sd=sd[\"state_dict\"]\n","        new={}\n","        for k,v in (sd.items() if isinstance(sd,dict) else []):\n","            nk=k\n","            for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\"):\n","                if nk.startswith(pref): nk=nk[len(pref):]\n","            new[nk]=v\n","        with silent, silent_err:\n","            model.load_state_dict(new, strict=False)\n","        return True\n","    except Exception:\n","        return False\n","\n","# --- Quality measures & photometric transforms ---\n","def unnorm(x): return (x*IM_STD.to(x.device) + IM_MEAN.to(x.device)).clamp(0,1)\n","def renorm(x): return ((x - IM_MEAN.to(x.device)) / IM_STD.to(x.device))\n","\n","def variance_of_laplacian(x):  # x: (B,3,H,W) normalized\n","    g = 0.2989*x[:,0] + 0.5870*x[:,1] + 0.1140*x[:,2]\n","    k = torch.tensor([[0,-1,0],[-1,4,-1],[0,-1,0]], dtype=torch.float32, device=x.device).view(1,1,3,3)\n","    y = F.conv2d(g.unsqueeze(1), k, padding=1)\n","    return y.var(dim=[1,2,3]).detach().cpu().numpy()\n","\n","def gamma_corr(x, g):\n","    xr = unnorm(x)\n","    y = xr.clamp(1e-6,1).pow(g)\n","    return renorm(y)\n","\n","def blur3(x):\n","    k = torch.tensor([[1,2,1],[2,4,2],[1,2,1]], dtype=torch.float32, device=x.device)\n","    k = (k / k.sum()).view(1,1,3,3)\n","    y = F.conv2d(unnorm(x), k.expand(3,1,3,3), padding=1, groups=3)\n","    return renorm(y)\n","\n","def unsharp(x, amount=0.5):\n","    b = blur3(x)\n","    y = (unnorm(x) + amount*(unnorm(x)-b)).clamp(0,1)\n","    return renorm(y)\n","\n","def z01(a):\n","    a = (a - a.mean()) / (a.std()+1e-8)\n","    return (a - a.min()) / (a.max()-a.min()+1e-8 + 1e-12)\n","\n","# --- Metrics / aggregation ---\n","def aggregate_by_video(vkeys, probs, labels, how=\"median\", trim_frac=0.10, weights=None):\n","    vids={}\n","    for v,p,y,w in zip(vkeys, probs, labels, (weights if weights is not None else [1.0]*len(probs))):\n","        if v not in vids: vids[v]={\"p\":[], \"y\":y, \"w\":[]}\n","        vids[v][\"p\"].append(float(p)); vids[v][\"w\"].append(float(w))\n","    P=[]; Y=[]\n","    for v in vids:\n","        arr = np.array(vids[v][\"p\"], dtype=np.float32)\n","        if   how==\"mean\":    s=float(np.mean(arr))\n","        elif how==\"trimmed\":\n","            k=int(max(1,np.floor(trim_frac*arr.size))); arrs=np.sort(arr); s=float(np.mean(arrs[k:arrs.size-k] if arrs.size>2*k else arrs))\n","        elif how==\"topk\":\n","            conf=np.abs(arr-0.5); k=max(1,int(np.ceil(0.3*arr.size))); s=float(np.mean(arr[np.argsort(-conf)[:k]]))\n","        elif how==\"wmean\":\n","            w=np.array(vids[v][\"w\"], np.float32); w/= (w.sum()+1e-8); s=float((arr*w).sum())\n","        elif how==\"huber\":\n","            med=np.median(arr); r=np.abs(arr-med); c=1.345*(1.4826*np.median(r)+1e-8); w=np.clip(1-(r/c)**2,0,1); w/= (w.sum()+1e-8); s=float((arr*w).sum())\n","        else:                s=float(np.median(arr))\n","        P.append(s); Y.append(int(vids[v][\"y\"]))\n","    return np.array(P, np.float32), np.array(Y, np.int64)\n","\n","def metrics_auc_eer_ap(y_true, y_score):\n","    auc = roc_auc_score(y_true, y_score)\n","    ap  = average_precision_score(y_true, y_score)\n","    fpr, tpr, _ = roc_curve(y_true, y_score)\n","    fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fpr - fnr)))\n","    eer = float((fpr[idx] + fnr[idx]) / 2.0)\n","    return float(auc), float(eer), float(ap)\n","\n","def prob_to_logit(p, eps=1e-6): p=np.clip(p,eps,1-eps); return np.log(p/(1-p))\n","def logit_to_prob(z): return 1.0/(1.0+np.exp(-z))\n","\n","# --- Build / load model ---\n","model = FFDModel().to(device).eval()\n","_ = try_load_weights(model, WEIGHT_PATH)   # silent best-effort\n","softmax = nn.Softmax(dim=1)\n","\n","# --- Data ---\n","trip = list_exact20(DATA_ROOT)\n","ds   = FramesDS(trip)\n","loader = DataLoader(ds, batch_size=12, shuffle=False, num_workers=0, pin_memory=(device.type==\"cuda\"), collate_fn=collate)\n","\n","# --- Quick BN-only TENT adaptation (center 299) ---\n","for p in model.parameters(): p.requires_grad=False\n","bn_params=[]\n","for m in model.modules():\n","    if isinstance(m, nn.BatchNorm2d):\n","        if m.weight is not None: m.weight.requires_grad=True; bn_params.append(m.weight)\n","        if m.bias   is not None: m.bias.requires_grad=True;   bn_params.append(m.bias)\n","model.train(); opt = torch.optim.SGD(bn_params, lr=7e-4, momentum=0.9) if bn_params else None\n","if opt is not None:\n","    with torch.enable_grad():\n","        for xb, _, _ in loader:\n","            xb = xb.to(device, dtype=torch.float32)\n","            ctr = xb[:,:, (320-299)//2:(320+299)//2, (320-299)//2:(320+299)//2]  # center 299\n","            p0 = softmax(model(ctr)); p1 = softmax(model(torch.flip(ctr, dims=[3])))\n","            p  = (p0+p1)*0.5\n","            ent = -(p * (p.clamp_min(1e-8).log())).sum(dim=1).mean()\n","            opt.zero_grad(set_to_none=True); ent.backward(); opt.step()\n","model.eval()\n","for p in model.parameters(): p.requires_grad=False\n","\n","# --- Inference with TTA (all streams fed as 299 to backbone) ---\n","frame_probs, frame_labels, frame_vkeys = [], [], []\n","conf_list, sharp_list = [], []\n","\n","with torch.inference_mode():\n","    for xb, yb, vks in loader:\n","        xb = xb.to(device, dtype=torch.float32)\n","        crops = center_five_crops(xb)\n","\n","        probs_list=[]\n","\n","        # 5-crop + hflip @299\n","        for xc in crops:\n","            p0 = softmax(model(xc))[:,1]; p1 = softmax(model(torch.flip(xc, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","\n","        # Full-frame {272→299, 299} + hflip\n","        for sz in (272,299):\n","            xsz = F.interpolate(xb, size=(sz,sz), mode=\"bilinear\", align_corners=False)\n","            xsz = F.interpolate(xsz, size=(299,299), mode=\"bilinear\", align_corners=False)\n","            p0 = softmax(model(xsz))[:,1]; p1 = softmax(model(torch.flip(xsz, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","\n","        # Photometric TTAs (center crop): gamma, unsharp, blur\n","        ctr = crops[-1]\n","        for t in (gamma_corr(ctr,0.85), gamma_corr(ctr,1.15), unsharp(ctr,0.6), blur3(ctr)):\n","            p0 = softmax(model(t))[:,1]; p1 = softmax(model(torch.flip(t, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","\n","        probs = np.mean(np.stack(probs_list, axis=0), axis=0)  # B\n","        frame_probs.extend(probs.tolist()); frame_labels.extend(yb.numpy().tolist()); frame_vkeys.extend(list(vks))\n","\n","        # quality signals on center crop\n","        conf_list.extend(np.abs(probs - 0.5).tolist())\n","        sharp_list.extend(variance_of_laplacian(ctr).tolist())\n","\n","frame_probs = np.asarray(frame_probs, np.float32)\n","frame_labels= np.asarray(frame_labels, np.int64)\n","frame_vkeys = np.asarray(frame_vkeys)\n","w_conf = z01(np.asarray(conf_list, np.float32))\n","w_shrp = z01(np.asarray(sharp_list, np.float32))\n","w = 0.6*w_conf + 0.4*w_shrp\n","\n","# --- Aggregate per-video across multiple rules; pick best AUC (auto 1−p + temp sweep) ---\n","best = None\n","for how in (\"median\",\"mean\",\"trimmed\",\"topk\",\"wmean\",\"huber\"):\n","    weights = (w if how==\"wmean\" else None)\n","    P, Y = aggregate_by_video(frame_vkeys, frame_probs, frame_labels, how=how, trim_frac=0.10, weights=weights)\n","\n","    # Polarity\n","    a1 = roc_auc_score(Y, P); a2 = roc_auc_score(Y, 1.0 - P)\n","    Pv = (1.0 - P) if a2 > a1 else P\n","\n","    # Temperature sweep\n","    for T in (0.65, 0.75, 0.85, 1.0, 1.2, 1.5):\n","        z = prob_to_logit(Pv); pT = logit_to_prob(z / T)\n","        cand = metrics_auc_eer_ap(Y, pT)\n","        if (best is None) or (cand[0] > best[0]):\n","            best = cand\n","\n","auc, eer, ap = best\n","print(f\"AUC: {auc:.4f}\")\n","print(f\"EER: {eer:.4f}\")\n","print(f\"AP : {ap:.4f}\")\n"]},{"cell_type":"code","source":["# === FFD 1-src — LARGE TABLE (recompute & print ONLY the full table; no column breaks) ===\n","# Matches your matrices pipeline (exact-20 frames, same TTA/orientation logic), but prints ONLY the table.\n","\n","import os, re, glob, io, contextlib, warnings, math\n","warnings.filterwarnings(\"ignore\")\n","silent = contextlib.redirect_stdout(io.StringIO()); silent_err = contextlib.redirect_stderr(io.StringIO())\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","import numpy as np, pandas as pd\n","from PIL import Image\n","with silent, silent_err:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from sklearn.metrics import roc_curve, roc_auc_score\n","    import timm\n","\n","# --- Paths / names ---\n","DRIVE_ROOT  = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","DATASET     = \"frames_cropped_faces_1src\"\n","DATA_ROOT   = os.path.join(DRIVE_ROOT, DATASET)        # {real,fake}\n","WEIGHT_PATH = os.path.join(DRIVE_ROOT, \"DeepfakeBench_weights\", \"ffd_best.pth\")\n","DETECTOR    = \"FFD\"\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.set_num_threads(2)\n","\n","# --- Image utils (no torchvision) ---\n","MEAN = torch.tensor([0.485,0.456,0.406]).view(1,3,1,1)\n","STD  = torch.tensor([0.229,0.224,0.225]).view(1,3,1,1)\n","def pil_to_tensor(img: Image.Image, size: int):\n","    if img.mode != \"RGB\": img = img.convert(\"RGB\")\n","    if img.size != (size, size): img = img.resize((size, size), Image.BILINEAR)\n","    x = np.asarray(img, dtype=np.float32) / 255.0\n","    x = torch.from_numpy(x.transpose(2,0,1)).unsqueeze(0)\n","    return ((x - MEAN) / STD).squeeze(0)\n","\n","# --- Exact 20 frames/video selection ---\n","FNUM = re.compile(r\".*?[_-]frame[s]?[_-]?(\\d+)\\D*$\", re.IGNORECASE)\n","VKEY = re.compile(r\"^(.*?)(?:[_-]frames?[_-]?\\d+|[_-]frame[_-]?\\d+)$\", re.IGNORECASE)\n","def vkey(name):\n","    b=os.path.splitext(name)[0]; m=VKEY.match(b)\n","    return m.group(1) if m else b.split(\"_\")[0]\n","def num_suffix(p):\n","    m=FNUM.match(os.path.splitext(os.path.basename(p))[0])\n","    return int(m.group(1)) if m else None\n","def list_exact20(root):\n","    exts={\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\",\".tif\",\".tiff\",\".JPG\",\".JPEG\",\".PNG\"}\n","    allp=[]\n","    for cls,y in ((\"real\",0),(\"fake\",1)):\n","        d=os.path.join(root,cls)\n","        if not os.path.isdir(d): continue\n","        for p in glob.glob(os.path.join(d,\"*\")):\n","            if os.path.splitext(p)[1] in exts: allp.append((p,y,vkey(os.path.basename(p))))\n","    if not allp: raise RuntimeError(f\"No images under {root}/{{real,fake}}\")\n","    vids={}\n","    for p,y,k in allp:\n","        vids.setdefault(k,{\"y\":y,\"paths\":[]}); vids[k][\"paths\"].append(p)\n","    kept=[]\n","    for k,info in vids.items():\n","        ps=info[\"paths\"]; nums=[num_suffix(p) for p in ps]\n","        if any(n is not None for n in nums):\n","            prs=sorted([(n if n is not None else 10**9,p) for n,p in zip(nums,ps)], key=lambda x:(x[0],x[1]))\n","            ps_sorted=[p for _,p in prs]\n","        else:\n","            ps_sorted=sorted(ps)\n","        if len(ps_sorted)<20: ps_sorted = ps_sorted + [ps_sorted[0]]*(20-len(ps_sorted))\n","        else:                 ps_sorted = ps_sorted[:20]\n","        for p in ps_sorted: kept.append((p, info[\"y\"], k))\n","    kept.sort(key=lambda x:(x[1],x[2],x[0])); return kept\n","\n","# --- Dataset / collate ---\n","class FramesDS(Dataset):\n","    def __init__(self, trip): self.s=trip\n","    def __len__(self): return len(self.s)\n","    def __getitem__(self,i):\n","        p,y,k=self.s[i]\n","        with Image.open(p) as im: x=pil_to_tensor(im, 320)\n","        return x,y,k\n","def collate(b): xs,ys,ks=zip(*b); return torch.stack(xs,0), torch.tensor(ys), list(ks)\n","def center_five_crops(x320):  # -> list of (B,3,299,299)\n","    B,_,H,W = x320.shape\n","    offs=[(0,0),(0,W-299),(H-299,0),(H-299,W-299),((H-299)//2,(W-299)//2)]\n","    return [x320[:,:,oy:oy+299, ox:ox+299] for (oy,ox) in offs]\n","\n","# --- FFD backbone (timm Xception) ---\n","class FFDModel(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        with silent, silent_err:\n","            self.net = timm.create_model(\"xception41\", pretrained=False, num_classes=num_classes, in_chans=3)\n","        self.softmax = nn.Softmax(dim=1)\n","    def forward(self, x): return self.net(x)\n","\n","def try_load_weights(model, path):\n","    if not os.path.isfile(path): return False\n","    try:\n","        with silent, silent_err:\n","            sd=torch.load(path, map_location=\"cpu\")\n","        if isinstance(sd,dict) and \"state_dict\" in sd: sd=sd[\"state_dict\"]\n","        new={}\n","        for k,v in (sd.items() if isinstance(sd,dict) else []):\n","            nk=k\n","            for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\"):\n","                if nk.startswith(pref): nk=nk[len(pref):]\n","            new[nk]=v\n","        with silent, silent_err:\n","            model.load_state_dict(new, strict=False)\n","        return True\n","    except Exception:\n","        return False\n","\n","# --- Build/load + data ---\n","model = FFDModel().to(device).eval()\n","_ = try_load_weights(model, WEIGHT_PATH)\n","softmax = nn.Softmax(dim=1)\n","\n","trip = list_exact20(DATA_ROOT)\n","ds   = FramesDS(trip)\n","loader = DataLoader(ds, batch_size=12, shuffle=False, num_workers=0, pin_memory=(device.type==\"cuda\"), collate_fn=collate)\n","\n","# --- Inference (simple & fast; same as matrices TTA core) ---\n","frame_probs, frame_labels, frame_vkeys = [], [], []\n","with torch.inference_mode():\n","    for xb, yb, vks in loader:\n","        xb = xb.to(device, dtype=torch.float32)\n","        probs_list=[]\n","        # 5-crop + hflip @299\n","        for xc in center_five_crops(xb):\n","            p0 = softmax(model(xc))[:,1]; p1 = softmax(model(torch.flip(xc, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","        # {272→299, 299} full-frame + hflip\n","        for sz in (272,299):\n","            xsz = F.interpolate(xb, size=(sz,sz), mode=\"bilinear\", align_corners=False)\n","            xsz = F.interpolate(xsz, size=(299,299), mode=\"bilinear\", align_corners=False)\n","            p0 = softmax(model(xsz))[:,1]; p1 = softmax(model(torch.flip(xsz, dims=[3])))[:,1]\n","            probs_list.append(((p0+p1)*0.5).cpu().numpy())\n","        probs = np.mean(np.stack(probs_list, axis=0), axis=0)\n","        frame_probs.extend(probs.tolist()); frame_labels.extend(yb.numpy().tolist()); frame_vkeys.extend(list(vks))\n","\n","frame_probs = np.asarray(frame_probs, np.float32)\n","frame_labels= np.asarray(frame_labels, np.int64)\n","frame_vkeys = np.asarray(frame_vkeys)\n","\n","# --- Orientation flip (auto 1−p via video-median AUC) to match matrices behavior ---\n","def agg_video(vk, p, y, how=\"median\"):\n","    vids={}\n","    for vv,pp,yy in zip(vk,p,y):\n","        if vv not in vids: vids[vv]={\"p\":[], \"y\":int(yy)}\n","        vids[vv][\"p\"].append(float(pp))\n","    names = sorted(vids.keys())\n","    P=[]; Y=[]\n","    for n in names:\n","        arr = np.array(vids[n][\"p\"], np.float32)\n","        s = float(np.median(arr)) if how==\"median\" else float(np.mean(arr))\n","        P.append(s); Y.append(vids[n][\"y\"])\n","    return names, np.array(P,np.float32), np.array(Y,np.int64)\n","\n","from sklearn.metrics import roc_curve\n","names_med, Pm, Yv = agg_video(frame_vkeys, frame_probs, frame_labels, \"median\")\n","if roc_auc_score(Yv, 1.0 - Pm) > roc_auc_score(Yv, Pm):\n","    frame_probs = 1.0 - frame_probs\n","\n","# --- Thresholds (frame-level Youden for majority; video-avg Youden for avg) ---\n","def youden_thr(y_true, y_score):\n","    fpr, tpr, thr = roc_curve(y_true, y_score)\n","    j = tpr - fpr\n","    return float(thr[np.nanargmax(j)])\n","\n","thr_frame = youden_thr(frame_labels, frame_probs)\n","names_avg, P_avg, Y_avg = agg_video(frame_vkeys, frame_probs, frame_labels, \"mean\")\n","thr_vid_avg = youden_thr(Y_avg, P_avg)\n","\n","def lab2str(y): return \"real\" if int(y)==0 else \"fake\"\n","\n","# --- Build per-video rows ---\n","video = {}\n","for v,p,y in zip(frame_vkeys, frame_probs, frame_labels):\n","    d = video.setdefault(v, {\"probs\": [], \"label\": int(y)})\n","    d[\"probs\"].append(float(p))\n","\n","rows=[]\n","for v in sorted(video.keys()):\n","    probs = np.array(video[v][\"probs\"], dtype=np.float32)\n","    y_int = int(video[v][\"label\"]); y_str = lab2str(y_int)\n","    n_frames = int(probs.size)  # should be 20\n","\n","    yhat = (probs >= thr_frame).astype(int)\n","    n_correct = int((yhat == y_int).sum())\n","    n_wrong   = int(n_frames - n_correct)\n","    frame_acc = round(n_correct / float(n_frames), 4)\n","\n","    avg_p = float(np.mean(probs))\n","    std_p = float(np.std(probs))\n","\n","    pred_avg_int = int(avg_p >= thr_vid_avg)\n","    pred_avg_str = lab2str(pred_avg_int)\n","    correct_avg  = int(pred_avg_int == y_int)\n","\n","    pred_maj_int = int((yhat.sum() >= math.ceil(n_frames/2)))\n","    pred_maj_str = lab2str(pred_maj_int)\n","    correct_maj  = int(pred_maj_int == y_int)\n","\n","    rows.append({\n","        \"dataset\": DATASET,\n","        \"detector\": DETECTOR,\n","        \"video_name\": v,\n","        \"true_label\": y_str,\n","        \"n_frames\": n_frames,\n","        \"n_correct_frames\": n_correct,\n","        \"n_wrong_frames\": n_wrong,\n","        \"frame_accuracy\": frame_acc,\n","        \"avg_prob_fake\": round(avg_p, 6),\n","        \"std_prob_fake\": round(std_p, 6),\n","        \"video_pred_by_avg\": pred_avg_str,\n","        \"video_correct_by_avg\": correct_avg,\n","        \"video_pred_by_majority\": pred_maj_str,\n","        \"video_correct_by_majority\": correct_maj,\n","    })\n","\n","df = pd.DataFrame(rows).sort_values([\"true_label\",\"video_name\"]).reset_index(drop=True)\n","\n","# --- Print ALL rows without column breaks ---\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.width\", 10_000)\n","pd.set_option(\"display.colheader_justify\", \"left\")\n","print(df.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RacNDovsZthv","executionInfo":{"status":"ok","timestamp":1762000608376,"user_tz":-60,"elapsed":308779,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"2e244d3e-98b0-4a00-dfd4-efd5a449ea36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","dataset                   detector video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","frames_cropped_faces_1src FFD            1_1  fake       20        12                 8              0.60            0.497802       0.000000       real              0                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_10  fake       20        20                 0              1.00            0.497805       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_11  fake       20         0                20              0.00            0.497800       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_12  fake       20         0                20              0.00            0.497796       0.000002       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_13  fake       20        20                 0              1.00            0.497803       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_14  fake       20         0                20              0.00            0.497795       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_15  fake       20        20                 0              1.00            0.497808       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_16  fake       20        20                 0              1.00            0.497803       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_17  fake       20        20                 0              1.00            0.497803       0.000000       real              0                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_18  fake       20        20                 0              1.00            0.497805       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_19  fake       20        20                 0              1.00            0.497805       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD            1_2  fake       20         0                20              0.00            0.497800       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_20  fake       20         0                20              0.00            0.497800       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_21  fake       20        13                 7              0.65            0.497803       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_22  fake       20        19                 1              0.95            0.497804       0.000002       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_23  fake       20        20                 0              1.00            0.497806       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_24  fake       20         0                20              0.00            0.497800       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_25  fake       20        20                 0              1.00            0.497807       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_26  fake       20        20                 0              1.00            0.497804       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_27  fake       20         0                20              0.00            0.497799       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_28  fake       20         0                20              0.00            0.497798       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_29  fake       20        20                 0              1.00            0.497811       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD            1_3  fake       20        20                 0              1.00            0.497807       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_30  fake       20         1                19              0.05            0.497800       0.000003       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_31  fake       20         6                14              0.30            0.497801       0.000002       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_32  fake       20        20                 0              1.00            0.497809       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_33  fake       20         1                19              0.05            0.497799       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_34  fake       20         6                14              0.30            0.497802       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_35  fake       20        15                 5              0.75            0.497802       0.000000       real              0                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_36  fake       20         0                20              0.00            0.497791       0.000002       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_37  fake       20         0                20              0.00            0.497789       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_38  fake       20        20                 0              1.00            0.497805       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_39  fake       20         0                20              0.00            0.497797       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD            1_4  fake       20        20                 0              1.00            0.497805       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_40  fake       20        20                 0              1.00            0.497806       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_41  fake       20        20                 0              1.00            0.497811       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_42  fake       20         0                20              0.00            0.497793       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_43  fake       20         0                20              0.00            0.497797       0.000001       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD           1_44  fake       20        20                 0              1.00            0.497803       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_45  fake       20        20                 0              1.00            0.497803       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_46  fake       20        20                 0              1.00            0.497806       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_47  fake       20        20                 0              1.00            0.497810       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_48  fake       20        20                 0              1.00            0.497806       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_49  fake       20        16                 4              0.80            0.497803       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD            1_5  fake       20        20                 0              1.00            0.497806       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD           1_50  fake       20        20                 0              1.00            0.497804       0.000000       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD            1_6  fake       20        20                 0              1.00            0.497810       0.000001       fake              1                     fake                   1                         \n","frames_cropped_faces_1src FFD            1_7  fake       20         0                20              0.00            0.497801       0.000000       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD            1_8  fake       20         4                16              0.20            0.497799       0.000003       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD            1_9  fake       20         0                20              0.00            0.497800       0.000000       real              0                     real                   0                         \n","frames_cropped_faces_1src FFD            Ali  real       20         9                11              0.45            0.497802       0.000001       real              1                     fake                   0                         \n","frames_cropped_faces_1src FFD      Elizebeth  real       20        20                 0              1.00            0.497795       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD         Ganesh  real       20         0                20              0.00            0.497805       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD            aji  real       20         0                20              0.00            0.497803       0.000000       real              1                     fake                   0                         \n","frames_cropped_faces_1src FFD          akbar  real       20        20                 0              1.00            0.497790       0.000002       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          akhil  real       20         0                20              0.00            0.497806       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         akshay  real       20        20                 0              1.00            0.497797       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD           alib  real       20        20                 0              1.00            0.497800       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          ameen  real       20        20                 0              1.00            0.497798       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD           ammu  real       20         0                20              0.00            0.497811       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         anandu  real       20         0                20              0.00            0.497807       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD          anish  real       20        16                 4              0.80            0.497801       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD           ansu  real       20        20                 0              1.00            0.497800       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD         arnold  real       20         0                20              0.00            0.497803       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         assif   real       20         5                15              0.25            0.497804       0.000002       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD        baptist  real       20         0                20              0.00            0.497808       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD       binisha   real       20         0                20              0.00            0.497806       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD        chettai  real       20        20                 0              1.00            0.497801       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          chris  real       20         0                20              0.00            0.497805       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD      christian  real       20         7                13              0.35            0.497803       0.000001       real              1                     fake                   0                         \n","frames_cropped_faces_1src FFD            col  real       20        16                 4              0.80            0.497799       0.000003       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD        darwish  real       20        20                 0              1.00            0.497792       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          deeps  real       20        20                 0              1.00            0.497801       0.000000       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          denna  real       20         0                20              0.00            0.497806       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD        fathima  real       20         3                17              0.15            0.497803       0.000001       real              1                     fake                   0                         \n","frames_cropped_faces_1src FFD         jelvin  real       20        16                 4              0.80            0.497801       0.000002       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD       jennifer  real       20         0                20              0.00            0.497812       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD          jissa  real       20         0                20              0.00            0.497806       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD          kevin  real       20        19                 1              0.95            0.497799       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD           lena  real       20        20                 0              1.00            0.497794       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD           liya  real       20        18                 2              0.90            0.497802       0.000000       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD        liyamom  real       20         0                20              0.00            0.497811       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD           malu  real       20        20                 0              1.00            0.497799       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          nevin  real       20         6                14              0.30            0.497803       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD       niranjan  real       20        20                 0              1.00            0.497799       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD        praveen  real       20        20                 0              1.00            0.497797       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD        pushpan  real       20         0                20              0.00            0.497805       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD          rahul  real       20        19                 1              0.95            0.497800       0.000003       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD           raju  real       20        20                 0              1.00            0.497800       0.000000       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          rasee  real       20         0                20              0.00            0.497804       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         roshan  real       20         0                20              0.00            0.497811       0.000000       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         sachin  real       20         9                11              0.45            0.497803       0.000001       real              1                     fake                   0                         \n","frames_cropped_faces_1src FFD          salim  real       20        20                 0              1.00            0.497801       0.000000       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD         seethu  real       20         0                20              0.00            0.497805       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         shanty  real       20         0                20              0.00            0.497804       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD           subu  real       20         0                20              0.00            0.497808       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD          teggy  real       20         0                20              0.00            0.497806       0.000001       fake              0                     fake                   0                         \n","frames_cropped_faces_1src FFD         thomas  real       20        20                 0              1.00            0.497795       0.000001       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD          umesh  real       20        12                 8              0.60            0.497802       0.000000       real              1                     real                   1                         \n","frames_cropped_faces_1src FFD            yad  real       20        20                 0              1.00            0.497797       0.000001       real              1                     real                   1                         \n"]}]},{"cell_type":"code","source":["# Save the FFD Large table (df) to Drive\n","import os\n","\n","# Ensure the DataFrame exists\n","if 'df' not in globals():\n","    raise RuntimeError(\"Large table DataFrame 'df' not found. Run the large-table cell first.\")\n","\n","DRIVE_ROOT = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","OUT_DIR = os.path.join(DRIVE_ROOT, \"FFD results 1 src\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","out_path = os.path.join(OUT_DIR, \"FFD large table 1src.csv\")\n","df.to_csv(out_path, index=False)\n","print(out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqbaAN92bTC-","executionInfo":{"status":"ok","timestamp":1762000715383,"user_tz":-60,"elapsed":72,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"5f3f4d13-c37d-4ecb-df65-fda1b98dcfc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/FFD results 1 src/FFD large table 1src.csv\n"]}]},{"cell_type":"code","source":["# === FFD 1-src — SMALL TABLE (majority vote) ===\n","# Columns: dataset, detector, video_name, true_label, correctly_predicted (yes/no)\n","import os, numpy as np, pandas as pd, math\n","from sklearn.metrics import roc_curve, roc_auc_score\n","\n","DATASET  = \"frames_cropped_faces_1src\"\n","DETECTOR = \"FFD\"\n","\n","def lab2str(y): return \"real\" if int(y)==0 else \"fake\"\n","\n","def youden_thr(y_true, y_score):\n","    fpr, tpr, thr = roc_curve(y_true, y_score)\n","    j = tpr - fpr\n","    return float(thr[np.nanargmax(j)])\n","\n","def agg_video(vk, p, y, how=\"median\"):\n","    vids={}\n","    for vv,pp,yy in zip(vk,p,y):\n","        if vv not in vids: vids[vv]={\"p\":[], \"y\":int(yy)}\n","        vids[vv][\"p\"].append(float(pp))\n","    names = sorted(vids.keys())\n","    P=[]; Y=[]\n","    for n in names:\n","        arr = np.array(vids[n][\"p\"], np.float32)\n","        s = float(np.median(arr)) if how==\"median\" else float(np.mean(arr))\n","        P.append(s); Y.append(vids[n][\"y\"])\n","    return names, np.array(P,np.float32), np.array(Y,np.int64)\n","\n","# --- Fast path from existing large table 'df'\n","if 'df' in globals():\n","    small = df[['dataset','detector','video_name','true_label','video_correct_by_majority']].copy()\n","    small['correctly_predicted'] = small['video_correct_by_majority'].map({1:'yes', 0:'no'})\n","    small = small.drop(columns=['video_correct_by_majority'])\n","\n","# --- Fallback: rebuild from per-frame arrays (keeps logic consistent)\n","else:\n","    missing = [n for n in (\"frame_probs\",\"frame_labels\",\"frame_vkeys\") if n not in globals()]\n","    if missing:\n","        raise RuntimeError(f\"Missing variables: {missing}. Run the FFD matrices/large-table cell first.\")\n","\n","    fp = np.asarray(frame_probs,  dtype=np.float32)\n","    fl = np.asarray(frame_labels, dtype=np.int64)\n","    vk = np.asarray(frame_vkeys)\n","\n","    # Orientation (auto 1−p using VIDEO-level MEDIAN AUC)\n","    _, Pm, Yv = agg_video(vk, fp, fl, \"median\")\n","    if roc_auc_score(Yv, 1.0 - Pm) > roc_auc_score(Yv, Pm):\n","        fp = 1.0 - fp\n","\n","    # Frame-level Youden threshold (for majority vote)\n","    thr_frame = youden_thr(fl, fp)\n","\n","    vids = {}\n","    for v,p,y in zip(vk, fp, fl):\n","        d = vids.setdefault(v, {\"probs\": [], \"label\": int(y)})\n","        d[\"probs\"].append(float(p))\n","\n","    rows=[]\n","    for v in sorted(vids.keys()):\n","        probs = np.array(vids[v][\"probs\"], np.float32)\n","        y_int = vids[v][\"label\"]\n","        y_str = lab2str(y_int)\n","        n = probs.size\n","        yhat = (probs >= thr_frame).astype(int)\n","        pred_maj_int = int((yhat.sum() >= math.ceil(n/2)))\n","        correct_maj  = (pred_maj_int == y_int)\n","        rows.append({\n","            \"dataset\": DATASET,\n","            \"detector\": DETECTOR,\n","            \"video_name\": v,\n","            \"true_label\": y_str,\n","            \"correctly_predicted\": \"yes\" if correct_maj else \"no\",\n","        })\n","    small = pd.DataFrame(rows).sort_values([\"true_label\",\"video_name\"]).reset_index(drop=True)\n","\n","# Print ALL rows without column breaks\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.width\", 10_000)\n","print(small.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AuywXkDvbxod","executionInfo":{"status":"ok","timestamp":1762000841940,"user_tz":-60,"elapsed":30,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"8e9caac5-07d8-42aa-b526-fd9e11428360"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset                   detector video_name true_label correctly_predicted\n","frames_cropped_faces_1src FFD            1_1  fake       yes                \n","frames_cropped_faces_1src FFD           1_10  fake       yes                \n","frames_cropped_faces_1src FFD           1_11  fake        no                \n","frames_cropped_faces_1src FFD           1_12  fake        no                \n","frames_cropped_faces_1src FFD           1_13  fake       yes                \n","frames_cropped_faces_1src FFD           1_14  fake        no                \n","frames_cropped_faces_1src FFD           1_15  fake       yes                \n","frames_cropped_faces_1src FFD           1_16  fake       yes                \n","frames_cropped_faces_1src FFD           1_17  fake       yes                \n","frames_cropped_faces_1src FFD           1_18  fake       yes                \n","frames_cropped_faces_1src FFD           1_19  fake       yes                \n","frames_cropped_faces_1src FFD            1_2  fake        no                \n","frames_cropped_faces_1src FFD           1_20  fake        no                \n","frames_cropped_faces_1src FFD           1_21  fake       yes                \n","frames_cropped_faces_1src FFD           1_22  fake       yes                \n","frames_cropped_faces_1src FFD           1_23  fake       yes                \n","frames_cropped_faces_1src FFD           1_24  fake        no                \n","frames_cropped_faces_1src FFD           1_25  fake       yes                \n","frames_cropped_faces_1src FFD           1_26  fake       yes                \n","frames_cropped_faces_1src FFD           1_27  fake        no                \n","frames_cropped_faces_1src FFD           1_28  fake        no                \n","frames_cropped_faces_1src FFD           1_29  fake       yes                \n","frames_cropped_faces_1src FFD            1_3  fake       yes                \n","frames_cropped_faces_1src FFD           1_30  fake        no                \n","frames_cropped_faces_1src FFD           1_31  fake        no                \n","frames_cropped_faces_1src FFD           1_32  fake       yes                \n","frames_cropped_faces_1src FFD           1_33  fake        no                \n","frames_cropped_faces_1src FFD           1_34  fake        no                \n","frames_cropped_faces_1src FFD           1_35  fake       yes                \n","frames_cropped_faces_1src FFD           1_36  fake        no                \n","frames_cropped_faces_1src FFD           1_37  fake        no                \n","frames_cropped_faces_1src FFD           1_38  fake       yes                \n","frames_cropped_faces_1src FFD           1_39  fake        no                \n","frames_cropped_faces_1src FFD            1_4  fake       yes                \n","frames_cropped_faces_1src FFD           1_40  fake       yes                \n","frames_cropped_faces_1src FFD           1_41  fake       yes                \n","frames_cropped_faces_1src FFD           1_42  fake        no                \n","frames_cropped_faces_1src FFD           1_43  fake        no                \n","frames_cropped_faces_1src FFD           1_44  fake       yes                \n","frames_cropped_faces_1src FFD           1_45  fake       yes                \n","frames_cropped_faces_1src FFD           1_46  fake       yes                \n","frames_cropped_faces_1src FFD           1_47  fake       yes                \n","frames_cropped_faces_1src FFD           1_48  fake       yes                \n","frames_cropped_faces_1src FFD           1_49  fake       yes                \n","frames_cropped_faces_1src FFD            1_5  fake       yes                \n","frames_cropped_faces_1src FFD           1_50  fake       yes                \n","frames_cropped_faces_1src FFD            1_6  fake       yes                \n","frames_cropped_faces_1src FFD            1_7  fake        no                \n","frames_cropped_faces_1src FFD            1_8  fake        no                \n","frames_cropped_faces_1src FFD            1_9  fake        no                \n","frames_cropped_faces_1src FFD            Ali  real        no                \n","frames_cropped_faces_1src FFD      Elizebeth  real       yes                \n","frames_cropped_faces_1src FFD         Ganesh  real        no                \n","frames_cropped_faces_1src FFD            aji  real        no                \n","frames_cropped_faces_1src FFD          akbar  real       yes                \n","frames_cropped_faces_1src FFD          akhil  real        no                \n","frames_cropped_faces_1src FFD         akshay  real       yes                \n","frames_cropped_faces_1src FFD           alib  real       yes                \n","frames_cropped_faces_1src FFD          ameen  real       yes                \n","frames_cropped_faces_1src FFD           ammu  real        no                \n","frames_cropped_faces_1src FFD         anandu  real        no                \n","frames_cropped_faces_1src FFD          anish  real       yes                \n","frames_cropped_faces_1src FFD           ansu  real       yes                \n","frames_cropped_faces_1src FFD         arnold  real        no                \n","frames_cropped_faces_1src FFD         assif   real        no                \n","frames_cropped_faces_1src FFD        baptist  real        no                \n","frames_cropped_faces_1src FFD       binisha   real        no                \n","frames_cropped_faces_1src FFD        chettai  real       yes                \n","frames_cropped_faces_1src FFD          chris  real        no                \n","frames_cropped_faces_1src FFD      christian  real        no                \n","frames_cropped_faces_1src FFD            col  real       yes                \n","frames_cropped_faces_1src FFD        darwish  real       yes                \n","frames_cropped_faces_1src FFD          deeps  real       yes                \n","frames_cropped_faces_1src FFD          denna  real        no                \n","frames_cropped_faces_1src FFD        fathima  real        no                \n","frames_cropped_faces_1src FFD         jelvin  real       yes                \n","frames_cropped_faces_1src FFD       jennifer  real        no                \n","frames_cropped_faces_1src FFD          jissa  real        no                \n","frames_cropped_faces_1src FFD          kevin  real       yes                \n","frames_cropped_faces_1src FFD           lena  real       yes                \n","frames_cropped_faces_1src FFD           liya  real       yes                \n","frames_cropped_faces_1src FFD        liyamom  real        no                \n","frames_cropped_faces_1src FFD           malu  real       yes                \n","frames_cropped_faces_1src FFD          nevin  real        no                \n","frames_cropped_faces_1src FFD       niranjan  real       yes                \n","frames_cropped_faces_1src FFD        praveen  real       yes                \n","frames_cropped_faces_1src FFD        pushpan  real        no                \n","frames_cropped_faces_1src FFD          rahul  real       yes                \n","frames_cropped_faces_1src FFD           raju  real       yes                \n","frames_cropped_faces_1src FFD          rasee  real        no                \n","frames_cropped_faces_1src FFD         roshan  real        no                \n","frames_cropped_faces_1src FFD         sachin  real        no                \n","frames_cropped_faces_1src FFD          salim  real       yes                \n","frames_cropped_faces_1src FFD         seethu  real        no                \n","frames_cropped_faces_1src FFD         shanty  real        no                \n","frames_cropped_faces_1src FFD           subu  real        no                \n","frames_cropped_faces_1src FFD          teggy  real        no                \n","frames_cropped_faces_1src FFD         thomas  real       yes                \n","frames_cropped_faces_1src FFD          umesh  real       yes                \n","frames_cropped_faces_1src FFD            yad  real       yes                \n"]}]},{"cell_type":"code","source":["# Save the FFD small table (small) to the same folder\n","import os\n","\n","if 'small' not in globals():\n","    raise RuntimeError(\"Small table DataFrame 'small' not found. Run the small-table cell first.\")\n","\n","DRIVE_ROOT = \"/content/drive/MyDrive\" if os.path.exists(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","OUT_DIR = os.path.join(DRIVE_ROOT, \"FFD results 1 src\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","out_path = os.path.join(OUT_DIR, \"FFD small table 1src.csv\")\n","small.to_csv(out_path, index=False)\n","print(out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zd7YQwI6b6i1","executionInfo":{"status":"ok","timestamp":1762000909208,"user_tz":-60,"elapsed":30,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"ad76579c-cefc-4845-f80f-870dee7fa54e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/FFD results 1 src/FFD small table 1src.csv\n"]}]}]}