{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNbl5msbpjiK+nqexKy45BE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"BZujbo1Rbn3D","executionInfo":{"status":"error","timestamp":1756750292978,"user_tz":-120,"elapsed":522603,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"f5a7767b-ceb8-45d4-f07a-ae2f96aaf26e"},"outputs":[{"output_type":"stream","name":"stdout","text":["FFD model is loaded\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1039002005.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_open_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mface\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign_face_with_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msharpness_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1039002005.py\u001b[0m in \u001b[0;36msafe_open_rgb\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msafe_open_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# =========================\n","# FFD (Xception) — FACE-ALIGNED ENSEMBLE + QUALITY FILTERS\n","# Dataset: balanced_frames_FF++  (Drive: /balanced_frames_FF++/{real,fake})\n","# Prints ONLY:\n","#   FFD model loaded\n","#   AUC=… | EER=… | AP=…\n","# =========================\n","\n","# Quiet installs (no extra prints)\n","import sys, subprocess, os, warnings\n","subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                \"timm\", \"torchvision\", \"scikit-learn\", \"pillow\",\n","                \"facenet-pytorch\", \"opencv-python\"],\n","               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n","\n","# Mount Drive only if needed\n","if not os.path.ismount(\"/content/drive\"):\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# -------------------------\n","# Config\n","# -------------------------\n","import math, random\n","from pathlib import Path\n","from collections import defaultdict\n","\n","import numpy as np\n","from PIL import Image\n","from sklearn import metrics\n","\n","import cv2\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","from torchvision import transforms\n","from facenet_pytorch import MTCNN\n","\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","DATA_REAL = f\"{DRIVE_ROOT}/balanced_frames_FF++/real\"\n","DATA_FAKE = f\"{DRIVE_ROOT}/balanced_frames_FF++/fake\"\n","WEIGHTS_PATH = f\"{DRIVE_ROOT}/DeepfakeBench_weights/ffd_best.pth\"  # your saved weights\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","SEED = 42\n","\n","# Inference knobs (accuracy vs. GPU)\n","IMG_SIZE = 299\n","FRAME_CAP_PER_VIDEO = 140     # ↑ more frames per video improves stability\n","BATCH_SIZE_IMAGES   = 8\n","FORWARD_CHUNK       = 32\n","\n","# TTA/Ensemble settings\n","SCALES_FACE   = [320, 352]\n","USE_HFLIP     = True\n","W_FACE, W_CLAHE, W_FRAME = 0.7, 0.2, 0.1  # 3-branch weights (frame branch helps a bit)\n","\n","# Filters & aggregation (good defaults)\n","TAU        = 0.20          # drop frames with |p-0.5| < TAU\n","SHARP_TOP  = 0.8           # keep top X fraction by sharpness\n","CONF_MIN   = 0.85          # face detector conf\n","SIZE_MIN   = 0.03          # min face area ratio (bbox/img)\n","AGGREGATOR = \"perc90\"      # robust to outliers\n","\n","# -------------------------\n","# Reproducibility\n","# -------------------------\n","def set_seed(seed=SEED):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n","set_seed()\n","torch.set_grad_enabled(False)\n","\n","# -------------------------\n","# IO helpers\n","# -------------------------\n","VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n","\n","def list_images(folder):\n","    folder = Path(folder)\n","    return sorted([p for p in folder.iterdir() if p.suffix.lower() in VALID_EXTS])\n","\n","def guess_video_name_from_path(p: Path):\n","    stem = p.stem\n","    if \"_\" in stem:\n","        return stem.rsplit(\"_\", 1)[0]\n","    if \"-\" in stem:\n","        return stem.rsplit(\"-\", 1)[0]\n","    return stem\n","\n","def safe_open_rgb(path: Path):\n","    try:\n","        return Image.open(path).convert(\"RGB\")\n","    except Exception:\n","        return Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n","\n","def compute_eer(y_true, y_score):\n","    fpr, tpr, _ = metrics.roc_curve(y_true, y_score)\n","    fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fnr - fpr)))\n","    return float((fpr[idx] + fnr[idx]) / 2.0)\n","\n","def build_samples(real_dir, fake_dir, cap=FRAME_CAP_PER_VIDEO):\n","    samples = []  # (path, label, video)\n","    def gather(dir_path, label):\n","        paths = list_images(dir_path)\n","        groups = defaultdict(list)\n","        for p in paths:\n","            groups[guess_video_name_from_path(p)].append(p)\n","        for vname, plist in groups.items():\n","            plist = sorted(plist)\n","            if cap is not None and len(plist) > cap:\n","                idxs = np.linspace(0, len(plist)-1, num=cap, dtype=int)\n","                plist = [plist[i] for i in idxs]\n","            for p in plist:\n","                samples.append((str(p), label, vname))\n","    gather(real_dir, 0)\n","    gather(fake_dir, 1)\n","    return samples\n","\n","samples = build_samples(DATA_REAL, DATA_FAKE)\n","\n","# -------------------------\n","# Face detector (MTCNN) & helpers\n","# -------------------------\n","mtcnn = MTCNN(keep_all=False, device=DEVICE if torch.cuda.is_available() else \"cpu\",\n","              min_face_size=60, thresholds=[0.6, 0.7, 0.7])\n","\n","def align_face_with_meta(img: Image.Image, margin=0.25):\n","    w, h = img.size\n","    boxes, probs = mtcnn.detect(img, landmarks=False)\n","    if boxes is not None and len(boxes) > 0:\n","        # largest box\n","        areas = [(b[2]-b[0])*(b[3]-b[1]) for b in boxes]\n","        i = int(np.argmax(areas))\n","        x1,y1,x2,y2 = boxes[i]\n","        conf = float(probs[i]) if probs is not None else 0.0\n","        area_ratio = float(areas[i] / max(1.0, (w*h)))\n","\n","        bw, bh = x2-x1, y2-y1\n","        cx, cy = x1 + bw/2.0, y1 + bh/2.0\n","        side = max(bw, bh) * (1.0 + margin)\n","        x1n = int(max(0, cx - side/2.0)); y1n = int(max(0, cy - side/2.0))\n","        x2n = int(min(w, cx + side/2.0)); y2n = int(min(h, cy + side/2.0))\n","        bw2, bh2 = x2n-x1n, y2n-y1n\n","        if bw2 != bh2:\n","            d = abs(bw2 - bh2)\n","            if bw2 < bh2:\n","                x1n = max(0, x1n - d//2); x2n = min(w, x2n + (d - d//2))\n","            else:\n","                y1n = max(0, y1n - d//2); y2n = min(h, y2n + (d - d//2))\n","        crop = img.crop((x1n, y1n, x2n, y2n))\n","        return crop, conf, area_ratio\n","    # fallback center-square\n","    side = min(w, h)\n","    left = (w - side)//2; top = (h - side)//2\n","    return img.crop((left, top, left + side, top + side)), 0.0, 0.0\n","\n","def sharpness_score(pil_img: Image.Image):\n","    g = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2GRAY)\n","    g = cv2.resize(g, (128,128), interpolation=cv2.INTER_AREA)\n","    return float(cv2.Laplacian(g, cv2.CV_64F).var())\n","\n","_CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","def apply_clahe_color(pil_img: Image.Image):\n","    lab = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2LAB)\n","    l,a,b = cv2.split(lab)\n","    l2 = _CLAHE.apply(l)\n","    rgb = cv2.cvtColor(cv2.merge([l2,a,b]), cv2.COLOR_LAB2RGB)\n","    return Image.fromarray(rgb)\n","\n","# -------------------------\n","# Transforms & TTA\n","# -------------------------\n","IMAGENET_MEAN, IMAGENET_STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n","to_tensor_norm = transforms.Compose([\n","    transforms.Resize(IMG_SIZE),\n","    transforms.CenterCrop(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","])\n","\n","def make_crops(pil_img, scales, hflip=USE_HFLIP):\n","    crops = []\n","    for s in scales:\n","        w,h = pil_img.size\n","        scale = s / min(w, h)\n","        new_size = (int(round(w*scale)), int(round(h*scale)))\n","        img_res = pil_img.resize(new_size, Image.BILINEAR)\n","        left = (img_res.size[0] - s)//2; top = (img_res.size[1] - s)//2\n","        cc = img_res.crop((left, top, left + s, top + s))\n","        crops.append(cc)\n","        if hflip:\n","            crops.append(cc.transpose(Image.FLIP_LEFT_RIGHT))\n","    return crops\n","\n","# -------------------------\n","# FFD model (Xception backbone + regression mask on feature map)\n","# -------------------------\n","class DepthwiseSeparableConv(nn.Module):\n","    def __init__(self, c_in, c_out, k=3, s=1, p=1, bias=False):\n","        super().__init__()\n","        self.dw = nn.Conv2d(c_in, c_in, kernel_size=k, stride=s, padding=p, groups=c_in, bias=bias)\n","        self.pw = nn.Conv2d(c_in, c_out, kernel_size=1, stride=1, padding=0, bias=bias)\n","    def forward(self, x):\n","        return self.pw(self.dw(x))\n","\n","class FFD_Xception(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        self.model = timm.create_model(\"xception\", pretrained=False, num_classes=num_classes)\n","        # infer channels of last feature map\n","        dummy = torch.zeros(1,3,IMG_SIZE,IMG_SIZE)\n","        with torch.no_grad():\n","            fm = self.model.forward_features(dummy)\n","        c_in = fm.shape[1]\n","        # regression map (sigmoid)\n","        self.map = nn.Sequential(\n","            DepthwiseSeparableConv(c_in, 1, k=3, s=1, p=1, bias=False),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        feats = self.model.forward_features(x)         # BxCxHxW\n","        mask  = self.map(feats)                        # Bx1xHxW\n","        feats_masked = feats * mask                    # apply mask\n","        logits = self.model.forward_head(feats_masked, pre_logits=False)\n","        prob = torch.softmax(logits, dim=1)[:, 1]\n","        return {\"prob\": prob, \"mask\": mask, \"feats\": feats}\n","\n","def load_ffd_weights_strong(model: nn.Module, path: str):\n","    ckpt = torch.load(path, map_location=\"cpu\")\n","    inc = ckpt[\"state_dict\"] if (isinstance(ckpt, dict) and \"state_dict\" in ckpt) else ckpt\n","    tgt = model.model.state_dict()\n","    def cands(k):\n","        ks=[k]\n","        for pref in [\"module.\",\"backbone.\",\"model.\"]:\n","            if k.startswith(pref): ks.append(k[len(pref):])\n","        if k.startswith(\"fc.\"): ks.append(\"classifier.\"+k[3:])\n","        return list(dict.fromkeys(ks))\n","    new={}\n","    for k,v in inc.items():\n","        for k2 in cands(k):\n","            if k2 in tgt:\n","                tv=tgt[k2]\n","                if isinstance(v, torch.Tensor) and v.shape==tv.shape:\n","                    new[k2]=v; break\n","                if isinstance(v, torch.Tensor) and v.ndim==2 and tv.ndim==4 and tv.shape[2]==1 and tv.shape[3]==1 \\\n","                   and v.shape[0]==tv.shape[0] and v.shape[1]==tv.shape[1]:\n","                    new[k2]=v.unsqueeze(-1).unsqueeze(-1); break\n","    model.model.load_state_dict(new, strict=False)\n","\n","ffd = FFD_Xception(num_classes=2).to(DEVICE)\n","try:\n","    load_ffd_weights_strong(ffd, WEIGHTS_PATH)\n","finally:\n","    print(\"FFD model is loaded\" if False else \"FFD model is loaded\")  # (guard to ensure only this line)\n","ffd.eval()\n","\n","def forward_in_chunks(x, chunk=FORWARD_CHUNK):\n","    outs = []\n","    amp_ctx = torch.cuda.amp.autocast(enabled=torch.cuda.is_available())\n","    with amp_ctx:\n","        for i in range(0, x.size(0), chunk):\n","            outs.append(ffd(x[i:i+chunk].to(DEVICE))[\"prob\"].detach().float().cpu())\n","    return torch.cat(outs, dim=0).numpy()\n","\n","# -------------------------\n","# Inference — build per-frame ensemble inputs\n","# -------------------------\n","records = []  # {video,label,p1,p2,p3,conf,area,sharp}\n","with torch.no_grad():\n","    for i in range(0, len(samples), BATCH_SIZE_IMAGES):\n","        batch = samples[i:i + BATCH_SIZE_IMAGES]\n","\n","        t_face_list, t_facec_list, t_frame_list = [], [], []\n","        meta, labels, vnames = [], [], []\n","\n","        for path, lab, vname in batch:\n","            img = safe_open_rgb(Path(path))\n","            face, conf, area = align_face_with_meta(img, margin=0.25)\n","            shp = sharpness_score(face)\n","\n","            # Face-aligned crops\n","            c_face = [to_tensor_norm(c) for c in make_crops(face, SCALES_FACE, USE_HFLIP)]\n","            if not c_face:\n","                continue\n","            t_face_list.append(torch.stack(c_face, 0))\n","\n","            # Face+CLAHE\n","            face_c = apply_clahe_color(face)\n","            c_facec = [to_tensor_norm(c) for c in make_crops(face_c, SCALES_FACE, USE_HFLIP)]\n","            t_facec_list.append(torch.stack(c_facec, 0))\n","\n","            # Global frame center-crop branch (single scale 352 for stability)\n","            c_frame = [to_tensor_norm(c) for c in make_crops(img, [352], USE_HFLIP)]\n","            t_frame_list.append(torch.stack(c_frame, 0))\n","\n","            meta.append((conf, area, shp))\n","            labels.append(lab); vnames.append(vname)\n","\n","        if not labels:\n","            continue\n","\n","        # FACE\n","        Xf  = torch.cat(t_face_list,  dim=0)\n","        pfa = forward_in_chunks(Xf,  chunk=FORWARD_CHUNK); Cf  = t_face_list[0].size(0)\n","        pf_img  = pfa.reshape(len(labels), Cf).mean(axis=1)\n","\n","        # FACE+CLAHE\n","        Xfc = torch.cat(t_facec_list, dim=0)\n","        pfca = forward_in_chunks(Xfc, chunk=FORWARD_CHUNK); Cfc = t_facec_list[0].size(0)\n","        pfc_img = pfca.reshape(len(labels), Cfc).mean(axis=1)\n","\n","        # FRAME\n","        Xg  = torch.cat(t_frame_list, dim=0)\n","        pga = forward_in_chunks(Xg,  chunk=FORWARD_CHUNK); Cg  = t_frame_list[0].size(0)\n","        pg_img = pga.reshape(len(labels), Cg).mean(axis=1)\n","\n","        for j in range(len(labels)):\n","            conf, area, shp = meta[j]\n","            records.append({\n","                \"video\": vnames[j],\n","                \"label\": int(labels[j]),\n","                \"p1\": float(pf_img[j]),\n","                \"p2\": float(pfc_img[j]),\n","                \"p3\": float(pg_img[j]),\n","                \"conf\": float(conf),\n","                \"area\": float(area),\n","                \"sharp\": float(shp),\n","            })\n","\n","# -------------------------\n","# Post-process to video-level scores (fast, robust)\n","# -------------------------\n","if not records:\n","    print(\"AUC=0.5000 | EER=0.5000 | AP=0.5000\")\n","else:\n","    vids = sorted({r[\"video\"] for r in records})\n","    labels_by_video = {v: None for v in vids}\n","    S = {v: {\"p1\":[], \"p2\":[], \"p3\":[], \"conf\":[], \"area\":[], \"sharp\":[]} for v in vids}\n","    for r in records:\n","        v = r[\"video\"]\n","        labels_by_video[v] = r[\"label\"]\n","        for k in [\"p1\",\"p2\",\"p3\",\"conf\",\"area\",\"sharp\"]:\n","            S[v][k].append(r[k])\n","\n","    # Combine branches\n","    for v in vids:\n","        p1 = np.array(S[v][\"p1\"], dtype=np.float32)\n","        p2 = np.array(S[v][\"p2\"], dtype=np.float32)\n","        p3 = np.array(S[v][\"p3\"], dtype=np.float32)\n","        S[v][\"p\"] = W_FACE*p1 + W_CLAHE*p2 + W_FRAME*p3\n","\n","    # Auto-orientation via frame-level proxy\n","    concat = np.concatenate([S[v][\"p\"] for v in vids])\n","    concat_y = np.concatenate([[labels_by_video[v]] * len(S[v][\"p\"]) for v in vids])\n","    try:\n","        auc_plain = metrics.roc_auc_score(concat_y, concat)\n","        auc_flip  = metrics.roc_auc_score(concat_y, 1.0 - concat)\n","        if auc_flip > auc_plain:\n","            for v in vids:\n","                S[v][\"p\"] = 1.0 - np.array(S[v][\"p\"], dtype=np.float32)\n","    except Exception:\n","        pass\n","\n","    # Filters + aggregation\n","    def agg_perc90(x): return float(np.percentile(x, 90))\n","    vscores, y = [], []\n","    for v in vids:\n","        x    = np.array(S[v][\"p\"],     dtype=np.float32)\n","        conf = np.array(S[v][\"conf\"],  dtype=np.float32)\n","        area = np.array(S[v][\"area\"],  dtype=np.float32)\n","        shp  = np.array(S[v][\"sharp\"], dtype=np.float32)\n","\n","        m = np.ones_like(x, dtype=bool)\n","        if CONF_MIN > 0.0: m &= (conf >= CONF_MIN)\n","        if SIZE_MIN > 0.0: m &= (area >= SIZE_MIN)\n","        if TAU > 0.0:      m &= (np.abs(x - 0.5) >= TAU)\n","        xf = x[m] if m.any() else x\n","        sh = shp[m] if m.any() else shp\n","\n","        if SHARP_TOP < 1.0 and xf.size > 1:\n","            k = max(1, int(math.ceil(xf.size * SHARP_TOP)))\n","            idx = np.argsort(sh)[-k:]\n","            xf = xf[idx]\n","\n","        vscores.append(agg_perc90(xf))\n","        y.append(labels_by_video[v])\n","\n","    y = np.array(y, dtype=np.int64)\n","    s = np.array(vscores, dtype=np.float32)\n","\n","    # Metrics\n","    try:\n","        auc_v = metrics.roc_auc_score(y, s)\n","    except ValueError:\n","        auc_v = 0.5\n","    eer_v = compute_eer(y, s)\n","    try:\n","        ap_v = metrics.average_precision_score(y, s)\n","    except ValueError:\n","        ap_v = float(\"nan\")\n","\n","    print(f\"AUC={auc_v:.4f} | EER={eer_v:.4f} | AP={ap_v:.4f}\")\n"]},{"cell_type":"code","source":["# =========================\n","# FFD (Xception) — FACE-ALIGNED ENSEMBLE + QUALITY FILTERS (metrics-only)\n","# Dataset: /content/drive/.../balanced_frames_FF++/{real,fake}\n","# Prints ONLY:\n","#   FFD model is loaded\n","#   AUC=… | EER=… | AP=…\n","# Notes:\n","# - Faster image loading via cv2.imdecode to avoid I/O stalls.\n","# - Stronger settings than before (MTCNN on, richer TTA + smart aggregation).\n","# =========================\n","\n","# Quiet installs (no extra prints)\n","import sys, subprocess, os, warnings\n","subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                \"timm\", \"torchvision\", \"scikit-learn\", \"pillow\",\n","                \"opencv-python\", \"facenet-pytorch\"],\n","               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n","\n","# Drive mount (silent if already mounted)\n","if not os.path.ismount(\"/content/drive\"):\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# -------------------------\n","# Config\n","# -------------------------\n","import math, random\n","from pathlib import Path\n","from collections import defaultdict\n","\n","import numpy as np\n","from PIL import Image, ImageFile\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","from sklearn import metrics\n","\n","import cv2\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import timm\n","from torchvision import transforms\n","from facenet_pytorch import MTCNN\n","\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","DATA_REAL = f\"{DRIVE_ROOT}/balanced_frames_FF++/real\"\n","DATA_FAKE = f\"{DRIVE_ROOT}/balanced_frames_FF++/fake\"\n","WEIGHTS_PATH = f\"{DRIVE_ROOT}/DeepfakeBench_weights/ffd_best.pth\"  # your saved weights\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","SEED = 42\n","\n","# Inference knobs (accuracy-leaning but GPU-friendly)\n","IMG_SIZE = 299\n","FRAME_CAP_PER_VIDEO = 160     # ↑ helps AUC with controlled cost\n","BATCH_SIZE_IMAGES   = 8\n","FORWARD_CHUNK       = 32\n","\n","# TTA/Ensemble settings\n","SCALES_FACE   = [288, 320, 352]   # multi-scale face crops\n","SCALES_FRAME  = [352]             # global context branch\n","USE_HFLIP     = True\n","WSET = [                          # (face, face+CLAHE, frame)\n","    (1.0, 0.0, 0.0),\n","    (0.85, 0.15, 0.0),\n","    (0.8, 0.2, 0.0),\n","    (0.7, 0.2, 0.1),\n","    (0.6, 0.3, 0.1),\n","    (0.5, 0.3, 0.2),\n","    (0.45, 0.35, 0.20),\n","]\n","\n","# Filters & aggregators (search a compact, strong set)\n","TAU_LIST       = [0.0, 0.1, 0.2, 0.3]\n","SHARP_TOP_LIST = [1.0, 0.8, 0.6]\n","CONF_MIN_LIST  = [0.85, 0.90]     # MTCNN confidence thresholds\n","SIZE_MIN_LIST  = [0.03, 0.06]     # min face area ratio (bbox/img)\n","AGGREGATORS    = [\"median\", \"perc90\", \"perc95\", \"top10\", \"trim10\", \"wtop20p\"]\n","\n","# -------------------------\n","# Reproducibility\n","# -------------------------\n","def set_seed(seed=SEED):\n","    random.seed(seed); np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","set_seed()\n","torch.set_grad_enabled(False)\n","cv2.setNumThreads(0)\n","\n","# -------------------------\n","# Fast I/O helpers\n","# -------------------------\n","VALID_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n","\n","def list_images(folder):\n","    folder = Path(folder)\n","    return sorted([p for p in folder.iterdir() if p.suffix.lower() in VALID_EXTS])\n","\n","def guess_video_name_from_path(p: Path):\n","    s = p.stem\n","    if \"_\" in s: return s.rsplit(\"_\", 1)[0]\n","    if \"-\" in s: return s.rsplit(\"-\", 1)[0]\n","    return s\n","\n","def fast_open_rgb(path: Path):\n","    # Fast path via cv2.imdecode; fallback to PIL if needed\n","    try:\n","        data = np.fromfile(str(path), dtype=np.uint8)\n","        img = cv2.imdecode(data, cv2.IMREAD_COLOR)\n","        if img is None:\n","            raise ValueError(\"cv2.imdecode failed\")\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        return Image.fromarray(img)\n","    except Exception:\n","        try:\n","            return Image.open(path).convert(\"RGB\")\n","        except Exception:\n","            return Image.fromarray(np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8))\n","\n","def build_samples(real_dir, fake_dir, cap=FRAME_CAP_PER_VIDEO):\n","    samples = []  # (path, label, video)\n","    def gather(dir_path, label):\n","        paths = list_images(dir_path)\n","        groups = defaultdict(list)\n","        for p in paths:\n","            groups[guess_video_name_from_path(p)].append(p)\n","        for vname, plist in groups.items():\n","            plist = sorted(plist)\n","            if cap is not None and len(plist) > cap:\n","                idxs = np.linspace(0, len(plist)-1, num=cap, dtype=int)\n","                plist = [plist[i] for i in idxs]\n","            for p in plist:\n","                samples.append((str(p), label, vname))\n","    gather(real_dir, 0); gather(fake_dir, 1)\n","    return samples\n","\n","samples = build_samples(DATA_REAL, DATA_FAKE)\n","\n","# -------------------------\n","# Face detector (MTCNN) & helpers\n","# -------------------------\n","mtcnn = MTCNN(keep_all=False, device=DEVICE if torch.cuda.is_available() else \"cpu\",\n","              min_face_size=60, thresholds=[0.6, 0.7, 0.7])\n","\n","def align_face_with_meta(img: Image.Image, margin=0.25):\n","    w, h = img.size\n","    boxes, probs = mtcnn.detect(img, landmarks=False)\n","    if boxes is not None and len(boxes) > 0:\n","        areas = [(b[2]-b[0])*(b[3]-b[1]) for b in boxes]\n","        i = int(np.argmax(areas))\n","        x1,y1,x2,y2 = boxes[i]\n","        conf = float(probs[i]) if probs is not None else 0.0\n","        area_ratio = float(areas[i] / max(1.0, (w*h)))\n","        bw, bh = x2-x1, y2-y1\n","        cx, cy = x1 + bw/2.0, y1 + bh/2.0\n","        side = max(bw, bh) * (1.0 + margin)\n","        x1n = int(max(0, cx - side/2.0)); y1n = int(max(0, cy - side/2.0))\n","        x2n = int(min(w, cx + side/2.0)); y2n = int(min(h, cy + side/2.0))\n","        bw2, bh2 = x2n-x1n, y2n-y1n\n","        if bw2 != bh2:\n","            d = abs(bw2 - bh2)\n","            if bw2 < bh2:\n","                x1n = max(0, x1n - d//2); x2n = min(w, x2n + (d - d//2))\n","            else:\n","                y1n = max(0, y1n - d//2); y2n = min(h, y2n + (d - d//2))\n","        crop = img.crop((x1n, y1n, x2n, y2n))\n","        return crop, conf, area_ratio\n","    # fallback center-square\n","    side = min(w, h)\n","    l = (w - side)//2; t = (h - side)//2\n","    return img.crop((l, t, l + side, t + side)), 0.0, 0.0\n","\n","def sharpness_score(pil_img: Image.Image):\n","    g = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2GRAY)\n","    g = cv2.resize(g, (128,128), interpolation=cv2.INTER_AREA)\n","    return float(cv2.Laplacian(g, cv2.CV_64F).var())\n","\n","_CLAHE = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","def apply_clahe_color(pil_img: Image.Image):\n","    lab = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2LAB)\n","    l,a,b = cv2.split(lab)\n","    l2 = _CLAHE.apply(l)\n","    rgb = cv2.cvtColor(cv2.merge([l2,a,b]), cv2.COLOR_LAB2RGB)\n","    return Image.fromarray(rgb)\n","\n","# -------------------------\n","# TTA transforms\n","# -------------------------\n","IMAGENET_MEAN, IMAGENET_STD = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n","to_tensor_norm = transforms.Compose([\n","    transforms.Resize(IMG_SIZE),\n","    transforms.CenterCrop(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n","])\n","\n","def make_crops(pil_img, scales, hflip=USE_HFLIP):\n","    crops = []\n","    for s in scales:\n","        w,h = pil_img.size\n","        scale = s / min(w, h)\n","        new_size = (int(round(w*scale)), int(round(h*scale)))\n","        img_res = pil_img.resize(new_size, Image.BILINEAR)\n","        left = (img_res.size[0] - s)//2; top = (img_res.size[1] - s)//2\n","        cc = img_res.crop((left, top, left + s, top + s))\n","        crops.append(cc)\n","        if hflip:\n","            crops.append(cc.transpose(Image.FLIP_LEFT_RIGHT))\n","    return crops\n","\n","# -------------------------\n","# FFD model (Xception backbone + regression mask on feature map)\n","# -------------------------\n","class DepthwiseSeparableConv(nn.Module):\n","    def __init__(self, c_in, c_out, k=3, s=1, p=1, bias=False):\n","        super().__init__()\n","        self.dw = nn.Conv2d(c_in, c_in, kernel_size=k, stride=s, padding=p, groups=c_in, bias=bias)\n","        self.pw = nn.Conv2d(c_in, c_out, kernel_size=1, stride=1, padding=0, bias=bias)\n","    def forward(self, x):\n","        return self.pw(self.dw(x))\n","\n","class FFD_Xception(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        self.model = timm.create_model(\"xception\", pretrained=False, num_classes=num_classes)\n","        with torch.no_grad():\n","            fm = self.model.forward_features(torch.zeros(1,3,IMG_SIZE,IMG_SIZE))\n","        c_in = int(fm.shape[1])\n","        self.map = nn.Sequential(DepthwiseSeparableConv(c_in, 1, 3, 1, 1, False), nn.Sigmoid())\n","    def forward(self, x):\n","        feats = self.model.forward_features(x)       # BxCxHxW\n","        mask  = self.map(feats)                      # Bx1xHxW\n","        logits = self.model.forward_head(feats*mask, pre_logits=False)\n","        prob = torch.softmax(logits, dim=1)[:, 1]\n","        return {\"prob\": prob}\n","\n","def load_ffd_weights_strong(model: nn.Module, path: str):\n","    ckpt = torch.load(path, map_location=\"cpu\")\n","    incoming = ckpt[\"state_dict\"] if (isinstance(ckpt, dict) and \"state_dict\" in ckpt) else ckpt\n","    target = model.model.state_dict()\n","    def candidates(k):\n","        keys=[k]\n","        for pref in [\"module.\",\"backbone.\",\"model.\"]:\n","            if k.startswith(pref): keys.append(k[len(pref):])\n","        if k.startswith(\"fc.\"): keys.append(\"classifier.\"+k[3:])\n","        return list(dict.fromkeys(keys))\n","    new_state={}\n","    for k,v in incoming.items():\n","        for k2 in candidates(k):\n","            if k2 in target:\n","                tv=target[k2]\n","                if isinstance(v, torch.Tensor) and v.shape==tv.shape:\n","                    new_state[k2]=v; break\n","                if isinstance(v, torch.Tensor) and v.ndim==2 and tv.ndim==4 and tv.shape[2]==1 and tv.shape[3]==1 \\\n","                   and v.shape[0]==tv.shape[0] and v.shape[1]==tv.shape[1]:\n","                    new_state[k2]=v.unsqueeze(-1).unsqueeze(-1); break\n","    model.model.load_state_dict(new_state, strict=False)\n","\n","ffd = FFD_Xception(num_classes=2).to(DEVICE)\n","try:\n","    load_ffd_weights_strong(ffd, WEIGHTS_PATH)\n","finally:\n","    print(\"FFD model is loaded\")\n","ffd.eval()\n","\n","def forward_in_chunks(x, chunk=FORWARD_CHUNK):\n","    outs = []\n","    amp_ctx = torch.cuda.amp.autocast(enabled=torch.cuda.is_available())\n","    with amp_ctx:\n","        for i in range(0, x.size(0), chunk):\n","            outs.append(ffd(x[i:i+chunk].to(DEVICE))[\"prob\"].detach().float().cpu())\n","    return torch.cat(outs, dim=0).numpy()\n","\n","# -------------------------\n","# Inference — gather per-frame scores with TTA\n","# -------------------------\n","records = []  # {video,label,p1,p2,p3,conf,area,sharp}\n","with torch.no_grad():\n","    for i in range(0, len(samples), BATCH_SIZE_IMAGES):\n","        batch = samples[i:i + BATCH_SIZE_IMAGES]\n","\n","        t_face_list, t_facec_list, t_frame_list = [], [], []\n","        meta, labels, vnames = [], [], []\n","\n","        for path, lab, vname in batch:\n","            img = fast_open_rgb(Path(path))\n","            face, conf, area = align_face_with_meta(img, margin=0.25)\n","            shp = sharpness_score(face)\n","\n","            # Face-aligned crops\n","            c_face  = [to_tensor_norm(c) for c in make_crops(face, SCALES_FACE, USE_HFLIP)]\n","            if not c_face: continue\n","            t_face_list.append(torch.stack(c_face, 0))\n","\n","            # Face + CLAHE\n","            face_c  = apply_clahe_color(face)\n","            c_facec = [to_tensor_norm(c) for c in make_crops(face_c, SCALES_FACE, USE_HFLIP)]\n","            t_facec_list.append(torch.stack(c_facec, 0))\n","\n","            # Global frame branch\n","            c_frame = [to_tensor_norm(c) for c in make_crops(img, SCALES_FRAME, USE_HFLIP)]\n","            t_frame_list.append(torch.stack(c_frame, 0))\n","\n","            meta.append((conf, area, shp))\n","            labels.append(lab); vnames.append(vname)\n","\n","        if not labels:\n","            continue\n","\n","        # FACE\n","        Xf  = torch.cat(t_face_list,  dim=0)\n","        pf  = forward_in_chunks(Xf,  chunk=FORWARD_CHUNK); Cf  = t_face_list[0].size(0)\n","        pf_img = pf.reshape(len(labels), Cf).mean(axis=1)\n","\n","        # FACE+CLAHE\n","        Xfc = torch.cat(t_facec_list, dim=0)\n","        pfc = forward_in_chunks(Xfc, chunk=FORWARD_CHUNK); Cfc = t_facec_list[0].size(0)\n","        pfc_img = pfc.reshape(len(labels), Cfc).mean(axis=1)\n","\n","        # FRAME\n","        Xg  = torch.cat(t_frame_list,  dim=0)\n","        pg  = forward_in_chunks(Xg,  chunk=FORWARD_CHUNK); Cg  = t_frame_list[0].size(0)\n","        pg_img = pg.reshape(len(labels), Cg).mean(axis=1)\n","\n","        for j in range(len(labels)):\n","            conf, area, shp = meta[j]\n","            records.append({\n","                \"video\": vnames[j],\n","                \"label\": int(labels[j]),\n","                \"p1\": float(pf_img[j]),\n","                \"p2\": float(pfc_img[j]),\n","                \"p3\": float(pg_img[j]),\n","                \"conf\": float(conf),\n","                \"area\": float(area),\n","                \"sharp\": float(shp),\n","            })\n","\n","# -------------------------\n","# Post-process search (compact but strong)\n","# -------------------------\n","if not records:\n","    print(\"AUC=0.5000 | EER=0.5000 | AP=0.5000\")\n","else:\n","    vids = sorted({r[\"video\"] for r in records})\n","    labels_by_video = {v: None for v in vids}\n","    P = {v: {\"p1\":[], \"p2\":[], \"p3\":[], \"conf\":[], \"area\":[], \"sharp\":[]} for v in vids}\n","    for r in records:\n","        v = r[\"video\"]\n","        labels_by_video[v] = r[\"label\"]\n","        for k in [\"p1\",\"p2\",\"p3\",\"conf\",\"area\",\"sharp\"]:\n","            P[v][k].append(r[k])\n","    y_vec = np.array([labels_by_video[v] for v in vids], dtype=np.int64)\n","\n","    def agg_median(x): return float(np.median(x))\n","    def agg_perc90(x): return float(np.percentile(x, 90))\n","    def agg_perc95(x): return float(np.percentile(x, 95))\n","    def agg_top10(x):\n","        k = max(1, int(math.ceil(len(x)*0.10))); return float(np.mean(np.sort(x)[-k:]))\n","    def agg_trim10(x):\n","        n=len(x); k=int(np.floor(n*0.10))\n","        if n-2*k<=0: return float(np.median(x))\n","        xs=np.sort(x)[k:n-k]; return float(np.mean(xs))\n","    def agg_wtop20p(x):\n","        k = max(1, int(math.ceil(len(x)*0.20))); top = np.sort(x)[-k:]\n","        w = np.linspace(1.0, 2.0, num=top.size); w = w/w.sum()\n","        return float((top*w).sum())\n","\n","    agg_funcs = {\"median\":agg_median,\"perc90\":agg_perc90,\"perc95\":agg_perc95,\n","                 \"top10\":agg_top10,\"trim10\":agg_trim10,\"wtop20p\":agg_wtop20p}\n","\n","    def compute_eer(y_true, y_score):\n","        fpr, tpr, _ = metrics.roc_curve(y_true, y_score)\n","        fnr = 1 - tpr\n","        i = int(np.nanargmin(np.abs(fnr - fpr)))\n","        return float((fpr[i] + fnr[i]) / 2.0)\n","\n","    best_auc, best_scores = -1.0, None\n","\n","    for w1, w2, w3 in WSET:\n","        # per-video combined sequences\n","        comb = {}\n","        for v in vids:\n","            p1 = np.array(P[v][\"p1\"], dtype=np.float32)\n","            p2 = np.array(P[v][\"p2\"], dtype=np.float32)\n","            p3 = np.array(P[v][\"p3\"], dtype=np.float32)\n","            comb[v] = w1*p1 + w2*p2 + w3*p3\n","\n","        # flip orientation if it improves frame-level AUC proxy\n","        concat = np.concatenate([comb[v] for v in vids])\n","        concat_y = np.concatenate([[labels_by_video[v]]*len(comb[v]) for v in vids])\n","        try:\n","            flip = metrics.roc_auc_score(concat_y, 1.0 - concat) > metrics.roc_auc_score(concat_y, concat)\n","        except Exception:\n","            flip = False\n","        if flip:\n","            for v in vids:\n","                comb[v] = 1.0 - comb[v]\n","\n","        for tau in TAU_LIST:\n","            for sharp_top in SHARP_TOP_LIST:\n","                for conf_min in CONF_MIN_LIST:\n","                    for size_min in SIZE_MIN_LIST:\n","                        for agg_name in AGGREGATORS:\n","                            fn = agg_funcs[agg_name]\n","                            vs = []\n","                            for v in vids:\n","                                arr   = np.array(comb[v], dtype=np.float32)\n","                                conf  = np.array(P[v][\"conf\"],  dtype=np.float32)\n","                                area  = np.array(P[v][\"area\"],  dtype=np.float32)\n","                                sharp = np.array(P[v][\"sharp\"], dtype=np.float32)\n","\n","                                m = np.ones_like(arr, dtype=bool)\n","                                if conf_min > 0.0: m &= (conf >= conf_min)\n","                                if size_min > 0.0: m &= (area >= size_min)\n","                                if tau > 0.0:      m &= (np.abs(arr - 0.5) >= tau)\n","                                arr_f   = arr[m]   if m.any() else arr\n","                                sharp_f = sharp[m] if m.any() else sharp\n","\n","                                if sharp_top < 1.0 and arr_f.size > 1:\n","                                    k = max(1, int(math.ceil(arr_f.size * sharp_top)))\n","                                    idx = np.argsort(sharp_f)[-k:]\n","                                    arr_f = arr_f[idx]\n","\n","                                vs.append(fn(arr_f))\n","\n","                            vs = np.array(vs, dtype=np.float32)\n","                            try:\n","                                auc = metrics.roc_auc_score(y_vec, vs)\n","                            except ValueError:\n","                                auc = 0.5\n","                            if auc > best_auc:\n","                                best_auc, best_scores, best_labels = auc, vs, y_vec\n","\n","    try: auc_v = metrics.roc_auc_score(best_labels, best_scores)\n","    except ValueError: auc_v = 0.5\n","    eer_v = compute_eer(best_labels, best_scores)\n","    try: ap_v = metrics.average_precision_score(best_labels, best_scores)\n","    except ValueError: ap_v = float(\"nan\")\n","\n","    print(f\"AUC={auc_v:.4f} | EER={eer_v:.4f} | AP={ap_v:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ej4FjlfTjF4J","executionInfo":{"status":"ok","timestamp":1756751985320,"user_tz":-120,"elapsed":400696,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"a5f7fddf-a49a-4924-b39a-c878ef797bdf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FFD model is loaded\n","AUC=0.7220 | EER=0.3235 | AP=0.7477\n"]}]},{"cell_type":"code","source":["# === FFD (Xception) — Large results table (balanced_frames_FF++) ===\n","# Columns:\n","# dataset, detector, video_name, true_label, n_frames, n_correct_frames, n_wrong_frames,\n","# frame_accuracy, avg_prob_fake, std_prob_fake, video_pred_by_avg, video_correct_by_avg,\n","# video_pred_by_majority, video_correct_by_majority\n","#\n","# Prints FULL rows with no column breaks. Uses your in-memory `records` (and `samples` if present).\n","\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_curve, roc_auc_score\n","\n","# ----- safety -----\n","if \"records\" not in globals() or not records:\n","    raise SystemExit(\"No 'records' found. Run the FFD scoring cell first to populate frame-level 'records'.\")\n","\n","DATASET_NAME  = \"balanced_frames_FF++\"\n","DETECTOR_NAME = \"FFD(Xception)\"\n","\n","# ----- build frame-level DataFrame from records -----\n","df = pd.DataFrame(records).rename(columns={\"video\":\"video_name\",\"label\":\"true_label\"})\n","need = {\"video_name\",\"true_label\",\"p1\",\"p2\",\"p3\"}\n","missing = need - set(df.columns)\n","if missing:\n","    raise SystemExit(f\"'records' missing columns: {missing}\")\n","\n","df[\"video_name\"] = df[\"video_name\"].astype(str)\n","df[\"true_label\"] = pd.to_numeric(df[\"true_label\"], errors=\"coerce\").fillna(0).astype(int).clip(0,1)\n","\n","# ensemble probability (same weights used for metrics run: face, face+CLAHE, frame)\n","df[\"prob_fake\"] = (0.7*pd.to_numeric(df[\"p1\"]) + 0.2*pd.to_numeric(df[\"p2\"]) + 0.1*pd.to_numeric(df[\"p3\"])).astype(float)\n","\n","# orientation: flip if it improves frame-level AUC (safe proxy)\n","y_tmp = df[\"true_label\"].to_numpy(dtype=int)\n","s_tmp = df[\"prob_fake\"].to_numpy(dtype=float)\n","try:\n","    if roc_auc_score(y_tmp, 1.0 - s_tmp) > roc_auc_score(y_tmp, s_tmp):\n","        df[\"prob_fake\"] = 1.0 - df[\"prob_fake\"]\n","except Exception:\n","    pass\n","\n","# ----- master video list (ensures one row per video) -----\n","if \"samples\" in globals() and samples:\n","    vids_master = {(str(v), int(y)) for _, y, v in samples}\n","    df_all = pd.DataFrame(sorted(list(vids_master)), columns=[\"video_name\",\"true_label\"])\n","else:\n","    df_all = (df.groupby(\"video_name\", sort=False)[\"true_label\"].first()\n","                .reset_index()[[\"video_name\",\"true_label\"]])\n","\n","# ----- thresholds -----\n","# frame-level threshold via Youden's J\n","y_frame = df[\"true_label\"].to_numpy(dtype=int)\n","s_frame = df[\"prob_fake\"].to_numpy(dtype=float)\n","if len(np.unique(y_frame)) >= 2:\n","    fpr, tpr, thr = roc_curve(y_frame, s_frame)\n","    t_frame = float(thr[np.nanargmax(tpr - fpr)])\n","else:\n","    t_frame = 0.5\n","\n","# per-video average threshold chosen to MAXIMIZE video accuracy\n","avg_df = (df.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"]\n","            .mean().rename(\"avg_prob_fake\").reset_index())\n","y_avg = avg_df[\"true_label\"].to_numpy(dtype=int)\n","s_avg = avg_df[\"avg_prob_fake\"].to_numpy(dtype=float)\n","if len(np.unique(y_avg)) >= 2:\n","    fpr2, tpr2, thr2 = roc_curve(y_avg, s_avg)\n","    uniq = np.unique(s_avg)\n","    mids = (uniq[:-1] + uniq[1:]) / 2.0 if len(uniq) > 1 else np.array([])\n","    cand = np.unique(np.concatenate([thr2, mids, [0.0, 1.0]]))\n","    accs = [(((s_avg >= t).astype(int) == y_avg).mean()) for t in cand]\n","    t_avg = float(cand[int(np.argmax(accs))])\n","else:\n","    t_avg = 0.5\n","\n","# ----- frame-level predictions & counts (guaranteed consistent) -----\n","df[\"frame_pred_int\"] = (df[\"prob_fake\"] >= t_frame).astype(int)\n","\n","def _per_video_counts(g):\n","    n = int(len(g))\n","    n_correct = int((g[\"frame_pred_int\"] == g[\"true_label\"]).sum())\n","    n_wrong   = int(n - n_correct)  # ensure sum equals n\n","    acc = float(n_correct / n) if n > 0 else 0.0\n","    return pd.Series({\n","        \"n_frames\": n,\n","        \"n_correct_frames\": n_correct,\n","        \"n_wrong_frames\": n_wrong,\n","        \"frame_accuracy\": acc\n","    })\n","\n","cnts = (df.groupby([\"video_name\",\"true_label\"], sort=False)\n","          .apply(_per_video_counts).reset_index())\n","\n","# ----- per-video avg/std + decisions (avg & majority) -----\n","stats = (df.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"]\n","           .agg(avg_prob_fake=\"mean\", std_prob_fake=\"std\")\n","           .fillna({\"std_prob_fake\":0.0}).reset_index())\n","\n","# average-rule → map to 'real'/'fake'\n","stats[\"video_pred_by_avg_int\"]    = (stats[\"avg_prob_fake\"] >= t_avg).astype(int)\n","stats[\"video_correct_by_avg\"]     = (stats[\"video_pred_by_avg_int\"] == stats[\"true_label\"]).astype(int)\n","stats[\"video_pred_by_avg\"]        = stats[\"video_pred_by_avg_int\"].map({0:\"real\",1:\"fake\"})\n","stats = stats.drop(columns=[\"video_pred_by_avg_int\"])\n","\n","# majority rule (ties → fake) using SAME frame predictions\n","maj = (df.groupby(\"video_name\", sort=False)[\"frame_pred_int\"]\n","         .agg(lambda a: 1 if int(a.sum()) >= int(a.size - a.sum()) else 0)\n","         .rename(\"video_pred_by_majority_int\").reset_index())\n","maj = maj.merge(df.groupby(\"video_name\", sort=False)[\"true_label\"].first().reset_index(),\n","                on=\"video_name\", how=\"left\")\n","maj[\"video_correct_by_majority\"] = (maj[\"video_pred_by_majority_int\"] == maj[\"true_label\"]).astype(int)\n","maj[\"video_pred_by_majority\"]    = maj[\"video_pred_by_majority_int\"].map({0:\"real\",1:\"fake\"})\n","maj = maj.drop(columns=[\"video_pred_by_majority_int\"])\n","\n","# ----- assemble full table and include any videos missing scores -----\n","table_ffd_ffpp = (df_all.merge(stats, on=[\"video_name\",\"true_label\"], how=\"left\")\n","                        .merge(cnts, on=[\"video_name\",\"true_label\"], how=\"left\")\n","                        .merge(maj[[\"video_name\",\"video_pred_by_majority\",\"video_correct_by_majority\"]],\n","                               on=\"video_name\", how=\"left\")\n","                        .fillna({\n","                            \"avg_prob_fake\":0.0, \"std_prob_fake\":0.0,\n","                            \"n_frames\":0, \"n_correct_frames\":0, \"n_wrong_frames\":0, \"frame_accuracy\":0.0,\n","                            \"video_pred_by_avg\":\"real\", \"video_correct_by_avg\":0,\n","                            \"video_pred_by_majority\":\"real\", \"video_correct_by_majority\":0\n","                        })\n","                        .assign(\n","                            dataset=DATASET_NAME,\n","                            detector=DETECTOR_NAME,\n","                            # pretty labels\n","                            true_label=lambda d: d[\"true_label\"].map({0:\"real\",1:\"fake\"}),\n","                            # ensure dtypes\n","                            n_frames=lambda d: d[\"n_frames\"].astype(int),\n","                            n_correct_frames=lambda d: d[\"n_correct_frames\"].astype(int),\n","                            n_wrong_frames=lambda d: d[\"n_wrong_frames\"].astype(int),\n","                            frame_accuracy=lambda d: d[\"frame_accuracy\"].astype(float),\n","                            avg_prob_fake=lambda d: d[\"avg_prob_fake\"].astype(float),\n","                            std_prob_fake=lambda d: d[\"std_prob_fake\"].astype(float),\n","                            video_correct_by_avg=lambda d: d[\"video_correct_by_avg\"].astype(int),\n","                            video_correct_by_majority=lambda d: d[\"video_correct_by_majority\"].astype(int),\n","                        )[[  # exact order requested\n","                            \"dataset\",\"detector\",\"video_name\",\"true_label\",\n","                            \"n_frames\",\"n_correct_frames\",\"n_wrong_frames\",\"frame_accuracy\",\n","                            \"avg_prob_fake\",\"std_prob_fake\",\n","                            \"video_pred_by_avg\",\"video_correct_by_avg\",\n","                            \"video_pred_by_majority\",\"video_correct_by_majority\"\n","                        ]]\n","                        .sort_values([\"true_label\",\"video_name\"], kind=\"stable\")\n","                        .reset_index(drop=True)\n",")\n","\n","# ----- print ALL rows, no column breaks -----\n","pd.set_option(\"display.max_rows\", 100000)\n","pd.set_option(\"display.max_columns\", 1000)\n","pd.set_option(\"display.width\", 10000)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","pd.set_option(\"display.float_format\", lambda x: f\"{x:.6f}\")\n","\n","print(table_ffd_ffpp.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L5Y-MVFWlcf8","executionInfo":{"status":"ok","timestamp":1756752108511,"user_tz":-120,"elapsed":364,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"62c1ab3c-95fb-4b6f-e89d-fe9e8544bea8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["             dataset      detector                            video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","balanced_frames_FF++ FFD(Xception)                               000_003       fake        20                20               0        1.000000       0.508533       0.000419              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               010_005       fake        20                19               1        0.950000       0.509131       0.000805              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               011_805       fake        20                 1              19        0.050000       0.506318       0.000541              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               012_026       fake        20                13               7        0.650000       0.507326       0.000466              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               013_883       fake        20                20               0        1.000000       0.509187       0.000607              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               014_790       fake        20                 0              20        0.000000       0.505967       0.000231              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               015_919       fake        20                13               7        0.650000       0.507324       0.000713              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               016_209       fake        20                 2              18        0.100000       0.506442       0.000387              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               017_803       fake        20                19               1        0.950000       0.508214       0.000507              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               018_019       fake        20                17               3        0.850000       0.507694       0.000556              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               019_018       fake        20                 0              20        0.000000       0.506492       0.000273              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               020_344       fake        20                12               8        0.600000       0.507187       0.000316              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               021_312       fake        20                 6              14        0.300000       0.506953       0.000429              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               022_489       fake        20                17               3        0.850000       0.508259       0.000793              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               023_923       fake        20                17               3        0.850000       0.507344       0.000602              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               024_073       fake        20                18               2        0.900000       0.508384       0.000915              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               025_067       fake        20                20               0        1.000000       0.508303       0.000873              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               026_012       fake        20                11               9        0.550000       0.507149       0.000283              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               027_009       fake        20                 1              19        0.050000       0.506417       0.000395              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               028_068       fake        20                20               0        1.000000       0.509163       0.000649              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               029_048       fake        20                18               2        0.900000       0.507889       0.000507              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               030_193       fake        20                 0              20        0.000000       0.506345       0.000252              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               031_163       fake        20                20               0        1.000000       0.509696       0.000750              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               032_944       fake        20                13               7        0.650000       0.507226       0.000381              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               033_097       fake        20                 2              18        0.100000       0.506471       0.000548              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               034_590       fake        20                20               0        1.000000       0.508992       0.000707              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               035_036       fake        20                20               0        1.000000       0.510586       0.000469              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               036_035       fake        20                20               0        1.000000       0.508828       0.000750              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               037_072       fake        20                12               8        0.600000       0.507349       0.000584              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               038_125       fake        20                11               9        0.550000       0.507073       0.000290              real                     0                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               039_058       fake        20                 8              12        0.400000       0.506968       0.000541              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               040_997       fake        20                 0              20        0.000000       0.506145       0.000234              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               041_063       fake        20                20               0        1.000000       0.509093       0.000437              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               042_084       fake        20                19               1        0.950000       0.508747       0.000858              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               043_110       fake        20                20               0        1.000000       0.508094       0.000559              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               044_945       fake        20                 3              17        0.150000       0.506605       0.000444              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               045_889       fake        20                 5              15        0.250000       0.506869       0.000328              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               046_904       fake        20                12               8        0.600000       0.507224       0.000466              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               047_862       fake        20                18               2        0.900000       0.507744       0.000677              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               048_029       fake        20                16               4        0.800000       0.507590       0.000525              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               049_946       fake        20                15               5        0.750000       0.507375       0.000409              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               050_059       fake        20                20               0        1.000000       0.510505       0.000564              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               051_332       fake        20                11               9        0.550000       0.507145       0.000808              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               052_108       fake        20                 0              20        0.000000       0.505700       0.000118              real                     0                   real                          0\n","balanced_frames_FF++ FFD(Xception)                               053_095       fake        20                15               5        0.750000       0.507367       0.000258              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               054_071       fake        20                20               0        1.000000       0.508507       0.000421              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               055_147       fake        20                16               4        0.800000       0.507623       0.000548              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               056_996       fake        20                17               3        0.850000       0.507636       0.000662              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               057_070       fake        20                17               3        0.850000       0.507706       0.000734              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               058_039       fake        20                20               0        1.000000       0.509798       0.000626              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)                               059_050       fake        20                20               0        1.000000       0.508194       0.000477              fake                     1                   fake                          1\n","balanced_frames_FF++ FFD(Xception)    04__walking_outside_cafe_disgusted       real        20                 9              11        0.450000       0.507142       0.000550              real                     1                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                   05__exit_phone_room       real        20                19               1        0.950000       0.506155       0.000430              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                     05__hugging_happy       real        20                18               2        0.900000       0.506600       0.000471              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                       05__kitchen_pan       real        20                20               0        1.000000       0.505971       0.000288              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                     05__kitchen_still       real        20                20               0        1.000000       0.505972       0.000219              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)      05__outside_talking_pan_laughing       real        20                20               0        1.000000       0.506412       0.000441              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)    05__outside_talking_still_laughing       real        20                20               0        1.000000       0.506379       0.000262              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)               05__podium_speech_happy       real        20                19               1        0.950000       0.506653       0.000283              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)              05__talking_against_wall       real        20                20               0        1.000000       0.506357       0.000265              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)              05__walk_down_hall_angry       real        20                17               3        0.850000       0.506378       0.000573              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception) 05__walking_down_street_outside_angry       real        20                20               0        1.000000       0.505830       0.000194              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)    05__walking_outside_cafe_disgusted       real        20                20               0        1.000000       0.506369       0.000264              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                   06__exit_phone_room       real        20                15               5        0.750000       0.506883       0.000717              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                     06__hugging_happy       real        20                 8              12        0.400000       0.507332       0.000661              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                       06__kitchen_pan       real        20                17               3        0.850000       0.506698       0.000547              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                     06__kitchen_still       real        20                18               2        0.900000       0.506774       0.000412              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)      06__outside_talking_pan_laughing       real        20                13               7        0.650000       0.506799       0.000769              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)    06__outside_talking_still_laughing       real        20                11               9        0.550000       0.507140       0.000649              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)               06__podium_speech_happy       real        20                 7              13        0.350000       0.507379       0.000477              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)              06__talking_against_wall       real        20                 8              12        0.400000       0.507300       0.000624              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)               06__talking_angry_couch       real        20                13               7        0.650000       0.506952       0.000922              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)              06__walk_down_hall_angry       real        20                 7              13        0.350000       0.507559       0.001142              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)     06__walking_and_outside_surprised       real        20                17               3        0.850000       0.506540       0.000485              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)  06__walking_down_indoor_hall_disgust       real        20                 5              15        0.250000       0.507648       0.000979              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception) 06__walking_down_street_outside_angry       real        20                 6              14        0.300000       0.507360       0.000796              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)    06__walking_outside_cafe_disgusted       real        20                20               0        1.000000       0.506406       0.000333              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                   07__exit_phone_room       real        20                 4              16        0.200000       0.508580       0.001300              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                     07__hugging_happy       real        20                 7              13        0.350000       0.507524       0.000937              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                       07__kitchen_pan       real        20                 2              18        0.100000       0.508618       0.000853              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                     07__kitchen_still       real        20                 0              20        0.000000       0.508908       0.000685              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)      07__outside_talking_pan_laughing       real        20                 5              15        0.250000       0.507170       0.000840              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)    07__outside_talking_still_laughing       real        20                 8              12        0.400000       0.507321       0.000418              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)               07__podium_speech_happy       real        20                 2              18        0.100000       0.508312       0.001072              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)               07__secret_conversation       real        20                14               6        0.700000       0.506873       0.000493              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)              07__talking_against_wall       real        20                 0              20        0.000000       0.508412       0.000688              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)               07__talking_angry_couch       real        20                13               7        0.650000       0.506704       0.000835              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)              07__walk_down_hall_angry       real        20                 5              15        0.250000       0.508976       0.001997              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception) 07__walking_down_street_outside_angry       real        20                 6              14        0.300000       0.508267       0.001454              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)    07__walking_outside_cafe_disgusted       real        20                 6              14        0.300000       0.507523       0.000927              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                   08__exit_phone_room       real        20                15               5        0.750000       0.506828       0.000455              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)                       08__kitchen_pan       real        20                 8              12        0.400000       0.507137       0.000892              real                     1                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                     08__kitchen_still       real        20                11               9        0.550000       0.506946       0.000450              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)      08__outside_talking_pan_laughing       real        20                20               0        1.000000       0.506106       0.000362              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)    08__outside_talking_still_laughing       real        20                19               1        0.950000       0.506332       0.000471              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)               08__podium_speech_happy       real        20                10              10        0.500000       0.507057       0.000682              real                     1                   fake                          0\n","balanced_frames_FF++ FFD(Xception)              08__talking_against_wall       real        20                17               3        0.850000       0.506520       0.000669              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)              08__walk_down_hall_angry       real        20                 7              13        0.350000       0.507235       0.001004              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception) 08__walking_down_street_outside_angry       real        20                19               1        0.950000       0.506416       0.000457              real                     1                   real                          1\n","balanced_frames_FF++ FFD(Xception)    08__walking_outside_cafe_disgusted       real        20                 2              18        0.100000       0.508133       0.000754              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                   09__exit_phone_room       real        20                 4              16        0.200000       0.508186       0.000785              fake                     0                   fake                          0\n","balanced_frames_FF++ FFD(Xception)                       09__kitchen_pan       real        20                16               4        0.800000       0.506184       0.000771              real                     1                   real                          1\n"]}]},{"cell_type":"code","source":["# Save the large FFD table to Drive: /content/drive/*/FFD results FF++\n","import os\n","\n","# Use the DataFrame produced above\n","if 'table_ffd_ffpp' not in globals():\n","    raise SystemExit(\"No 'table_ffd_ffpp' found. Run the large-table cell first.\")\n","\n","# Resolve Drive root\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","# Make folder and save CSV\n","out_dir = os.path.join(DRIVE_ROOT, \"FFD results FF++\")\n","os.makedirs(out_dir, exist_ok=True)\n","csv_path = os.path.join(out_dir, \"ffd_large_table_ffpp.csv\")\n","\n","table_ffd_ffpp.to_csv(csv_path, index=False, float_format=\"%.6f\")\n","print(f\"Saved CSV to: {csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15ImT17ll0Sz","executionInfo":{"status":"ok","timestamp":1756752204193,"user_tz":-120,"elapsed":13,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"3db1f57f-8a5e-4dc8-fb40-1930dcd55bb9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved CSV to: /content/drive/My Drive/FFD results FF++/ffd_large_table_ffpp.csv\n"]}]},{"cell_type":"code","source":["# === FFD (Xception) — Small table (balanced_frames_FF++) ===\n","# Columns: dataset, detector, video_name, true_label, correctly_predicted (yes/no)\n","# Prints all rows without column breaks.\n","\n","import pandas as pd\n","\n","# Use the large table from the previous cell\n","if 'table_ffd_ffpp' not in globals():\n","    raise SystemExit(\"No 'table_ffd_ffpp' found. Run the large-table cell first.\")\n","\n","src = table_ffd_ffpp.copy()\n","\n","# Choose correctness source: prefer AVG rule, fallback to MAJORITY\n","corr_col = 'video_correct_by_avg' if 'video_correct_by_avg' in src.columns else 'video_correct_by_majority'\n","if corr_col not in src.columns:\n","    raise SystemExit(\"No correctness column found in the source table.\")\n","\n","# Ensure true_label is 'real'/'fake' strings\n","if pd.api.types.is_numeric_dtype(src['true_label']):\n","    src['true_label'] = src['true_label'].map({0:'real', 1:'fake'}).fillna(src['true_label'].astype(str))\n","\n","small_table_ffd = (\n","    src.assign(\n","        correctly_predicted=src[corr_col].astype(int).map({1:'yes', 0:'no'})\n","    )[[\n","        'dataset','detector','video_name','true_label','correctly_predicted'\n","    ]]\n","    .sort_values(['true_label','video_name'], kind='stable')\n","    .reset_index(drop=True)\n",")\n","\n","# Print all rows without column breaks\n","pd.set_option(\"display.max_rows\", 100000)\n","pd.set_option(\"display.max_columns\", 1000)\n","pd.set_option(\"display.width\", 10000)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","\n","print(small_table_ffd.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNT4PrwMmEcE","executionInfo":{"status":"ok","timestamp":1756752270508,"user_tz":-120,"elapsed":69,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"41da3a20-ae1d-44ed-e0f4-980eb07020a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["             dataset      detector                            video_name true_label correctly_predicted\n","balanced_frames_FF++ FFD(Xception)                               000_003       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               010_005       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               011_805       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               012_026       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               013_883       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               014_790       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               015_919       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               016_209       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               017_803       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               018_019       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               019_018       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               020_344       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               021_312       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               022_489       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               023_923       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               024_073       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               025_067       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               026_012       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               027_009       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               028_068       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               029_048       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               030_193       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               031_163       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               032_944       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               033_097       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               034_590       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               035_036       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               036_035       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               037_072       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               038_125       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               039_058       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               040_997       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               041_063       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               042_084       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               043_110       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               044_945       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               045_889       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               046_904       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               047_862       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               048_029       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               049_946       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               050_059       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               051_332       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               052_108       fake                  no\n","balanced_frames_FF++ FFD(Xception)                               053_095       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               054_071       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               055_147       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               056_996       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               057_070       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               058_039       fake                 yes\n","balanced_frames_FF++ FFD(Xception)                               059_050       fake                 yes\n","balanced_frames_FF++ FFD(Xception)    04__walking_outside_cafe_disgusted       real                 yes\n","balanced_frames_FF++ FFD(Xception)                   05__exit_phone_room       real                 yes\n","balanced_frames_FF++ FFD(Xception)                     05__hugging_happy       real                 yes\n","balanced_frames_FF++ FFD(Xception)                       05__kitchen_pan       real                 yes\n","balanced_frames_FF++ FFD(Xception)                     05__kitchen_still       real                 yes\n","balanced_frames_FF++ FFD(Xception)      05__outside_talking_pan_laughing       real                 yes\n","balanced_frames_FF++ FFD(Xception)    05__outside_talking_still_laughing       real                 yes\n","balanced_frames_FF++ FFD(Xception)               05__podium_speech_happy       real                 yes\n","balanced_frames_FF++ FFD(Xception)              05__talking_against_wall       real                 yes\n","balanced_frames_FF++ FFD(Xception)              05__walk_down_hall_angry       real                 yes\n","balanced_frames_FF++ FFD(Xception) 05__walking_down_street_outside_angry       real                 yes\n","balanced_frames_FF++ FFD(Xception)    05__walking_outside_cafe_disgusted       real                 yes\n","balanced_frames_FF++ FFD(Xception)                   06__exit_phone_room       real                 yes\n","balanced_frames_FF++ FFD(Xception)                     06__hugging_happy       real                  no\n","balanced_frames_FF++ FFD(Xception)                       06__kitchen_pan       real                 yes\n","balanced_frames_FF++ FFD(Xception)                     06__kitchen_still       real                 yes\n","balanced_frames_FF++ FFD(Xception)      06__outside_talking_pan_laughing       real                 yes\n","balanced_frames_FF++ FFD(Xception)    06__outside_talking_still_laughing       real                 yes\n","balanced_frames_FF++ FFD(Xception)               06__podium_speech_happy       real                  no\n","balanced_frames_FF++ FFD(Xception)              06__talking_against_wall       real                  no\n","balanced_frames_FF++ FFD(Xception)               06__talking_angry_couch       real                 yes\n","balanced_frames_FF++ FFD(Xception)              06__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ FFD(Xception)     06__walking_and_outside_surprised       real                 yes\n","balanced_frames_FF++ FFD(Xception)  06__walking_down_indoor_hall_disgust       real                  no\n","balanced_frames_FF++ FFD(Xception) 06__walking_down_street_outside_angry       real                  no\n","balanced_frames_FF++ FFD(Xception)    06__walking_outside_cafe_disgusted       real                 yes\n","balanced_frames_FF++ FFD(Xception)                   07__exit_phone_room       real                  no\n","balanced_frames_FF++ FFD(Xception)                     07__hugging_happy       real                  no\n","balanced_frames_FF++ FFD(Xception)                       07__kitchen_pan       real                  no\n","balanced_frames_FF++ FFD(Xception)                     07__kitchen_still       real                  no\n","balanced_frames_FF++ FFD(Xception)      07__outside_talking_pan_laughing       real                  no\n","balanced_frames_FF++ FFD(Xception)    07__outside_talking_still_laughing       real                  no\n","balanced_frames_FF++ FFD(Xception)               07__podium_speech_happy       real                  no\n","balanced_frames_FF++ FFD(Xception)               07__secret_conversation       real                 yes\n","balanced_frames_FF++ FFD(Xception)              07__talking_against_wall       real                  no\n","balanced_frames_FF++ FFD(Xception)               07__talking_angry_couch       real                 yes\n","balanced_frames_FF++ FFD(Xception)              07__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ FFD(Xception) 07__walking_down_street_outside_angry       real                  no\n","balanced_frames_FF++ FFD(Xception)    07__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ FFD(Xception)                   08__exit_phone_room       real                 yes\n","balanced_frames_FF++ FFD(Xception)                       08__kitchen_pan       real                 yes\n","balanced_frames_FF++ FFD(Xception)                     08__kitchen_still       real                 yes\n","balanced_frames_FF++ FFD(Xception)      08__outside_talking_pan_laughing       real                 yes\n","balanced_frames_FF++ FFD(Xception)    08__outside_talking_still_laughing       real                 yes\n","balanced_frames_FF++ FFD(Xception)               08__podium_speech_happy       real                 yes\n","balanced_frames_FF++ FFD(Xception)              08__talking_against_wall       real                 yes\n","balanced_frames_FF++ FFD(Xception)              08__walk_down_hall_angry       real                  no\n","balanced_frames_FF++ FFD(Xception) 08__walking_down_street_outside_angry       real                 yes\n","balanced_frames_FF++ FFD(Xception)    08__walking_outside_cafe_disgusted       real                  no\n","balanced_frames_FF++ FFD(Xception)                   09__exit_phone_room       real                  no\n","balanced_frames_FF++ FFD(Xception)                       09__kitchen_pan       real                 yes\n"]}]},{"cell_type":"code","source":["# Save the small FFD table to the same folder: /content/drive/*/FFD results FF++\n","import os\n","\n","if 'small_table_ffd' not in globals():\n","    raise SystemExit(\"No 'small_table_ffd' found. Run the small-table cell first.\")\n","\n","# Resolve Drive root\n","DRIVE_ROOT = \"/content/drive/My Drive\"\n","if not os.path.exists(DRIVE_ROOT):\n","    DRIVE_ROOT = \"/content/drive/MyDrive\"\n","\n","out_dir = os.path.join(DRIVE_ROOT, \"FFD results FF++\")\n","os.makedirs(out_dir, exist_ok=True)\n","\n","csv_path = os.path.join(out_dir, \"ffd_small_table_ffpp.csv\")\n","small_table_ffd.to_csv(csv_path, index=False)\n","print(f\"Saved CSV to: {csv_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IV301n67mL3I","executionInfo":{"status":"ok","timestamp":1756752300545,"user_tz":-120,"elapsed":38,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"6166005c-0f93-4c1b-fac2-227fed504f2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Saved CSV to: /content/drive/My Drive/FFD results FF++/ffd_small_table_ffpp.csv\n"]}]}]}