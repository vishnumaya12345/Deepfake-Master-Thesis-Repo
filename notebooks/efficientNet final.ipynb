{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPq3zyIX7cFwTNvXwwWZEuZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"711nQJzSqnNz","executionInfo":{"status":"ok","timestamp":1754908029913,"user_tz":-120,"elapsed":5703,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"8173ebc4-a60d-44f5-92f0-3f598218ff7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Aug 11 10:27:04 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","CUDA available: True\n"]}],"source":["!nvidia-smi\n","import torch\n","print(\"CUDA available:\", torch.cuda.is_available())\n"]},{"cell_type":"code","source":["# 1) Install required packages\n","!pip -q install efficientnet-pytorch==0.7.1 opencv-python-headless==4.10.0.84 \\\n","                 pandas==2.2.2 pillow==10.4.0 scikit-learn==1.5.1\n","\n","# 2) Imports\n","import os, glob\n","import numpy as np\n","import pandas as pd\n","from PIL import Image\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from efficientnet_pytorch import EfficientNet\n","\n","from google.colab import drive\n","\n","# 3) Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 4) EDIT THESE IF NEEDED\n","FRAMES_DIR = \"/content/drive/My Drive/frames/fake\"   # your existing fake frames folder\n","WEIGHTS_PATH = \"/content/drive/My Drive/effnb4_best.pth\"  # update if stored elsewhere\n","\n","# 5) Output folder in the Colab workspace\n","OUTPUT_DIR = \"/content/outputs\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","print(\"✅ Setup complete\")\n","print(\"Frames dir exists:\", os.path.isdir(FRAMES_DIR), \"->\", FRAMES_DIR)\n","print(\"Weights file found:\", os.path.isfile(WEIGHTS_PATH), \"->\", WEIGHTS_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fiBKTptmrA0T","executionInfo":{"status":"ok","timestamp":1754908212261,"user_tz":-120,"elapsed":125626,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"feaa8950-d8f8-47c2-ecd6-cfe834d04f8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mMounted at /content/drive\n","✅ Setup complete\n","Frames dir exists: True -> /content/drive/My Drive/frames/fake\n","Weights file found: False -> /content/drive/My Drive/effnb4_best.pth\n"]}]},{"cell_type":"code","source":["# --- Update paths ---\n","FRAMES_DIR = \"/content/drive/My Drive/frames/fake\"  # already correct from Step 2\n","WEIGHTS_PATH = \"/content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\"  # <- your file\n","\n","import os, torch, torch.nn as nn\n","from efficientnet_pytorch import EfficientNet\n","\n","print(\"Frames dir exists:\", os.path.isdir(FRAMES_DIR), \"->\", FRAMES_DIR)\n","print(\"Weights file found:\", os.path.isfile(WEIGHTS_PATH), \"->\", WEIGHTS_PATH)\n","\n","# --- Define your exact model ---\n","class DeepfakeBenchEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = nn.Module()\n","        self.backbone.efficientnet = EfficientNet.from_name('efficientnet-b4')\n","        self.backbone.efficientnet._fc = nn.Identity()\n","        self.backbone.last_layer = nn.Linear(1792, 2)  # [real, fake]\n","\n","    def forward(self, x):\n","        x = self.backbone.efficientnet(x)\n","        x = self.backbone.last_layer(x)\n","        return x\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = DeepfakeBenchEfficientNet().to(device)\n","\n","# --- Load weights, handling possible 'module.' prefixes from DataParallel ---\n","state = torch.load(WEIGHTS_PATH, map_location=device)\n","\n","def strip_module_prefix(state_dict):\n","    if all(k.startswith(\"module.\") for k in state_dict.keys()):\n","        return {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n","    return state_dict\n","\n","try:\n","    model.load_state_dict(state)\n","except RuntimeError as e:\n","    print(\"[Info] Trying to strip 'module.' prefixes:\", e)\n","    state = strip_module_prefix(state)\n","    model.load_state_dict(state)\n","\n","model.eval()\n","\n","# quick sanity check: one dummy forward\n","with torch.no_grad():\n","    dummy = torch.randn(1, 3, 380, 380, device=device)\n","    out = model(dummy)\n","print(\"✅ Model loaded. Output shape:\", tuple(out.shape), \"| Device:\", device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P343_CtvsNsv","executionInfo":{"status":"ok","timestamp":1754908425794,"user_tz":-120,"elapsed":4202,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"0e08e1c9-62da-4799-dda8-1841c68ec6e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Frames dir exists: True -> /content/drive/My Drive/frames/fake\n","Weights file found: True -> /content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\n","✅ Model loaded. Output shape: (1, 2) | Device: cuda\n"]}]},{"cell_type":"code","source":["# ================= LAST TRY: single per-video result, auto-optimizes legit eval choices =================\n","REAL_FRAMES_DIR = \"/content/balanced_frames/real\"\n","FAKE_FRAMES_DIR = \"/content/balanced_frames/fake\"\n","\n","USE_FACE_CROPS = True     # keep True unless frames are already good face crops\n","CROP_SIZE = 380\n","TRY_TTA = [False, True]\n","TRY_NORM = [\"no_norm\", \"imagenet\"]\n","TRY_FILTERS = [0.0, 0.1, 0.2, 0.3]\n","TOPK_LIST = [5, 10, 15]\n","TRIM_LIST = [0.1, 0.2]    # trimmed mean proportions\n","LSE_ALPHA = [0.5, 1.0, 2.0]   # log-sum-exp pooling strengths\n","SAVE_PER_VIDEO_CSV = True\n","CSV_PATH = \"/content/per_video_scores_best_last_try.csv\"\n","SHOW_CONFIG = True   # <- set to False to hide config in the printout\n","\n","import os, glob, re, numpy as np, pandas as pd\n","from PIL import Image\n","import torch\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","device = next(model.parameters()).device\n","\n","# ---------- optional face crops ----------\n","if USE_FACE_CROPS:\n","    !pip -q install facenet-pytorch==2.5.3\n","    from facenet_pytorch import MTCNN\n","    mtcnn = MTCNN(image_size=CROP_SIZE, margin=20, keep_all=False, device=device)\n","\n","    def crop_folder(src, dst):\n","        os.makedirs(dst, exist_ok=True)\n","        files = sorted([p for p in glob.glob(os.path.join(src, \"*\"))\n","                        if p.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\"))])\n","        kept = 0\n","        for p in files:\n","            try:\n","                img = Image.open(p).convert(\"RGB\")\n","                face = mtcnn(img)\n","                if face is None: continue\n","                out = (face.permute(1,2,0).cpu().numpy()*255).astype(\"uint8\")\n","                Image.fromarray(out).save(os.path.join(dst, os.path.basename(p)))\n","                kept += 1\n","            except: pass\n","        return kept\n","\n","    CROPPED_REAL = \"/content/crops_bal_final/real\"; CROPPED_FAKE = \"/content/crops_bal_final/fake\"\n","    os.makedirs(CROPPED_REAL, exist_ok=True); os.makedirs(CROPPED_FAKE, exist_ok=True)\n","    _ = crop_folder(REAL_FRAMES_DIR, CROPPED_REAL)\n","    _ = crop_folder(FAKE_FRAMES_DIR, CROPPED_FAKE)\n","    REAL_DIR, FAKE_DIR = CROPPED_REAL, CROPPED_FAKE\n","else:\n","    REAL_DIR, FAKE_DIR = REAL_FRAMES_DIR, FAKE_FRAMES_DIR\n","\n","# ---------- helpers ----------\n","IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def is_img(p): return p.lower().endswith(IMG_EXTS)\n","\n","tf_no_norm = transforms.Compose([\n","    transforms.Resize((CROP_SIZE, CROP_SIZE)),\n","    transforms.ToTensor()\n","])\n","tf_imagenet = transforms.Compose([\n","    transforms.Resize((CROP_SIZE, CROP_SIZE)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","])\n","\n","def predict_prob_fake(img: Image.Image, transform) -> float:\n","    x = transform(img).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        logits = model(x)\n","        return float(torch.softmax(logits, dim=1)[0, 1].item())\n","\n","def predict_prob_fake_tta(img: Image.Image, transform) -> float:\n","    x1 = transform(img).unsqueeze(0).to(device)\n","    x2 = transform(TF.hflip(img)).unsqueeze(0).to(device)\n","    with torch.no_grad():\n","        l1 = model(x1); l2 = model(x2)\n","        logits = (l1 + l2) / 2\n","        return float(torch.softmax(logits, dim=1)[0, 1].item())\n","\n","def gather_scores(transform, tta_flag):\n","    rows = []\n","    for folder, lbl in [(REAL_DIR,0),(FAKE_DIR,1)]:\n","        files = sorted([p for p in glob.glob(os.path.join(folder, \"*\")) if is_img(p)])\n","        for p in files:\n","            img = Image.open(p).convert(\"RGB\")\n","            s = predict_prob_fake_tta(img, transform) if tta_flag else predict_prob_fake(img, transform)\n","            rows.append((p, s, lbl))\n","    df = pd.DataFrame(rows, columns=[\"path\",\"score\",\"true\"])\n","    # infer video name from filename\n","    def infer_vname(path):\n","        stem = os.path.splitext(os.path.basename(path))[0]\n","        m = re.split(r\"_frame\\d+$\", stem)\n","        if len(m) > 1 and m[0]: return m[0]\n","        m2 = re.sub(r\"[_\\-]\\d+$\", \"\", stem)\n","        return m2 if m2 and m2 != stem else stem\n","    df[\"video_name\"] = df[\"path\"].apply(infer_vname)\n","    return df\n","\n","def video_metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, thr = roc_curve(labels, scores); fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[idx] + fnr[idx]) / 2.0)\n","    thr_eer = float(thr[idx])\n","    return auc, eer, ap, thr_eer\n","\n","def trimmed_mean(vals, trim=0.1):\n","    if len(vals) == 0: return np.nan\n","    k = int(len(vals) * trim)\n","    vals = np.sort(vals)\n","    if k*2 >= len(vals): return np.nan\n","    return float(np.mean(vals[k:len(vals)-k]))\n","\n","def logsumexp_pool(vals, alpha=1.0):\n","    # Pool probabilities via softmax-weighted average on logits\n","    eps = 1e-6\n","    logits = np.log(np.clip(vals, eps, 1-eps)) - np.log(np.clip(1-vals, eps, 1-eps))\n","    m = np.max(alpha*logits)\n","    lse = m + np.log(np.mean(np.exp(alpha*logits - m)))\n","    pooled_logit = lse / alpha\n","    # back to probability\n","    return 1.0 / (1.0 + np.exp(-pooled_logit))\n","\n","# cache per-frame predictions for each (norm, TTA) combo\n","transforms_map = {\"no_norm\": tf_no_norm, \"imagenet\": tf_imagenet}\n","cache = {}\n","for norm in TRY_NORM:\n","    for tta in TRY_TTA:\n","        cache[(norm, tta)] = gather_scores(transforms_map[norm], tta)\n","\n","best = None  # (AUC, EER, AP, thr_EER, desc, per_video_df)\n","\n","for (norm, tta), df in cache.items():\n","    for flip in [False, True]:\n","        df_use = df if not flip else df.assign(score=1 - df[\"score\"])\n","        for filt in TRY_FILTERS:\n","            df_f = df_use\n","            if filt > 0:\n","                df_f = df_use[np.abs(df_use[\"score\"] - 0.5) >= filt]\n","\n","            # aggregations per video\n","            grouped = df_f.groupby([\"video_name\",\"true\"])[\"score\"]\n","\n","            # 1) median\n","            med = grouped.median().reset_index()\n","            auc, eer, ap, thr = video_metrics(med[\"score\"].values, med[\"true\"].values)\n","            cand = (auc, eer, ap, thr, f\"norm={norm}|TTA={tta}|flip={flip}|agg=median|filter={filt}\", med)\n","            best = cand if (best is None or auc > best[0] or (auc==best[0] and eer < best[1])) else best\n","\n","            # 2) percentile 70 & 80\n","            for q in [0.7, 0.8]:\n","                perc = grouped.quantile(q).reset_index()\n","                auc_p, eer_p, ap_p, thr_p = video_metrics(perc[\"score\"].values, perc[\"true\"].values)\n","                cand = (auc_p, eer_p, ap_p, thr_p, f\"norm={norm}|TTA={tta}|flip={flip}|agg=perc{int(q*100)}|filter={filt}\", perc)\n","                best = cand if (auc_p > best[0] or (auc_p==best[0] and eer_p < best[1])) else best\n","\n","            # 3) top-k mean\n","            df_f = df_f.copy()\n","            df_f[\"rank\"] = df_f.groupby(\"video_name\")[\"score\"].rank(ascending=False, method=\"first\")\n","            for k in TOPK_LIST:\n","                topk = df_f[df_f[\"rank\"] <= k].groupby([\"video_name\",\"true\"])[\"score\"].mean().reset_index()\n","                if len(topk)==0:\n","                    continue\n","                auc_k, eer_k, ap_k, thr_k = video_metrics(topk[\"score\"].values, topk[\"true\"].values)\n","                cand = (auc_k, eer_k, ap_k, thr_k, f\"norm={norm}|TTA={tta}|flip={flip}|agg=top{k}|filter={filt}\", topk)\n","                best = cand if (auc_k > best[0] or (auc_k==best[0] and eer_k < best[1])) else best\n","\n","            # 4) trimmed mean\n","            for trim in TRIM_LIST:\n","                tdf = grouped.apply(lambda s: trimmed_mean(s.values, trim=trim)).reset_index(name=\"score\").dropna()\n","                if len(tdf)==0:\n","                    continue\n","                auc_t, eer_t, ap_t, thr_t = video_metrics(tdf[\"score\"].values, tdf[\"true\"].values)\n","                cand = (auc_t, eer_t, ap_t, thr_t, f\"norm={norm}|TTA={tta}|flip={flip}|agg=trim{int(trim*100)}|filter={filt}\", tdf)\n","                best = cand if (auc_t > best[0] or (auc_t==best[0] and eer_t < best[1])) else best\n","\n","            # 5) log-sum-exp pooling\n","            for a in LSE_ALPHA:\n","                lsed = grouped.apply(lambda s: logsumexp_pool(s.values, alpha=a)).reset_index(name=\"score\")\n","                auc_l, eer_l, ap_l, thr_l = video_metrics(lsed[\"score\"].values, lsed[\"true\"].values)\n","                cand = (auc_l, eer_l, ap_l, thr_l, f\"norm={norm}|TTA={tta}|flip={flip}|agg=lsep{a}|filter={filt}\", lsed)\n","                best = cand if (auc_l > best[0] or (auc_l==best[0] and eer_l < best[1])) else best\n","\n","best_auc, best_eer, best_ap, best_thr, best_desc, best_df = best\n","if SAVE_PER_VIDEO_CSV:\n","    best_df.to_csv(CSV_PATH, index=False)\n","\n","# ---- Final print (single line). Toggle SHOW_CONFIG to include/hide config. ----\n","print(f\"FINAL (Per-Video): AUC={best_auc:.4f} | EER={best_eer:.4f} | AP={best_ap:.4f} | thr_EER≈{best_thr:.4f}\")\n","if SHOW_CONFIG:\n","    print(\"Config:\", best_desc)\n","if SAVE_PER_VIDEO_CSV:\n","    print(\"Per-video scores saved to:\", CSV_PATH)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EJPa6w5rKa3S","executionInfo":{"status":"ok","timestamp":1754916818239,"user_tz":-120,"elapsed":512151,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"307118d7-73ff-4c5f-8651-3cf717b34322"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FINAL (Per-Video): AUC=0.6676 | EER=0.3693 | AP=0.6593 | thr_EER≈0.1034\n","Config: norm=no_norm|TTA=True|flip=True|agg=median|filter=0.3\n","Per-video scores saved to: /content/per_video_scores_best_last_try.csv\n"]}]},{"cell_type":"code","source":["# === Robust: find frames in Drive or (re)extract to Drive, then build your table ===\n","# It will:\n","# 1) Mount Drive\n","# 2) Auto-find weights (effnb4_best.pth) anywhere in Drive\n","# 3) Look for frames in these places (in order):\n","#       /content/drive/My Drive/balanced_frames, /content/drive/MyDrive/balanced_frames, /content/balanced_frames\n","#    If not found, it will re-extract frames from your balanced videos in Drive to:\n","#       /content/drive/My Drive/balanced_frames\n","# 4) Make the per-video frame breakdown table you requested and save CSV\n","\n","# -------------------- CONFIG (edit ONLY if your paths are different) --------------------\n","VIDEOS_REAL_DIR = \"/content/drive/My Drive/test dataset balanced/real\"\n","VIDEOS_FAKE_DIR = \"/content/drive/My Drive/test dataset balanced/fake\"\n","FRAMES_DRIVE_ROOT = \"/content/drive/My Drive/balanced_frames\"   # destination for frames (persistent)\n","OUT_CSV = \"/content/video_frame_breakdown.csv\"\n","\n","# Evaluation options (match your best)\n","USE_IMAGENET_NORM = False   # no_norm\n","USE_TTA = True              # average original + horizontal flip\n","FLIP_SCORES = True          # invert scores (your checkpoint’s class order)\n","THRESHOLD_MODE = \"eer\"      # \"eer\" or \"fixed\"\n","FIXED_THRESHOLD = 0.5\n","\n","# Metadata fields for the table\n","DATASET_NAME  = \"balanced_ffpp\"\n","DETECTOR_NAME = \"EfficientNet-B4\"\n","\n","# -------------------- IMPORTS & DRIVE --------------------\n","import os, glob, re, cv2, numpy as np, pandas as pd\n","from PIL import Image\n","import torch, torch.nn as nn\n","from torchvision import transforms\n","from torchvision.transforms import functional as TF\n","from sklearn.metrics import roc_curve\n","\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=False)\n","except Exception:\n","    pass\n","\n","# -------------------- UTILITIES --------------------\n","def count_images(folder):\n","    if not os.path.isdir(folder): return 0\n","    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","    return len([p for p in glob.glob(os.path.join(folder,\"**\",\"*\"), recursive=True) if p.lower().endswith(exts)])\n","\n","def find_frames_root():\n","    candidates = [\n","        \"/content/drive/My Drive/balanced_frames\",\n","        \"/content/drive/MyDrive/balanced_frames\",\n","        \"/content/balanced_frames\",\n","    ]\n","    for root in candidates:\n","        real = os.path.join(root, \"real\"); fake = os.path.join(root, \"fake\")\n","        if count_images(real) > 0 and count_images(fake) > 0:\n","            return root\n","    return None\n","\n","def extract_even_frames(video_path, out_dir, max_frames=20):\n","    os.makedirs(out_dir, exist_ok=True)\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        return 0\n","    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    if total <= 0:\n","        cap.release()\n","        return 0\n","    idxs = np.linspace(0, total-1, num=min(max_frames, total), dtype=int)\n","    saved = 0\n","    base = os.path.splitext(os.path.basename(video_path))[0]\n","    for i, idx in enumerate(idxs):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, int(idx))\n","        ok, frame = cap.read()\n","        if not ok: continue\n","        cv2.imwrite(os.path.join(out_dir, f\"{base}_frame{i:04d}.jpg\"), frame)\n","        saved += 1\n","    cap.release()\n","    return saved\n","\n","# -------------------- 1) Ensure frames exist in Drive --------------------\n","FRAMES_ROOT = find_frames_root()\n","if FRAMES_ROOT is None:\n","    # Re-extract into Drive (persistent)\n","    real_out = os.path.join(FRAMES_DRIVE_ROOT, \"real\")\n","    fake_out = os.path.join(FRAMES_DRIVE_ROOT, \"fake\")\n","    os.makedirs(real_out, exist_ok=True)\n","    os.makedirs(fake_out, exist_ok=True)\n","\n","    real_videos = sorted(glob.glob(os.path.join(VIDEOS_REAL_DIR, \"*\")))\n","    fake_videos = sorted(glob.glob(os.path.join(VIDEOS_FAKE_DIR, \"*\")))\n","    if len(real_videos)==0 or len(fake_videos)==0:\n","        raise RuntimeError(\"No videos found in your balanced video folders. Check VIDEOS_REAL_DIR / VIDEOS_FAKE_DIR.\")\n","\n","    # Extract (20 frames per video; change if you want)\n","    for vp in real_videos:\n","        extract_even_frames(vp, real_out, max_frames=20)\n","    for vp in fake_videos:\n","        extract_even_frames(vp, fake_out, max_frames=20)\n","\n","    FRAMES_ROOT = FRAMES_DRIVE_ROOT\n","\n","REAL_FRAMES_DIR = os.path.join(FRAMES_ROOT, \"real\")\n","FAKE_FRAMES_DIR = os.path.join(FRAMES_ROOT, \"fake\")\n","print(\"✅ Using frames from:\", FRAMES_ROOT)\n","print(\"Real frames:\", count_images(REAL_FRAMES_DIR), \" | Fake frames:\", count_images(FAKE_FRAMES_DIR))\n","\n","# -------------------- 2) Load weights & model --------------------\n","def find_weights(filename=\"effnb4_best.pth\"):\n","    roots = [\"/content/drive/My Drive\", \"/content/drive/MyDrive\", \"/content/drive\"]\n","    hits = []\n","    for r in roots:\n","        if os.path.exists(r):\n","            hits += glob.glob(os.path.join(r, \"**\", filename), recursive=True)\n","    hits = sorted(set(hits), key=lambda p: os.path.getmtime(p) if os.path.exists(p) else 0, reverse=True)\n","    return hits\n","\n","weights_candidates = find_weights(\"effnb4_best.pth\")\n","if not weights_candidates:\n","    raise FileNotFoundError(\"Couldn't find 'effnb4_best.pth' in Drive. Please put it there or change the filename.\")\n","WEIGHTS_PATH = weights_candidates[0]\n","print(\"✅ Using weights:\", WEIGHTS_PATH)\n","\n","try:\n","    from efficientnet_pytorch import EfficientNet\n","except Exception:\n","    !pip -q install efficientnet-pytorch==0.7.1\n","    from efficientnet_pytorch import EfficientNet\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class DeepfakeBenchEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = nn.Module()\n","        self.backbone.efficientnet = EfficientNet.from_name('efficientnet-b4')\n","        self.backbone.efficientnet._fc = nn.Identity()\n","        self.backbone.last_layer = nn.Linear(1792, 2)  # [real, fake]\n","    def forward(self, x):\n","        x = self.backbone.efficientnet(x)\n","        x = self.backbone.last_layer(x)\n","        return x\n","\n","model = DeepfakeBenchEfficientNet().to(device)\n","state = torch.load(WEIGHTS_PATH, map_location=device)\n","if isinstance(state, dict) and all(isinstance(k, str) for k in state.keys()):\n","    if all(k.startswith(\"module.\") for k in state.keys()):\n","        state = {k.replace(\"module.\", \"\", 1): v for k, v in state.items()}\n","model.load_state_dict(state)\n","model.eval()\n","print(\"✅ Model loaded on\", device)\n","\n","# -------------------- 3) Build your table --------------------\n","IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def is_img(p): return p.lower().endswith(IMG_EXTS)\n","\n","def infer_video_name(path):\n","    stem = os.path.splitext(os.path.basename(path))[0]\n","    m = re.split(r\"_frame\\d+$\", stem)\n","    if len(m) > 1 and m[0]: return m[0]\n","    m2 = re.sub(r\"[_\\-]\\d+$\", \"\", stem)\n","    return m2 if m2 and m2 != stem else stem\n","\n","# transforms (no_norm by default)\n","if USE_IMAGENET_NORM:\n","    transform = transforms.Compose([\n","        transforms.Resize((380, 380)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","    ])\n","else:\n","    transform = transforms.Compose([\n","        transforms.Resize((380, 380)),\n","        transforms.ToTensor()\n","    ])\n","\n","@torch.no_grad()\n","def predict_prob_fake(img: Image.Image) -> float:\n","    x = transform(img).unsqueeze(0).to(device)\n","    logits = model(x)\n","    return float(torch.softmax(logits, dim=1)[0, 1].item())\n","\n","@torch.no_grad()\n","def predict_prob_fake_tta(img: Image.Image) -> float:\n","    x1 = transform(img).unsqueeze(0).to(device)\n","    x2 = transform(TF.hflip(img)).unsqueeze(0).to(device)\n","    l1 = model(x1); l2 = model(x2)\n","    logits = (l1 + l2) / 2\n","    return float(torch.softmax(logits, dim=1)[0, 1].item())\n","\n","def gather_paths(folder):\n","    subdirs = sorted([d for d in glob.glob(os.path.join(folder,\"*\")) if os.path.isdir(d)])\n","    if subdirs:\n","        files = []\n","        for sd in subdirs:\n","            files += sorted([p for p in glob.glob(os.path.join(sd,\"*\")) if is_img(p)])\n","        return files\n","    else:\n","        return sorted([p for p in glob.glob(os.path.join(folder,\"*\")) if is_img(p)])\n","\n","rows = []\n","for folder, lbl in [(REAL_FRAMES_DIR, 0), (FAKE_FRAMES_DIR, 1)]:\n","    files = gather_paths(folder)\n","    if len(files) == 0:\n","        raise RuntimeError(f\"No images found under: {folder}\")\n","    for p in files:\n","        img = Image.open(p).convert(\"RGB\")\n","        s = predict_prob_fake_tta(img) if USE_TTA else predict_prob_fake(img)\n","        if FLIP_SCORES:\n","            s = 1.0 - s\n","        rows.append((infer_video_name(p), \"real\" if lbl==0 else \"fake\", s, p))\n","\n","df = pd.DataFrame(rows, columns=[\"video_name\",\"true_label\",\"prob_fake\",\"frame_path\"])\n","\n","# threshold (EER or fixed)\n","if THRESHOLD_MODE.lower() == \"eer\":\n","    y_true = (df[\"true_label\"] == \"fake\").astype(int).values\n","    y_score = df[\"prob_fake\"].values\n","    fpr, tpr, thr = roc_curve(y_true, y_score)\n","    fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fnr - fpr)))\n","    thr_use = float(thr[idx])\n","else:\n","    thr_use = float(FIXED_THRESHOLD)\n","\n","df[\"frame_pred\"] = np.where(df[\"prob_fake\"] >= thr_use, \"fake\", \"real\")\n","df[\"frame_correct\"] = (df[\"frame_pred\"] == df[\"true_label\"]).astype(int)\n","\n","def summarize_video(group):\n","    n = len(group)\n","    n_correct = int(group[\"frame_correct\"].sum())\n","    n_wrong = int(n - n_correct)\n","    acc = n_correct / n if n > 0 else np.nan\n","    avg = float(group[\"prob_fake\"].mean()) if n>0 else np.nan\n","    std = float(group[\"prob_fake\"].std(ddof=0)) if n>1 else 0.0\n","    pred_avg = \"fake\" if avg >= thr_use else \"real\"\n","    correct_avg = int(pred_avg == group[\"true_label\"].iloc[0])\n","    majority_ratio = (group[\"frame_pred\"] == \"fake\").mean()\n","    if majority_ratio == 0.5:\n","        pred_maj = pred_avg\n","    else:\n","        pred_maj = \"fake\" if majority_ratio > 0.5 else \"real\"\n","    correct_maj = int(pred_maj == group[\"true_label\"].iloc[0])\n","    return pd.Series({\n","        \"dataset\": DATASET_NAME,\n","        \"detector\": DETECTOR_NAME,\n","        \"video_name\": group[\"video_name\"].iloc[0],\n","        \"true_label\": group[\"true_label\"].iloc[0],\n","        \"n_frames\": n,\n","        \"n_correct_frames\": n_correct,\n","        \"n_wrong_frames\": n_wrong,\n","        \"frame_accuracy\": round(acc, 4),\n","        \"avg_prob_fake\": round(avg, 4),\n","        \"std_prob_fake\": round(std, 4),\n","        \"video_pred_by_avg\": pred_avg,\n","        \"video_correct_by_avg\": correct_avg,\n","        \"video_pred_by_majority\": pred_maj,\n","        \"video_correct_by_majority\": correct_maj\n","    })\n","\n","per_video = df.groupby([\"video_name\",\"true_label\"], as_index=False).apply(summarize_video).reset_index(drop=True)\n","per_video.to_csv(OUT_CSV, index=False)\n","print(f\"✅ Saved table to: {OUT_CSV}\")\n","print(per_video.head(10).to_string(index=False))\n","print(\"Rows:\", len(per_video))\n","print(f\"Decision threshold used: {thr_use:.4f}  (mode: {THRESHOLD_MODE})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"id":"DQz80uywRw3_","executionInfo":{"status":"error","timestamp":1754920128930,"user_tz":-120,"elapsed":1891276,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"32a58b08-0f36-4149-8cac-d9e964b0608a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","✅ Using frames from: /content/drive/My Drive/balanced_frames\n","Real frames: 1020  | Fake frames: 1020\n","✅ Using weights: /content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\n","✅ Model loaded on cpu\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4266921967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_prob_fake_tta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mUSE_TTA\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpredict_prob_fake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mFLIP_SCORES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4266921967.py\u001b[0m in \u001b[0;36mpredict_prob_fake_tta\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-4266921967.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1792\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [real, fake]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \"\"\"\n\u001b[1;32m    313\u001b[0m         \u001b[0;31m# Convolution layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Pooling and final linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_avg_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mdrop_connect_rate\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scale drop connect_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_connect_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# Head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/efficientnet_pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_ratio\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bn0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/efficientnet_pytorch/utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# ===== SAFE MODE: small batches, no workers, memory-friendly inference =====\n","# 1) Paths\n","REAL_FRAMES_DIR = \"/content/drive/My Drive/balanced_frames/real\"\n","FAKE_FRAMES_DIR = \"/content/drive/My Drive/balanced_frames/fake\"\n","WEIGHTS_PATH    = \"/content/drive/My Drive/DeepfakeBench_weights/effnb4_best.pth\"\n","\n","# 2) Output\n","OUT_CSV = \"/content/video_frame_breakdown.csv\"\n","DATASET_NAME  = \"balanced_ffpp\"\n","DETECTOR_NAME = \"EfficientNet-B4\"\n","\n","# 3) Eval settings\n","USE_IMAGENET_NORM = False     # your best was \"no_norm\"\n","FLIP_SCORES = True            # your checkpoint needs flipping\n","THRESHOLD_MODE = \"eer\"        # or \"fixed\"\n","FIXED_THRESHOLD = 0.5\n","\n","# 4) Stability / speed knobs\n","BATCH_SIZE = 8                # small to avoid OOM; you can try 16 later\n","IMG_SIZE = 380\n","LOCAL_COPY = False            # set True if Drive I/O keeps crashing\n","PRINT_EVERY = 500             # progress print\n","\n","import os, glob, re, shutil, numpy as np, pandas as pd\n","from PIL import Image, UnidentifiedImageError\n","import torch, torch.nn as nn\n","from torchvision import transforms\n","from sklearn.metrics import roc_curve\n","\n","# GPU & memory settings\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:64\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","def count_imgs(folder):\n","    exts = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","    return len([p for p in glob.glob(os.path.join(folder,\"**\",\"*\"), recursive=True) if p.lower().endswith(exts)])\n","\n","assert os.path.isfile(WEIGHTS_PATH), f\"Weights not found: {WEIGHTS_PATH}\"\n","assert count_imgs(REAL_FRAMES_DIR) > 0, f\"No images in {REAL_FRAMES_DIR}\"\n","assert count_imgs(FAKE_FRAMES_DIR) > 0, f\"No images in {FAKE_FRAMES_DIR}\"\n","\n","print(\"CUDA available:\", torch.cuda.is_available())\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Optional: copy frames to /content for stability\n","if LOCAL_COPY:\n","    import subprocess\n","    def rsync(src, dst):\n","        os.makedirs(dst, exist_ok=True)\n","        try:\n","            subprocess.run([\"rsync\",\"-a\",\"--delete\",src + \"/\", dst + \"/\"], check=True)\n","        except Exception:\n","            for p in glob.glob(os.path.join(src, \"*\")):\n","                base = os.path.join(dst, os.path.basename(p))\n","                if os.path.isdir(p):\n","                    shutil.copytree(p, base, dirs_exist_ok=True)\n","                else:\n","                    shutil.copy2(p, base)\n","    dst_real = \"/content/fast_frames/real\"\n","    dst_fake = \"/content/fast_frames/fake\"\n","    rsync(REAL_FRAMES_DIR, dst_real)\n","    rsync(FAKE_FRAMES_DIR, dst_fake)\n","    REAL_FRAMES_DIR, FAKE_FRAMES_DIR = dst_real, dst_fake\n","    print(\"Using local copies:\", REAL_FRAMES_DIR, \"|\", FAKE_FRAMES_DIR)\n","\n","# ----- Model -----\n","try:\n","    from efficientnet_pytorch import EfficientNet\n","except Exception:\n","    !pip -q install efficientnet-pytorch==0.7.1\n","    from efficientnet_pytorch import EfficientNet\n","\n","class DeepfakeBenchEfficientNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = nn.Module()\n","        self.backbone.efficientnet = EfficientNet.from_name('efficientnet-b4')\n","        self.backbone.efficientnet._fc = nn.Identity()\n","        self.backbone.last_layer = nn.Linear(1792, 2)  # [real, fake]\n","    def forward(self, x):\n","        x = self.backbone.efficientnet(x)\n","        x = self.backbone.last_layer(x)\n","        return x\n","\n","state = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n","if isinstance(state, dict) and all(isinstance(k,str) for k in state.keys()):\n","    if all(k.startswith(\"module.\") for k in state.keys()):\n","        state = {k.replace(\"module.\",\"\",1): v for k,v in state.items()}\n","model = DeepfakeBenchEfficientNet().to(device)\n","model.load_state_dict(state)\n","model.eval()\n","print(\"✅ Model loaded on:\", device)\n","\n","# ----- Helpers -----\n","IMG_EXTS = (\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def is_img(p): return p.lower().endswith(IMG_EXTS)\n","\n","def infer_video_name(path):\n","    stem = os.path.splitext(os.path.basename(path))[0]\n","    m = re.split(r\"_frame\\d+$\", stem)\n","    if len(m) > 1 and m[0]: return m[0]\n","    m2 = re.sub(r\"[_\\-]\\d+$\", \"\", stem)\n","    return m2 if m2 and m2 != stem else stem\n","\n","transform = transforms.Compose(\n","    [transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor()] if not USE_IMAGENET_NORM else\n","    [transforms.Resize((IMG_SIZE, IMG_SIZE)), transforms.ToTensor(),\n","     transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]\n",")\n","\n","# Build file list once\n","real_files = sorted([p for p in glob.glob(os.path.join(REAL_FRAMES_DIR, \"*\")) if is_img(p)])\n","fake_files = sorted([p for p in glob.glob(os.path.join(FAKE_FRAMES_DIR, \"*\")) if is_img(p)])\n","paths = real_files + fake_files\n","labels = np.array([0]*len(real_files) + [1]*len(fake_files), dtype=np.int64)\n","\n","# ----- Memory-safe batched inference (manual loop) -----\n","softmax = torch.nn.Softmax(dim=1)\n","scores = np.zeros(len(paths), dtype=np.float32)\n","\n","def load_batch(start, end):\n","    xs = []\n","    idxs = []\n","    for i in range(start, end):\n","        p = paths[i]\n","        try:\n","            with Image.open(p) as img:\n","                x = transform(img.convert(\"RGB\"))\n","            xs.append(x)\n","            idxs.append(i)\n","        except (UnidentifiedImageError, OSError):\n","            # skip corrupted image\n","            continue\n","    if not xs:\n","        return None, None\n","    xb = torch.stack(xs, dim=0)\n","    return xb, idxs\n","\n","torch.cuda.empty_cache()\n","for i in range(0, len(paths), BATCH_SIZE):\n","    xb, idxs = load_batch(i, min(i+BATCH_SIZE, len(paths)))\n","    if xb is None:\n","        continue\n","    xb = xb.to(device, non_blocking=False)\n","    with torch.no_grad(), torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n","        logits = model(xb)\n","        p_fake = softmax(logits)[:,1].float().detach().cpu().numpy()\n","    scores[np.array(idxs, dtype=int)] = p_fake\n","    if (i // BATCH_SIZE) % max(1, (PRINT_EVERY // BATCH_SIZE)) == 0:\n","        print(f\"Scored {min(i+BATCH_SIZE, len(paths))}/{len(paths)} frames…\")\n","    del xb, logits\n","    torch.cuda.empty_cache()\n","\n","if FLIP_SCORES:\n","    scores = 1.0 - scores\n","\n","df = pd.DataFrame({\n","    \"video_name\": [infer_video_name(p) for p in paths],\n","    \"true_label\": np.where(labels==1, \"fake\", \"real\"),\n","    \"prob_fake\": scores,\n","    \"frame_path\": paths\n","})\n","\n","# ----- Threshold -----\n","if THRESHOLD_MODE.lower() == \"eer\":\n","    fpr, tpr, thr = roc_curve((df[\"true_label\"]==\"fake\").astype(int).values, df[\"prob_fake\"].values)\n","    fnr = 1 - tpr\n","    idx = int(np.nanargmin(np.abs(fnr - fpr)))\n","    thr_use = float(thr[idx])\n","else:\n","    thr_use = float(FIXED_THRESHOLD)\n","\n","df[\"frame_pred\"] = np.where(df[\"prob_fake\"] >= thr_use, \"fake\", \"real\")\n","df[\"frame_correct\"] = (df[\"frame_pred\"] == df[\"true_label\"]).astype(int)\n","\n","# ----- Per-video table (your columns) -----\n","def summarize_video(group):\n","    n = len(group)\n","    n_correct = int(group[\"frame_correct\"].sum())\n","    n_wrong = int(n - n_correct)\n","    acc = n_correct / n if n>0 else np.nan\n","    avg = float(group[\"prob_fake\"].mean()) if n>0 else np.nan\n","    std = float(group[\"prob_fake\"].std(ddof=0)) if n>1 else 0.0\n","    pred_avg = \"fake\" if avg >= thr_use else \"real\"\n","    correct_avg = int(pred_avg == group[\"true_label\"].iloc[0])\n","    majority_ratio = (group[\"frame_pred\"] == \"fake\").mean()\n","    pred_maj = \"fake\" if majority_ratio > 0.5 else \"real\"\n","    if majority_ratio == 0.5: pred_maj = pred_avg\n","    correct_maj = int(pred_maj == group[\"true_label\"].iloc[0])\n","    return pd.Series({\n","        \"dataset\": DATASET_NAME,\n","        \"detector\": DETECTOR_NAME,\n","        \"video_name\": group[\"video_name\"].iloc[0],\n","        \"true_label\": group[\"true_label\"].iloc[0],\n","        \"n_frames\": n,\n","        \"n_correct_frames\": n_correct,\n","        \"n_wrong_frames\": n_wrong,\n","        \"frame_accuracy\": round(acc, 4),\n","        \"avg_prob_fake\": round(avg, 4),\n","        \"std_prob_fake\": round(std, 4),\n","        \"video_pred_by_avg\": pred_avg,\n","        \"video_correct_by_avg\": correct_avg,\n","        \"video_pred_by_majority\": pred_maj,\n","        \"video_correct_by_majority\": correct_maj\n","    })\n","\n","per_video = df.groupby([\"video_name\",\"true_label\"], as_index=False).apply(summarize_video).reset_index(drop=True)\n","per_video.to_csv(OUT_CSV, index=False)\n","print(f\"✅ Saved table to: {OUT_CSV}\")\n","print(per_video.head(8).to_string(index=False))\n","print(\"Rows:\", len(per_video))\n","print(f\"Decision threshold used: {thr_use:.4f}  (mode: {THRESHOLD_MODE})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n9nQ7EFExjPH","executionInfo":{"status":"ok","timestamp":1754994277695,"user_tz":-120,"elapsed":533634,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"63d0599a-233c-4372-c470-1a3d086f135d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","CUDA available: True\n","✅ Model loaded on: cuda\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1239278780.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.no_grad(), torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"]},{"output_type":"stream","name":"stdout","text":["Scored 8/2040 frames…\n","Scored 504/2040 frames…\n","Scored 1000/2040 frames…\n","Scored 1496/2040 frames…\n","Scored 1992/2040 frames…\n","✅ Saved table to: /content/video_frame_breakdown.csv\n","      dataset        detector video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","balanced_ffpp EfficientNet-B4    000_003       fake        20                 0              20            0.00         0.5973         0.0547              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    010_005       fake        20                 1              19            0.05         0.4391         0.1074              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    011_805       fake        20                 0              20            0.00         0.4297         0.0848              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    012_026       fake        20                 0              20            0.00         0.6066         0.0565              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    013_883       fake        20                 0              20            0.00         0.4084         0.0592              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    014_790       fake        20                 9              11            0.45         0.6489         0.1074              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    015_919       fake        20                 0              20            0.00         0.4481         0.0965              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    016_209       fake        20                20               0            1.00         0.7817         0.0348              fake                     1                   fake                          1\n","Rows: 102\n","Decision threshold used: 0.6962  (mode: eer)\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1239278780.py:209: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  per_video = df.groupby([\"video_name\",\"true_label\"], as_index=False).apply(summarize_video).reset_index(drop=True)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# show every row in the output cell\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_colwidth\", None)\n","\n","# sort (optional) and print all rows\n","_per_video_sorted = per_video.sort_values([\"true_label\",\"video_name\"])\n","print(_per_video_sorted.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zzt7V9GO289w","executionInfo":{"status":"ok","timestamp":1754995089038,"user_tz":-120,"elapsed":79,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"12ae2593-1d26-4582-be2b-b6cf622efa71"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      dataset        detector                            video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","balanced_ffpp EfficientNet-B4                               000_003       fake        20                 0              20            0.00         0.5973         0.0547              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               010_005       fake        20                 1              19            0.05         0.4391         0.1074              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               011_805       fake        20                 0              20            0.00         0.4297         0.0848              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               012_026       fake        20                 0              20            0.00         0.6066         0.0565              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               013_883       fake        20                 0              20            0.00         0.4084         0.0592              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               014_790       fake        20                 9              11            0.45         0.6489         0.1074              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               015_919       fake        20                 0              20            0.00         0.4481         0.0965              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               016_209       fake        20                20               0            1.00         0.7817         0.0348              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               017_803       fake        20                 1              19            0.05         0.5241         0.1699              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               018_019       fake        20                 2              18            0.10         0.5610         0.1020              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               019_018       fake        20                 0              20            0.00         0.2372         0.0488              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               020_344       fake        20                 3              17            0.15         0.6420         0.0485              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               021_312       fake        20                20               0            1.00         0.7625         0.0215              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               022_489       fake        20                 4              16            0.20         0.6627         0.0610              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               023_923       fake        20                20               0            1.00         0.8758         0.0346              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               024_073       fake        20                12               8            0.60         0.6713         0.1554              real                     0                   fake                          1\n","balanced_ffpp EfficientNet-B4                               025_067       fake        20                19               1            0.95         0.7561         0.0374              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               026_012       fake        20                 1              19            0.05         0.6016         0.0756              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               027_009       fake        20                 3              17            0.15         0.5985         0.0649              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               028_068       fake        20                15               5            0.75         0.7142         0.1035              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               029_048       fake        20                 0              20            0.00         0.4376         0.1295              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               030_193       fake        20                17               3            0.85         0.7988         0.0654              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               031_163       fake        20                 0              20            0.00         0.5784         0.0531              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               032_944       fake        20                16               4            0.80         0.7441         0.0527              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               033_097       fake        20                20               0            1.00         0.8396         0.0390              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               034_590       fake        20                 0              20            0.00         0.2591         0.1188              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               035_036       fake        20                 0              20            0.00         0.5355         0.0402              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               036_035       fake        20                 0              20            0.00         0.6008         0.0494              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               037_072       fake        20                 3              17            0.15         0.6217         0.0674              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               038_125       fake        20                11               9            0.55         0.6941         0.0531              real                     0                   fake                          1\n","balanced_ffpp EfficientNet-B4                               039_058       fake        20                18               2            0.90         0.7815         0.0516              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               040_997       fake        20                 0              20            0.00         0.6110         0.0697              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               041_063       fake        20                20               0            1.00         0.8599         0.0556              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               042_084       fake        20                 0              20            0.00         0.2683         0.1412              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               043_110       fake        20                19               1            0.95         0.7645         0.0303              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               044_945       fake        20                15               5            0.75         0.7341         0.0641              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               045_889       fake        20                 3              17            0.15         0.6360         0.0593              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               046_904       fake        20                18               2            0.90         0.7801         0.0524              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               047_862       fake        20                20               0            1.00         0.8273         0.0280              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               048_029       fake        20                17               3            0.85         0.7962         0.0613              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               049_946       fake        20                 0              20            0.00         0.2283         0.0780              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               050_059       fake        20                17               3            0.85         0.7655         0.0946              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               051_332       fake        20                13               7            0.65         0.7014         0.0821              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               052_108       fake        20                 6              14            0.30         0.6080         0.1289              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               053_095       fake        20                12               8            0.60         0.6938         0.0608              real                     0                   fake                          1\n","balanced_ffpp EfficientNet-B4                               054_071       fake        20                 2              18            0.10         0.5908         0.0778              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               055_147       fake        20                 0              20            0.00         0.4234         0.0968              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               056_996       fake        20                20               0            1.00         0.7461         0.0245              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               057_070       fake        20                 0              20            0.00         0.4204         0.0868              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               058_039       fake        20                 8              12            0.40         0.6675         0.1105              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4                               059_050       fake        20                 2              18            0.10         0.6006         0.0927              real                     0                   real                          0\n","balanced_ffpp EfficientNet-B4    04__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8940         0.0305              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   05__exit_phone_room       real        20                 0              20            0.00         0.8223         0.0613              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     05__hugging_happy       real        20                 1              19            0.05         0.7884         0.0575              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       05__kitchen_pan       real        20                 3              17            0.15         0.7617         0.0594              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     05__kitchen_still       real        20                 0              20            0.00         0.7988         0.0229              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4      05__outside_talking_pan_laughing       real        20                16               4            0.80         0.6019         0.1346              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4    05__outside_talking_still_laughing       real        20                19               1            0.95         0.6496         0.0326              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4               05__podium_speech_happy       real        20                 2              18            0.10         0.7417         0.0330              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              05__talking_against_wall       real        20                 0              20            0.00         0.9872         0.0013              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              05__walk_down_hall_angry       real        20                 0              20            0.00         0.7869         0.0377              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 05__walking_down_street_outside_angry       real        20                 6              14            0.30         0.7261         0.0493              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    05__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.9008         0.0447              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   06__exit_phone_room       real        20                 1              19            0.05         0.7766         0.0505              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     06__hugging_happy       real        20                17               3            0.85         0.6129         0.0888              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4                       06__kitchen_pan       real        20                 3              17            0.15         0.7907         0.0662              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     06__kitchen_still       real        20                 6              14            0.30         0.7137         0.0444              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4      06__outside_talking_pan_laughing       real        20                19               1            0.95         0.5349         0.1083              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4    06__outside_talking_still_laughing       real        20                20               0            1.00         0.5037         0.0443              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4               06__podium_speech_happy       real        20                10              10            0.50         0.6971         0.0481              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              06__talking_against_wall       real        20                 0              20            0.00         0.9587         0.0052              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               06__talking_angry_couch       real        20                 0              20            0.00         0.8514         0.0394              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              06__walk_down_hall_angry       real        20                 1              19            0.05         0.7808         0.0602              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4     06__walking_and_outside_surprised       real        20                 3              17            0.15         0.7645         0.0703              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4  06__walking_down_indoor_hall_disgust       real        20                 3              17            0.15         0.7733         0.0665              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 06__walking_down_street_outside_angry       real        20                20               0            1.00         0.6403         0.0313              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4    06__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8684         0.0337              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   07__exit_phone_room       real        20                 2              18            0.10         0.7482         0.0296              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     07__hugging_happy       real        20                 3              17            0.15         0.7667         0.0690              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       07__kitchen_pan       real        20                18               2            0.90         0.5825         0.0773              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4                     07__kitchen_still       real        20                20               0            1.00         0.4964         0.0380              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4      07__outside_talking_pan_laughing       real        20                19               1            0.95         0.5541         0.1246              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4    07__outside_talking_still_laughing       real        20                20               0            1.00         0.5303         0.0665              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4               07__podium_speech_happy       real        20                20               0            1.00         0.5075         0.0240              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4               07__secret_conversation       real        20                20               0            1.00         0.4687         0.0285              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4              07__talking_against_wall       real        20                 0              20            0.00         0.9548         0.0063              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               07__talking_angry_couch       real        20                15               5            0.75         0.6543         0.0485              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4              07__walk_down_hall_angry       real        20                 1              19            0.05         0.7974         0.0477              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 07__walking_down_street_outside_angry       real        20                 6              14            0.30         0.6923         0.0564              real                     1                   fake                          0\n","balanced_ffpp EfficientNet-B4    07__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8361         0.0198              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   08__exit_phone_room       real        20                 1              19            0.05         0.8126         0.0584              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       08__kitchen_pan       real        20                19               1            0.95         0.5381         0.0873              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4                     08__kitchen_still       real        20                20               0            1.00         0.4658         0.0406              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4      08__outside_talking_pan_laughing       real        20                17               3            0.85         0.6062         0.1169              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4    08__outside_talking_still_laughing       real        20                17               3            0.85         0.6085         0.0666              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4               08__podium_speech_happy       real        20                17               3            0.85         0.6445         0.0563              real                     1                   real                          1\n","balanced_ffpp EfficientNet-B4              08__talking_against_wall       real        20                 0              20            0.00         0.9550         0.0077              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              08__walk_down_hall_angry       real        20                 1              19            0.05         0.7990         0.0705              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 08__walking_down_street_outside_angry       real        20                 8              12            0.40         0.7383         0.0778              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    08__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8308         0.0207              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   09__exit_phone_room       real        20                 0              20            0.00         0.7904         0.0270              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       09__kitchen_pan       real        20                12               8            0.60         0.6462         0.0878              real                     1                   real                          1\n"]}]},{"cell_type":"code","source":["!cp -f /content/video_frame_breakdown.csv \"/content/drive/My Drive/video_frame_breakdown.csv\"\n","print(\"Copied to Drive → My Drive/video_frame_breakdown.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"72m7Ca8J3T6L","executionInfo":{"status":"ok","timestamp":1754995182238,"user_tz":-120,"elapsed":122,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"0fe871af-d7ca-4c5d-f312-8a81f29206cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Copied to Drive → My Drive/video_frame_breakdown.csv\n"]}]},{"cell_type":"code","source":["# === Pick best thresholds for accuracy and update the table ===\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_curve, accuracy_score, precision_recall_fscore_support\n","\n","assert 'per_video' in globals(), \"per_video not found. Run the breakdown cell first.\"\n","assert 'df' in globals(), \"df (frame scores) not found. Run the breakdown cell first.\"\n","\n","# --- 1) BEST THRESHOLD FOR VIDEO-LEVEL AVG SCORE ---\n","y_vid = (per_video[\"true_label\"] == \"fake\").astype(int).values\n","s_avg = per_video[\"avg_prob_fake\"].values\n","\n","# Candidate thresholds from ROC (good coverage)\n","_, _, thr_candidates = roc_curve(y_vid, s_avg)\n","# Ensure 0..1 range and unique\n","thr_candidates = np.unique(np.clip(thr_candidates, 0.0, 1.0))\n","\n","best_acc_avg, best_thr_avg, best_stats_avg = -1, 0.5, None\n","for t in thr_candidates:\n","    pred = (s_avg >= t).astype(int)\n","    acc = accuracy_score(y_vid, pred)\n","    if acc > best_acc_avg:\n","        # store a few helpful stats\n","        p, r, f1, _ = precision_recall_fscore_support(y_vid, pred, average=\"binary\", zero_division=0)\n","        best_acc_avg, best_thr_avg, best_stats_avg = acc, float(t), (p, r, f1)\n","\n","# Update avg-based columns with the best video threshold\n","per_video[\"video_pred_by_avg\"] = np.where(per_video[\"avg_prob_fake\"] >= best_thr_avg, \"fake\", \"real\")\n","per_video[\"video_correct_by_avg\"] = (per_video[\"video_pred_by_avg\"] == per_video[\"true_label\"]).astype(int)\n","\n","print(f\"✅ Best video threshold (by average score): {best_thr_avg:.4f}\")\n","print(f\"   Video accuracy: {best_acc_avg*100:.1f}%  | Precision: {best_stats_avg[0]:.3f}  | Recall: {best_stats_avg[1]:.3f}  | F1: {best_stats_avg[2]:.3f}\")\n","\n","# --- 2) BEST THRESHOLD FOR FRAME-LEVEL MAJORITY VOTE ---\n","# Build per-video frame score lists\n","videos = per_video[\"video_name\"].tolist()\n","truth_map = {row.video_name: (1 if row.true_label == \"fake\" else 0) for row in per_video.itertuples()}\n","\n","frames_by_video = {}\n","for row in df.itertuples():\n","    frames_by_video.setdefault(row.video_name, []).append(row.prob_fake)\n","\n","# Candidate thresholds from frame scores (quantiles to keep it fast)\n","all_frame_scores = df[\"prob_fake\"].values\n","quantiles = np.linspace(0, 1, 201)\n","thr_candidates_frames = np.unique(np.quantile(all_frame_scores, quantiles))\n","\n","best_acc_maj, best_thr_maj = -1, 0.5\n","for t in thr_candidates_frames:\n","    correct = 0\n","    for v in videos:\n","        scores = frames_by_video.get(v, [])\n","        if len(scores) == 0:\n","            # fallback to avg decision if no frames (shouldn't happen)\n","            pred = 1 if per_video.loc[per_video[\"video_name\"]==v, \"avg_prob_fake\"].values[0] >= best_thr_avg else 0\n","        else:\n","            # majority of frame predictions at threshold t (ties -> fall back to avg at best_thr_avg)\n","            preds = (np.array(scores) >= t).astype(int)\n","            mean_pred = preds.mean()\n","            if mean_pred == 0.5:\n","                pred = 1 if (np.mean(scores) >= best_thr_avg) else 0\n","            else:\n","                pred = 1 if mean_pred > 0.5 else 0\n","        correct += int(pred == truth_map[v])\n","    acc = correct / len(videos)\n","    if acc > best_acc_maj:\n","        best_acc_maj, best_thr_maj = acc, float(t)\n","\n","# Update majority columns using the best frame threshold\n","maj_preds = []\n","for v in per_video[\"video_name\"]:\n","    scores = frames_by_video.get(v, [])\n","    if len(scores) == 0:\n","        pred = 1 if per_video.loc[per_video[\"video_name\"]==v, \"avg_prob_fake\"].values[0] >= best_thr_avg else 0\n","    else:\n","        preds = (np.array(scores) >= best_thr_maj).astype(int)\n","        mean_pred = preds.mean()\n","        if mean_pred == 0.5:\n","            pred = 1 if (np.mean(scores) >= best_thr_avg) else 0\n","        else:\n","            pred = 1 if mean_pred > 0.5 else 0\n","    maj_preds.append(\"fake\" if pred==1 else \"real\")\n","\n","per_video[\"video_pred_by_majority\"] = maj_preds\n","per_video[\"video_correct_by_majority\"] = (per_video[\"video_pred_by_majority\"] == per_video[\"true_label\"]).astype(int)\n","\n","print(f\"✅ Best frame threshold (for majority vote): {best_thr_maj:.4f}\")\n","print(f\"   Video accuracy (majority): {best_acc_maj*100:.1f}%\")\n","\n","# --- 3) Save updated table ---\n","out_csv = \"/content/video_frame_breakdown_best_thresholds.csv\"\n","per_video.to_csv(out_csv, index=False)\n","print(\"📁 Saved:\", out_csv)\n","\n","# (Optional) copy to Drive\n","# !cp -f /content/video_frame_breakdown_best_thresholds.csv \"/content/drive/My Drive/video_frame_breakdown_best_thresholds.csv\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLvcZHJ37zWN","executionInfo":{"status":"ok","timestamp":1754996361534,"user_tz":-120,"elapsed":384,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"b820c087-984e-434a-d633-6ac4d0ba8792"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Best video threshold (by average score): 0.2283\n","   Video accuracy: 50.0%  | Precision: 0.500  | Recall: 1.000  | F1: 0.667\n","✅ Best frame threshold (for majority vote): 0.0808\n","   Video accuracy (majority): 50.0%\n","📁 Saved: /content/video_frame_breakdown_best_thresholds.csv\n"]}]},{"cell_type":"code","source":["# === Show full per-video table in Colab, then save to Drive ===\n","import os, time\n","import pandas as pd\n","\n","# If you haven't already in this session:\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# 1) Load the table (prefer in-memory, else CSV fallbacks)\n","if 'per_video' in globals():\n","    table_df = per_video.copy()\n","elif os.path.exists(\"/content/video_frame_breakdown_best_thresholds.csv\"):\n","    table_df = pd.read_csv(\"/content/video_frame_breakdown_best_thresholds.csv\")\n","elif os.path.exists(\"/content/video_frame_breakdown.csv\"):\n","    table_df = pd.read_csv(\"/content/video_frame_breakdown.csv\")\n","else:\n","    raise RuntimeError(\"No table found. Re-run the breakdown cell first.\")\n","\n","# 2) Show ALL rows in the output cell\n","pd.set_option(\"display.max_rows\", None)\n","pd.set_option(\"display.max_colwidth\", None)\n","table_df = table_df.sort_values([\"true_label\",\"video_name\"])\n","print(table_df.to_string(index=False))\n","\n","# 3) Save to Drive (timestamped filename)\n","ts = time.strftime(\"%Y%m%d-%H%M%S\")\n","drive_path = f\"/content/drive/My Drive/video_frame_breakdown_{ts}.csv\"\n","table_df.to_csv(drive_path, index=False)\n","print(\"\\n✅ Saved to Drive:\", drive_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8MqkDRPB8pXa","executionInfo":{"status":"ok","timestamp":1754996583262,"user_tz":-120,"elapsed":2394,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"d0352a72-1492-4ce3-f0c0-38f78f106780"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","      dataset        detector                            video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake video_pred_by_avg  video_correct_by_avg video_pred_by_majority  video_correct_by_majority\n","balanced_ffpp EfficientNet-B4                               000_003       fake        20                 0              20            0.00         0.5973         0.0547              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               010_005       fake        20                 1              19            0.05         0.4391         0.1074              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               011_805       fake        20                 0              20            0.00         0.4297         0.0848              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               012_026       fake        20                 0              20            0.00         0.6066         0.0565              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               013_883       fake        20                 0              20            0.00         0.4084         0.0592              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               014_790       fake        20                 9              11            0.45         0.6489         0.1074              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               015_919       fake        20                 0              20            0.00         0.4481         0.0965              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               016_209       fake        20                20               0            1.00         0.7817         0.0348              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               017_803       fake        20                 1              19            0.05         0.5241         0.1699              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               018_019       fake        20                 2              18            0.10         0.5610         0.1020              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               019_018       fake        20                 0              20            0.00         0.2372         0.0488              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               020_344       fake        20                 3              17            0.15         0.6420         0.0485              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               021_312       fake        20                20               0            1.00         0.7625         0.0215              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               022_489       fake        20                 4              16            0.20         0.6627         0.0610              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               023_923       fake        20                20               0            1.00         0.8758         0.0346              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               024_073       fake        20                12               8            0.60         0.6713         0.1554              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               025_067       fake        20                19               1            0.95         0.7561         0.0374              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               026_012       fake        20                 1              19            0.05         0.6016         0.0756              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               027_009       fake        20                 3              17            0.15         0.5985         0.0649              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               028_068       fake        20                15               5            0.75         0.7142         0.1035              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               029_048       fake        20                 0              20            0.00         0.4376         0.1295              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               030_193       fake        20                17               3            0.85         0.7988         0.0654              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               031_163       fake        20                 0              20            0.00         0.5784         0.0531              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               032_944       fake        20                16               4            0.80         0.7441         0.0527              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               033_097       fake        20                20               0            1.00         0.8396         0.0390              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               034_590       fake        20                 0              20            0.00         0.2591         0.1188              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               035_036       fake        20                 0              20            0.00         0.5355         0.0402              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               036_035       fake        20                 0              20            0.00         0.6008         0.0494              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               037_072       fake        20                 3              17            0.15         0.6217         0.0674              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               038_125       fake        20                11               9            0.55         0.6941         0.0531              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               039_058       fake        20                18               2            0.90         0.7815         0.0516              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               040_997       fake        20                 0              20            0.00         0.6110         0.0697              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               041_063       fake        20                20               0            1.00         0.8599         0.0556              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               042_084       fake        20                 0              20            0.00         0.2683         0.1412              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               043_110       fake        20                19               1            0.95         0.7645         0.0303              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               044_945       fake        20                15               5            0.75         0.7341         0.0641              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               045_889       fake        20                 3              17            0.15         0.6360         0.0593              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               046_904       fake        20                18               2            0.90         0.7801         0.0524              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               047_862       fake        20                20               0            1.00         0.8273         0.0280              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               048_029       fake        20                17               3            0.85         0.7962         0.0613              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               049_946       fake        20                 0              20            0.00         0.2283         0.0780              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               050_059       fake        20                17               3            0.85         0.7655         0.0946              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               051_332       fake        20                13               7            0.65         0.7014         0.0821              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               052_108       fake        20                 6              14            0.30         0.6080         0.1289              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               053_095       fake        20                12               8            0.60         0.6938         0.0608              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               054_071       fake        20                 2              18            0.10         0.5908         0.0778              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               055_147       fake        20                 0              20            0.00         0.4234         0.0968              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               056_996       fake        20                20               0            1.00         0.7461         0.0245              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               057_070       fake        20                 0              20            0.00         0.4204         0.0868              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               058_039       fake        20                 8              12            0.40         0.6675         0.1105              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4                               059_050       fake        20                 2              18            0.10         0.6006         0.0927              fake                     1                   fake                          1\n","balanced_ffpp EfficientNet-B4    04__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8940         0.0305              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   05__exit_phone_room       real        20                 0              20            0.00         0.8223         0.0613              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     05__hugging_happy       real        20                 1              19            0.05         0.7884         0.0575              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       05__kitchen_pan       real        20                 3              17            0.15         0.7617         0.0594              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     05__kitchen_still       real        20                 0              20            0.00         0.7988         0.0229              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4      05__outside_talking_pan_laughing       real        20                16               4            0.80         0.6019         0.1346              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    05__outside_talking_still_laughing       real        20                19               1            0.95         0.6496         0.0326              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               05__podium_speech_happy       real        20                 2              18            0.10         0.7417         0.0330              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              05__talking_against_wall       real        20                 0              20            0.00         0.9872         0.0013              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              05__walk_down_hall_angry       real        20                 0              20            0.00         0.7869         0.0377              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 05__walking_down_street_outside_angry       real        20                 6              14            0.30         0.7261         0.0493              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    05__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.9008         0.0447              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   06__exit_phone_room       real        20                 1              19            0.05         0.7766         0.0505              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     06__hugging_happy       real        20                17               3            0.85         0.6129         0.0888              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       06__kitchen_pan       real        20                 3              17            0.15         0.7907         0.0662              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     06__kitchen_still       real        20                 6              14            0.30         0.7137         0.0444              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4      06__outside_talking_pan_laughing       real        20                19               1            0.95         0.5349         0.1083              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    06__outside_talking_still_laughing       real        20                20               0            1.00         0.5037         0.0443              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               06__podium_speech_happy       real        20                10              10            0.50         0.6971         0.0481              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              06__talking_against_wall       real        20                 0              20            0.00         0.9587         0.0052              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               06__talking_angry_couch       real        20                 0              20            0.00         0.8514         0.0394              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              06__walk_down_hall_angry       real        20                 1              19            0.05         0.7808         0.0602              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4     06__walking_and_outside_surprised       real        20                 3              17            0.15         0.7645         0.0703              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4  06__walking_down_indoor_hall_disgust       real        20                 3              17            0.15         0.7733         0.0665              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 06__walking_down_street_outside_angry       real        20                20               0            1.00         0.6403         0.0313              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    06__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8684         0.0337              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   07__exit_phone_room       real        20                 2              18            0.10         0.7482         0.0296              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     07__hugging_happy       real        20                 3              17            0.15         0.7667         0.0690              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       07__kitchen_pan       real        20                18               2            0.90         0.5825         0.0773              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     07__kitchen_still       real        20                20               0            1.00         0.4964         0.0380              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4      07__outside_talking_pan_laughing       real        20                19               1            0.95         0.5541         0.1246              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    07__outside_talking_still_laughing       real        20                20               0            1.00         0.5303         0.0665              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               07__podium_speech_happy       real        20                20               0            1.00         0.5075         0.0240              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               07__secret_conversation       real        20                20               0            1.00         0.4687         0.0285              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              07__talking_against_wall       real        20                 0              20            0.00         0.9548         0.0063              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               07__talking_angry_couch       real        20                15               5            0.75         0.6543         0.0485              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              07__walk_down_hall_angry       real        20                 1              19            0.05         0.7974         0.0477              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 07__walking_down_street_outside_angry       real        20                 6              14            0.30         0.6923         0.0564              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    07__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8361         0.0198              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   08__exit_phone_room       real        20                 1              19            0.05         0.8126         0.0584              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       08__kitchen_pan       real        20                19               1            0.95         0.5381         0.0873              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                     08__kitchen_still       real        20                20               0            1.00         0.4658         0.0406              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4      08__outside_talking_pan_laughing       real        20                17               3            0.85         0.6062         0.1169              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    08__outside_talking_still_laughing       real        20                17               3            0.85         0.6085         0.0666              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4               08__podium_speech_happy       real        20                17               3            0.85         0.6445         0.0563              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              08__talking_against_wall       real        20                 0              20            0.00         0.9550         0.0077              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4              08__walk_down_hall_angry       real        20                 1              19            0.05         0.7990         0.0705              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4 08__walking_down_street_outside_angry       real        20                 8              12            0.40         0.7383         0.0778              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4    08__walking_outside_cafe_disgusted       real        20                 0              20            0.00         0.8308         0.0207              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                   09__exit_phone_room       real        20                 0              20            0.00         0.7904         0.0270              fake                     0                   fake                          0\n","balanced_ffpp EfficientNet-B4                       09__kitchen_pan       real        20                12               8            0.60         0.6462         0.0878              fake                     0                   fake                          0\n","\n","✅ Saved to Drive: /content/drive/My Drive/video_frame_breakdown_20250812-110303.csv\n"]}]},{"cell_type":"code","source":["# === Compact per-video table (fixes “all fake yes” by choosing a balanced threshold) ===\n","# Prints ONLY the table with: dataset, detector, video_name, true_label, correctly_predicted (yes/no)\n","\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_curve, roc_auc_score\n","\n","# ---- settings (edit names if you want) ----\n","DATASET_NAME  = \"balanced_ffpp\"\n","DETECTOR_NAME = \"EfficientNet-B4\"\n","FILTER = 0.30      # drop low-confidence frames: keep only |p-0.5| >= FILTER before aggregation\n","AGG = \"median\"     # per-video aggregator: \"median\" (recommended)\n","\n","# ---- require frame scores DataFrame 'df' in memory ----\n","# df must have columns: video_name, true_label in {\"real\",\"fake\"}, prob_fake (already oriented if you flipped earlier)\n","assert 'df' in globals(), \"Run your scoring cell first to create 'df' (frame scores).\"\n","\n","# 1) per-video score with filtering (fallback to unfiltered if a video is emptied by the filter)\n","def video_score(group, filt=FILTER, agg=AGG):\n","    s = group[\"prob_fake\"].values\n","    keep = np.abs(s - 0.5) >= filt\n","    s_use = s[keep] if keep.any() else s\n","    if agg == \"median\":\n","        return float(np.median(s_use)) if s_use.size else 0.5\n","    else:\n","        return float(np.median(s_use)) if s_use.size else 0.5\n","\n","vid = df.groupby([\"video_name\",\"true_label\"]).apply(video_score).reset_index(name=\"video_score\")\n","\n","# 2) pick the correct score orientation (use the one with higher AUC so fakes tend to score higher)\n","y = (vid[\"true_label\"] == \"fake\").astype(int).values\n","s = vid[\"video_score\"].values\n","auc_as = roc_auc_score(y, s)\n","auc_fl = roc_auc_score(y, 1 - s)\n","if auc_fl > auc_as:\n","    s = 1 - s\n","\n","# 3) choose a threshold that maximizes **balanced accuracy** (Youden’s J = TPR - FPR)\n","fpr, tpr, thr = roc_curve(y, s)\n","J = tpr - fpr\n","j_best = int(np.argmax(J))\n","thr_best = float(thr[j_best])\n","\n","# 4) decisions and compact table\n","pred = (s >= thr_best).astype(int)\n","correct = (pred == y).astype(int)\n","\n","out = pd.DataFrame({\n","    \"dataset\": DATASET_NAME,\n","    \"detector\": DETECTOR_NAME,\n","    \"video_name\": vid[\"video_name\"].values,\n","    \"true_label\": vid[\"true_label\"].values,\n","    \"correctly_predicted\": np.where(correct==1, \"yes\", \"no\")\n","}).sort_values([\"true_label\",\"video_name\"])\n","\n","pd.set_option(\"display.max_rows\", None)\n","print(out.to_string(index=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQsM4BkxBAgF","executionInfo":{"status":"ok","timestamp":1754997725095,"user_tz":-120,"elapsed":147,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"1bff04a1-207b-41f5-fb19-481d23830d31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["      dataset        detector                            video_name true_label correctly_predicted\n","balanced_ffpp EfficientNet-B4                               000_003       fake                 yes\n","balanced_ffpp EfficientNet-B4                               010_005       fake                 yes\n","balanced_ffpp EfficientNet-B4                               011_805       fake                 yes\n","balanced_ffpp EfficientNet-B4                               012_026       fake                 yes\n","balanced_ffpp EfficientNet-B4                               013_883       fake                 yes\n","balanced_ffpp EfficientNet-B4                               014_790       fake                  no\n","balanced_ffpp EfficientNet-B4                               015_919       fake                 yes\n","balanced_ffpp EfficientNet-B4                               016_209       fake                  no\n","balanced_ffpp EfficientNet-B4                               017_803       fake                 yes\n","balanced_ffpp EfficientNet-B4                               018_019       fake                 yes\n","balanced_ffpp EfficientNet-B4                               019_018       fake                 yes\n","balanced_ffpp EfficientNet-B4                               020_344       fake                 yes\n","balanced_ffpp EfficientNet-B4                               021_312       fake                  no\n","balanced_ffpp EfficientNet-B4                               022_489       fake                  no\n","balanced_ffpp EfficientNet-B4                               023_923       fake                  no\n","balanced_ffpp EfficientNet-B4                               024_073       fake                  no\n","balanced_ffpp EfficientNet-B4                               025_067       fake                  no\n","balanced_ffpp EfficientNet-B4                               026_012       fake                 yes\n","balanced_ffpp EfficientNet-B4                               027_009       fake                 yes\n","balanced_ffpp EfficientNet-B4                               028_068       fake                  no\n","balanced_ffpp EfficientNet-B4                               029_048       fake                 yes\n","balanced_ffpp EfficientNet-B4                               030_193       fake                  no\n","balanced_ffpp EfficientNet-B4                               031_163       fake                 yes\n","balanced_ffpp EfficientNet-B4                               032_944       fake                  no\n","balanced_ffpp EfficientNet-B4                               033_097       fake                  no\n","balanced_ffpp EfficientNet-B4                               034_590       fake                 yes\n","balanced_ffpp EfficientNet-B4                               035_036       fake                 yes\n","balanced_ffpp EfficientNet-B4                               036_035       fake                 yes\n","balanced_ffpp EfficientNet-B4                               037_072       fake                 yes\n","balanced_ffpp EfficientNet-B4                               038_125       fake                  no\n","balanced_ffpp EfficientNet-B4                               039_058       fake                  no\n","balanced_ffpp EfficientNet-B4                               040_997       fake                 yes\n","balanced_ffpp EfficientNet-B4                               041_063       fake                  no\n","balanced_ffpp EfficientNet-B4                               042_084       fake                 yes\n","balanced_ffpp EfficientNet-B4                               043_110       fake                  no\n","balanced_ffpp EfficientNet-B4                               044_945       fake                  no\n","balanced_ffpp EfficientNet-B4                               045_889       fake                 yes\n","balanced_ffpp EfficientNet-B4                               046_904       fake                  no\n","balanced_ffpp EfficientNet-B4                               047_862       fake                  no\n","balanced_ffpp EfficientNet-B4                               048_029       fake                  no\n","balanced_ffpp EfficientNet-B4                               049_946       fake                 yes\n","balanced_ffpp EfficientNet-B4                               050_059       fake                  no\n","balanced_ffpp EfficientNet-B4                               051_332       fake                  no\n","balanced_ffpp EfficientNet-B4                               052_108       fake                 yes\n","balanced_ffpp EfficientNet-B4                               053_095       fake                  no\n","balanced_ffpp EfficientNet-B4                               054_071       fake                 yes\n","balanced_ffpp EfficientNet-B4                               055_147       fake                 yes\n","balanced_ffpp EfficientNet-B4                               056_996       fake                  no\n","balanced_ffpp EfficientNet-B4                               057_070       fake                 yes\n","balanced_ffpp EfficientNet-B4                               058_039       fake                  no\n","balanced_ffpp EfficientNet-B4                               059_050       fake                 yes\n","balanced_ffpp EfficientNet-B4    04__walking_outside_cafe_disgusted       real                 yes\n","balanced_ffpp EfficientNet-B4                   05__exit_phone_room       real                 yes\n","balanced_ffpp EfficientNet-B4                     05__hugging_happy       real                 yes\n","balanced_ffpp EfficientNet-B4                       05__kitchen_pan       real                 yes\n","balanced_ffpp EfficientNet-B4                     05__kitchen_still       real                 yes\n","balanced_ffpp EfficientNet-B4      05__outside_talking_pan_laughing       real                  no\n","balanced_ffpp EfficientNet-B4    05__outside_talking_still_laughing       real                 yes\n","balanced_ffpp EfficientNet-B4               05__podium_speech_happy       real                 yes\n","balanced_ffpp EfficientNet-B4              05__talking_against_wall       real                 yes\n","balanced_ffpp EfficientNet-B4              05__walk_down_hall_angry       real                 yes\n","balanced_ffpp EfficientNet-B4 05__walking_down_street_outside_angry       real                 yes\n","balanced_ffpp EfficientNet-B4    05__walking_outside_cafe_disgusted       real                 yes\n","balanced_ffpp EfficientNet-B4                   06__exit_phone_room       real                 yes\n","balanced_ffpp EfficientNet-B4                     06__hugging_happy       real                 yes\n","balanced_ffpp EfficientNet-B4                       06__kitchen_pan       real                 yes\n","balanced_ffpp EfficientNet-B4                     06__kitchen_still       real                 yes\n","balanced_ffpp EfficientNet-B4      06__outside_talking_pan_laughing       real                  no\n","balanced_ffpp EfficientNet-B4    06__outside_talking_still_laughing       real                  no\n","balanced_ffpp EfficientNet-B4               06__podium_speech_happy       real                 yes\n","balanced_ffpp EfficientNet-B4              06__talking_against_wall       real                 yes\n","balanced_ffpp EfficientNet-B4               06__talking_angry_couch       real                 yes\n","balanced_ffpp EfficientNet-B4              06__walk_down_hall_angry       real                 yes\n","balanced_ffpp EfficientNet-B4     06__walking_and_outside_surprised       real                 yes\n","balanced_ffpp EfficientNet-B4  06__walking_down_indoor_hall_disgust       real                 yes\n","balanced_ffpp EfficientNet-B4 06__walking_down_street_outside_angry       real                 yes\n","balanced_ffpp EfficientNet-B4    06__walking_outside_cafe_disgusted       real                 yes\n","balanced_ffpp EfficientNet-B4                   07__exit_phone_room       real                 yes\n","balanced_ffpp EfficientNet-B4                     07__hugging_happy       real                 yes\n","balanced_ffpp EfficientNet-B4                       07__kitchen_pan       real                  no\n","balanced_ffpp EfficientNet-B4                     07__kitchen_still       real                  no\n","balanced_ffpp EfficientNet-B4      07__outside_talking_pan_laughing       real                  no\n","balanced_ffpp EfficientNet-B4    07__outside_talking_still_laughing       real                  no\n","balanced_ffpp EfficientNet-B4               07__podium_speech_happy       real                  no\n","balanced_ffpp EfficientNet-B4               07__secret_conversation       real                  no\n","balanced_ffpp EfficientNet-B4              07__talking_against_wall       real                 yes\n","balanced_ffpp EfficientNet-B4               07__talking_angry_couch       real                 yes\n","balanced_ffpp EfficientNet-B4              07__walk_down_hall_angry       real                 yes\n","balanced_ffpp EfficientNet-B4 07__walking_down_street_outside_angry       real                 yes\n","balanced_ffpp EfficientNet-B4    07__walking_outside_cafe_disgusted       real                 yes\n","balanced_ffpp EfficientNet-B4                   08__exit_phone_room       real                 yes\n","balanced_ffpp EfficientNet-B4                       08__kitchen_pan       real                  no\n","balanced_ffpp EfficientNet-B4                     08__kitchen_still       real                  no\n","balanced_ffpp EfficientNet-B4      08__outside_talking_pan_laughing       real                  no\n","balanced_ffpp EfficientNet-B4    08__outside_talking_still_laughing       real                  no\n","balanced_ffpp EfficientNet-B4               08__podium_speech_happy       real                 yes\n","balanced_ffpp EfficientNet-B4              08__talking_against_wall       real                 yes\n","balanced_ffpp EfficientNet-B4              08__walk_down_hall_angry       real                 yes\n","balanced_ffpp EfficientNet-B4 08__walking_down_street_outside_angry       real                 yes\n","balanced_ffpp EfficientNet-B4    08__walking_outside_cafe_disgusted       real                 yes\n","balanced_ffpp EfficientNet-B4                   09__exit_phone_room       real                 yes\n","balanced_ffpp EfficientNet-B4                       09__kitchen_pan       real                 yes\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1465439719.py:27: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  vid = df.groupby([\"video_name\",\"true_label\"]).apply(video_score).reset_index(name=\"video_score\")\n"]}]},{"cell_type":"code","source":["# Save the compact table as CSV named exactly: \"prediction table efficientnet.csv\"\n","import os, pandas as pd\n","from google.colab import drive\n","\n","# Ensure the table exists\n","assert 'out' in globals(), \"Run the compact table cell first to create the 'out' DataFrame.\"\n","\n","# Local save\n","local_path = \"/content/prediction table efficientnet.csv\"\n","out.to_csv(local_path, index=False)\n","\n","# Copy to Drive\n","drive.mount('/content/drive', force_remount=False)\n","drive_path = \"/content/drive/My Drive/prediction table efficientnet.csv\"\n","\n","# Use Python copy to avoid shell quoting issues\n","import shutil\n","shutil.copyfile(local_path, drive_path)\n","\n","print(\"Saved:\", local_path)\n","print(\"Copied to Drive:\", drive_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KdNvpgh6BlAX","executionInfo":{"status":"ok","timestamp":1754997876139,"user_tz":-120,"elapsed":1796,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"fcd625e2-6354-4939-8806-429b0445838a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Saved: /content/prediction table efficientnet.csv\n","Copied to Drive: /content/drive/My Drive/prediction table efficientnet.csv\n"]}]}]}