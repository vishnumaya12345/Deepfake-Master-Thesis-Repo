{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQE1IPqb18kqwiBzNx5zfQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":480},"id":"wMzwOrA9P0W4","executionInfo":{"status":"error","timestamp":1756580817437,"user_tz":-120,"elapsed":1132056,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"d4f9f0a2-4d61-4883-d972-663f8ee33186"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Capsule model loaded\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2395063823.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;31m# ---------- auto orientation (flip scores if helps per-video AUC) ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-2395063823.py\u001b[0m in \u001b[0;36mscore_frames\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    261\u001b[0m                         num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n\u001b[1;32m    262\u001b[0m     \u001b[0mvnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_tta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# === Capsule (spatial) on balanced_frames_FF++ — prints ONLY: \"Capsule model loaded\" + AUC | EER | AP ===\n","# Implements VGG19 feature extractor + Capsule head (as in DeepfakeBench CapsuleNetDetector),\n","# loads capsule_best.pth (partial-safe), does light TTA (flip), auto orientation, and picks the best\n","# video aggregation (median / perc90 / top10 / trim10). Uses 256x256 RGB with ImageNet normalization.\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# ---------- paths ----------\n","import os, re, io, contextlib, subprocess, numpy as np, pandas as pd, cv2, math\n","from PIL import Image\n","\n","ROOT = \"/content/drive/MyDrive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","REAL_DIR = f\"{ROOT}/balanced_frames_FF++/real\"\n","FAKE_DIR = f\"{ROOT}/balanced_frames_FF++/fake\"\n","CAPSULE_WEIGHTS = f\"{ROOT}/DeepfakeBench_weights/capsule_best.pth\"\n","\n","assert os.path.isdir(REAL_DIR) and os.path.isdir(FAKE_DIR), \"Check dataset folders.\"\n","assert os.path.isfile(CAPSULE_WEIGHTS), \"Missing capsule_best.pth.\"\n","\n","# ---------- deps ----------\n","def _pipq(*pkgs): subprocess.run([os.sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs], check=True)\n","try:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    import torchvision\n","    from torchvision import models\n","except Exception:\n","    _pipq(\"torch\", \"torchvision\"); import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","# ---------- hardware / knobs ----------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = (device.type==\"cuda\")\n","IMG_SIZE    = 256\n","BATCH       = 16 if device.type==\"cuda\" else 8\n","NUM_WORKERS = 2 if device.type==\"cuda\" else 0\n","FRAME_CAP   = 120      # try 100–150 depending on runtime\n","softmax = torch.nn.Softmax(dim=1)\n","\n","# ---------- utils: list & name frames ----------\n","IMG_EXTS=(\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def list_imgs(d): return sorted([os.path.join(d,f) for f in os.listdir(d) if f.lower().endswith(IMG_EXTS)]) if os.path.isdir(d) else []\n","reals, fakes = list_imgs(REAL_DIR), list_imgs(FAKE_DIR)\n","assert len(reals) and len(fakes), f\"No images found. REAL={len(reals)} FAKE={len(fakes)}.\"\n","\n","def infer_video_name(p):\n","    stem=os.path.splitext(os.path.basename(p))[0]\n","    m=re.split(r\"_frame(\\d+)$\", stem)\n","    return m[0] if len(m)>1 and m[0] else re.sub(r\"[_\\-]\\d+$\",\"\",stem)\n","\n","def frame_index(p):\n","    m=re.search(r\"_frame(\\d+)\", os.path.basename(p))\n","    return int(m.group(1)) if m else 10**9\n","\n","def build_df(paths, label):\n","    rows=[{\"path\":p,\"video_name\":infer_video_name(p),\"idx\":frame_index(p),\"label\":label} for p in paths]\n","    return pd.DataFrame(rows).sort_values([\"video_name\",\"idx\"])\n","\n","df_sel = pd.concat([build_df(reals,0), build_df(fakes,1)], ignore_index=True)\n","df_sel = df_sel.sort_values([\"video_name\",\"idx\"]).groupby(\"video_name\", as_index=False).head(FRAME_CAP).reset_index(drop=True)\n","\n","# ---------- preprocessing (RGB -> tensor) ----------\n","IMN_MEAN = np.array([0.485,0.456,0.406], np.float32)\n","IMN_STD  = np.array([0.229,0.224,0.225], np.float32)\n","\n","def prep_rgb(path, out=IMG_SIZE):\n","    im = cv2.imread(path, cv2.IMREAD_COLOR)\n","    if im is None:\n","        im = cv2.cvtColor(np.array(Image.open(path).convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im, (out,out), interpolation=cv2.INTER_CUBIC).astype(np.float32)/255.0\n","    x = im.transpose(2,0,1)\n","    x = (x - IMN_MEAN[:,None,None]) / IMN_STD[:,None,None]\n","    return torch.from_numpy(x.astype(np.float32))\n","\n","class DSRGB(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, i):\n","        r=self.df.iloc[i]\n","        x = prep_rgb(r[\"path\"])\n","        return x, int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","# ---------- Capsule model (per DeepfakeBench structure) ----------\n","class VggExtractor(nn.Module):\n","    def __init__(self, train=False):\n","        super().__init__()\n","        # handle both new/old torchvision APIs quietly\n","        try:\n","            vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_FEATURES)\n","        except Exception:\n","            vgg = models.vgg19(pretrained=True)\n","        self.vgg_1 = nn.Sequential(*list(vgg.features.children())[:19])  # 0..18 inclusive\n","        if train:\n","            self.vgg_1.train(True)\n","        else:\n","            self.vgg_1.eval()\n","    def forward(self, x): return self.vgg_1(x)\n","\n","class StatsNet(nn.Module):\n","    def forward(self, x):\n","        # x: [B, C, H, W]  ->  [B, 2, C] with per-channel mean/std over spatial dims\n","        B,C,H,W = x.shape\n","        x = x.view(B, C, H*W)\n","        mean = torch.mean(x, dim=2)\n","        std  = torch.std(x, dim=2)\n","        return torch.stack((mean, std), dim=1)  # [B, 2, C]\n","\n","class View(nn.Module):\n","    def __init__(self, *shape): super().__init__(); self.shape = shape\n","    def forward(self, inp): return inp.view(self.shape)\n","\n","class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.NO_CAPS = 10\n","        self.capsules = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(256, 64, kernel_size=3, stride=1, padding=1),\n","                nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","                nn.Conv2d(64, 16, kernel_size=3, stride=1, padding=1),\n","                nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n","                StatsNet(),                          # [B, 2, 16]\n","                nn.Conv1d(2, 8, kernel_size=5, stride=2, padding=2),  # [B, 8, 8]\n","                nn.BatchNorm1d(8),\n","                nn.Conv1d(8, 1, kernel_size=3, stride=1, padding=1),  # [B, 1, 8]\n","                nn.BatchNorm1d(1),\n","                View(-1, 8),                        # [B, 8]\n","            ) for _ in range(self.NO_CAPS)\n","        ])\n","    def squash(self, tensor, dim):\n","        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n","        scale = squared_norm / (1.0 + squared_norm + 1e-8)\n","        return scale * tensor / (torch.sqrt(squared_norm + 1e-8))\n","    def forward(self, x):\n","        outs = [cap(x) for cap in self.capsules]   # list of [B,8]\n","        out  = torch.stack(outs, dim=-1)           # [B, 8, NO_CAPS]\n","        return self.squash(out, dim=-1)            # [B, 8, NO_CAPS]\n","\n","class RoutingLayer(nn.Module):\n","    def __init__(self, num_input_capsules, num_output_capsules, data_in, data_out, num_iterations):\n","        super().__init__()\n","        self.num_iterations = num_iterations\n","        # [out_caps, in_caps, data_out, data_in]\n","        self.route_weights = nn.Parameter(torch.randn(num_output_capsules, num_input_capsules, data_out, data_in)*0.1)\n","    def squash(self, tensor, dim):\n","        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n","        scale = squared_norm / (1.0 + squared_norm + 1e-8)\n","        return scale * tensor / (torch.sqrt(squared_norm + 1e-8))\n","    def forward(self, x, random=False, dropout=0.0):\n","        # x: [B, data_in, in_caps]\n","        x = x.transpose(2,1)   # [B, in_caps, data_in]\n","        route_weights = self.route_weights\n","        # priors: [out_caps, B, in_caps, data_out, 1]\n","        priors = route_weights[:, None, :, :, :] @ x[None, :, :, :, None]\n","        priors = priors.transpose(1,0)  # [B, out_caps, in_caps, data_out, 1]\n","        if dropout > 0.0:\n","            drop = torch.bernoulli(torch.full_like(priors, 1.0 - dropout))\n","            priors = priors * drop\n","        logits = torch.zeros_like(priors)\n","        for i in range(self.num_iterations):\n","            probs = F.softmax(logits, dim=2)\n","            outputs = self.squash((probs * priors).sum(dim=2, keepdim=True), dim=3)  # [B, out_caps, 1, data_out, 1]\n","            if i != self.num_iterations - 1:\n","                logits = logits + priors * outputs\n","        outputs = outputs.squeeze()  # [B, out_caps, data_out] or [out_caps, data_out] -> handle batch\n","        if outputs.ndim == 2:\n","            outputs = outputs.unsqueeze(0)\n","        outputs = outputs.transpose(2,1).contiguous()  # [B, data_out, out_caps]\n","        return outputs\n","\n","class CapsuleNet(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        self.num_classes = num_classes\n","        self.vgg_ext = VggExtractor(train=False)\n","        self.fea_ext = FeatureExtractor()\n","        self.routing = RoutingLayer(num_input_capsules=10, num_output_capsules=num_classes,\n","                                    data_in=8, data_out=4, num_iterations=2)\n","        # init small\n","        self.apply(self._weights_init)\n","    def _weights_init(self, m):\n","        name = m.__class__.__name__\n","        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n","            if hasattr(m, \"weight\") and m.weight is not None:\n","                nn.init.normal_(m.weight, 0.0, 0.02)\n","        if isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n","            if hasattr(m, \"weight\") and m.weight is not None:\n","                nn.init.normal_(m.weight, 1.0, 0.02)\n","            if hasattr(m, \"bias\") and m.bias is not None:\n","                nn.init.constant_(m.bias, 0.0)\n","    def forward(self, x):\n","        with torch.no_grad():\n","            feat = self.vgg_ext(x)           # [B,256,H',W']\n","        caps = self.fea_ext(feat)            # [B,8,10]\n","        z = self.routing(caps, random=False, dropout=0.0)   # [B,4,2]\n","        classes = F.softmax(z, dim=-1)       # [B,4,2] softmax over out_caps\n","        pred = classes.detach().mean(dim=1)  # [B,2]\n","        prob = F.softmax(pred, dim=1)[:,1]   # scalar prob of class-1 (fake)\n","        return pred, prob\n","\n","# ---------- build model + weights ----------\n","model = CapsuleNet(num_classes=2)\n","\n","def try_load_capsule_weights(model, ckpt_path, min_cover=0.25):\n","    ok=False; cover=0.0\n","    try:\n","        sd=torch.load(ckpt_path, map_location=\"cpu\")\n","        if isinstance(sd,dict):\n","            for k in (\"state_dict\",\"model\",\"net\",\"weights\",\"model_state\",\"ema_state_dict\"):\n","                if k in sd and isinstance(sd[k],dict): sd=sd[k]; break\n","        clean={}\n","        if isinstance(sd,dict):\n","            for k,v in sd.items():\n","                if not isinstance(k,str): continue\n","                k2=k\n","                # strip common prefixes\n","                for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\",\"vgg_ext.\",\"fea_ext.\",\"routing.\",\"routing_stats.\"):\n","                    if k2.startswith(pref): k2=k2[len(pref):]\n","                clean[k2]=v\n","            ms=model.state_dict()\n","            matched={k:v for k,v in clean.items() if k in ms and ms[k].shape==v.shape}\n","            cover=len(matched)/max(1,len(ms))\n","            if cover>=min_cover:\n","                ms.update(matched); model.load_state_dict(ms, strict=False); ok=True\n","    except Exception as e:\n","        print(\"[warn] weight load:\", e)\n","    return ok, cover\n","\n","weights_loaded, coverage = try_load_capsule_weights(model, CAPSULE_WEIGHTS, min_cover=0.25)\n","model = model.to(device).eval()\n","print(\"Capsule model loaded\")\n","\n","# ---------- light TTA (horizontal flip) ----------\n","@torch.no_grad()\n","def forward_tta(xb):\n","    use_amp=(device.type==\"cuda\")\n","    with torch.amp.autocast('cuda', enabled=use_amp):\n","        pred1, prob1 = model(xb)\n","        pred2, prob2 = model(torch.flip(xb, dims=[3]))\n","    # average probs\n","    prob = (prob1 + prob2) / 2.0\n","    # logits proxy for orientation decisions\n","    logit = torch.stack([1.0-prob, prob], dim=1)\n","    return logit, prob\n","\n","# ---------- scoring ----------\n","class DSRGBCaps(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self,i):\n","        r=self.df.iloc[i]; return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","@torch.no_grad()\n","def score_frames(df):\n","    loader = DataLoader(DSRGBCaps(df), batch_size=BATCH, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n","    vnames, idxs, probs, labels = [], [], [], []\n","    for xb, yb, vb, ib in loader:\n","        xb = xb.to(device, non_blocking=(device.type==\"cuda\"))\n","        logit, prob = forward_tta(xb)\n","        vnames += list(vb); idxs += list(ib)\n","        probs.append(prob.detach().cpu().numpy())\n","        labels.append(np.array(yb))\n","    out = pd.DataFrame({\n","        \"video_name\": pd.Series(vnames, dtype=object),\n","        \"idx\":        pd.Series(idxs, dtype=np.int64),\n","        \"true_label\": pd.Series(np.where(np.concatenate(labels)==1,\"fake\",\"real\"), dtype=object),\n","        \"prob_fake\":  pd.Series(np.concatenate(probs).astype(float), dtype=np.float64),\n","    })\n","    return out.sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n","\n","df_scores = score_frames(df_sel)\n","\n","# ---------- auto orientation (flip scores if helps per-video AUC) ----------\n","avg = df_scores.groupby([\"video_name\",\"true_label\"], as_index=False)[\"prob_fake\"].mean()\n","y_avg = (avg[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_avg = avg[\"prob_fake\"].to_numpy(dtype=float)\n","try:\n","    if roc_auc_score(y_avg, 1 - s_avg) > roc_auc_score(y_avg, s_avg):\n","        df_scores[\"prob_fake\"] = 1 - df_scores[\"prob_fake\"]\n","except Exception:\n","    pass\n","\n","# ---------- per-video aggregation & metrics ----------\n","def aggregate_numpy(df, how):\n","    rows=[]\n","    for (v,t), g in df.groupby([\"video_name\",\"true_label\"], sort=False):\n","        vals = g[\"prob_fake\"].to_numpy(dtype=float)\n","        n = vals.size\n","        if n==0: continue\n","        vs = np.sort(vals)\n","        if   how==\"median\":  score=float(np.median(vs))\n","        elif how==\"perc90\":  score=float(np.quantile(vs, 0.90, method=\"linear\")) if \"method\" in np.quantile.__code__.co_varnames else float(np.quantile(vs,0.90, interpolation=\"linear\"))\n","        elif how==\"top10\":   score=float(np.mean(vs[-min(10,n):]))\n","        elif how==\"trim10\":\n","            k=int(0.1*n); lo=k; hi=max(n-k,1); score=float(np.mean(vs[lo:hi]))\n","        else: score=float(np.median(vs))\n","        rows.append({\"video_name\":v, \"true_label\":t, \"score\":score})\n","    return pd.DataFrame(rows)\n","\n","def metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, _ = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","best=None; best_cfg=None\n","for agg in (\"median\",\"perc90\",\"top10\",\"trim10\"):\n","    dfv = aggregate_numpy(df_scores, agg)\n","    if dfv.empty: continue\n","    y = (dfv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","    s = dfv[\"score\"].to_numpy(dtype=float)\n","    if len(np.unique(y))<2: continue\n","    cand = metrics(s, y)\n","    if (best is None) or (cand[0] > best[0]) or (cand[0]==best[0] and cand[1] < best[1]):\n","        best = cand; best_cfg = agg\n","\n","auc, eer, ap = best\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] dataset='balanced_frames_FF++', device={device.type}, img={IMG_SIZE}, cap={FRAME_CAP}, agg={best_cfg}, \"\n","      f\"tta=flip, weights_loaded={weights_loaded}, cover={coverage:.2f}\")\n"]},{"cell_type":"code","source":["# === Capsule metrics patch (no re-scoring, no downloads) ===\n","# Fixes NumPy quantile API issue and computes best aggregation.\n","\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","if 'df_scores' not in globals() or df_scores.empty:\n","    raise SystemExit(\"No 'df_scores' found. Run the Capsule scoring cell first (the one that prints 'Capsule model loaded').\")\n","\n","def qnp(v, q):\n","    v = np.asarray(v, dtype=float)\n","    try:\n","        return float(np.quantile(v, q, method=\"linear\"))\n","    except TypeError:\n","        # older NumPy\n","        return float(np.quantile(v, q, interpolation=\"linear\"))\n","\n","def aggregate_numpy(df, how):\n","    rows=[]\n","    for (v,t), g in df.groupby([\"video_name\",\"true_label\"], sort=False):\n","        vals = g[\"prob_fake\"].to_numpy(dtype=float)\n","        n = vals.size\n","        if n == 0:\n","            continue\n","        vs = np.sort(vals)\n","        if   how == \"median\": score = float(np.median(vs))\n","        elif how == \"perc90\": score = qnp(vs, 0.90)\n","        elif how == \"top10\":  score = float(np.mean(vs[-min(10, n):]))\n","        elif how == \"trim10\":\n","            k = int(0.1*n); lo = k; hi = max(n-k, 1)\n","            score = float(np.mean(vs[lo:hi]))\n","        else:                 score = float(np.median(vs))\n","        rows.append((v, t, score))\n","    return pd.DataFrame(rows, columns=[\"video_name\",\"true_label\",\"score\"])\n","\n","def metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, _ = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","best=None; best_agg=None\n","for agg in (\"median\",\"perc90\",\"top10\",\"trim10\"):\n","    dfv = aggregate_numpy(df_scores, agg)\n","    if dfv.empty: continue\n","    y = (dfv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","    if len(np.unique(y)) < 2: continue\n","    s = dfv[\"score\"].to_numpy(dtype=float)\n","    cand = metrics(s, y)\n","    if (best is None) or (cand[0] > best[0]) or (cand[0]==best[0] and cand[1] < best[1]):\n","        best, best_agg = cand, agg\n","\n","auc, eer, ap = best\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] agg={best_agg}, frames_scored={len(df_scores)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXy9nNDJTmKo","executionInfo":{"status":"ok","timestamp":1756579667418,"user_tz":-120,"elapsed":58,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"de8a2589-cce9-4644-8857-3750b3753c4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC=0.5000 | EER=0.5000 | AP=0.5000\n","[info] agg=median, frames_scored=2040\n"]}]},{"cell_type":"code","source":["# === FAST Capsule (spatial) on balanced_frames_FF++ ===\n","# Prints: \"Capsule model loaded (FAST)\" then AUC | EER | AP\n","# Speed tweaks: IMG_SIZE=224, CAP=40 frames/video, no multi-crop TTA, single pass, median aggregation.\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# ---------- paths ----------\n","import os, re, io, contextlib, warnings, numpy as np, pandas as pd, cv2\n","from PIL import Image\n","\n","ROOT = \"/content/drive/MyDrive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","REAL_DIR = f\"{ROOT}/balanced_frames_FF++/real\"\n","FAKE_DIR = f\"{ROOT}/balanced_frames_FF++/fake\"\n","CAPSULE_WEIGHTS = f\"{ROOT}/DeepfakeBench_weights/capsule_best.pth\"\n","\n","assert os.path.isdir(REAL_DIR) and os.path.isdir(FAKE_DIR), \"Check dataset folders exist.\"\n","assert os.path.isfile(CAPSULE_WEIGHTS), \"Missing capsule_best.pth.\"\n","\n","# ---------- deps ----------\n","def _pipq(*pkgs):\n","    import subprocess, sys as _sys\n","    subprocess.run([_sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs], check=True)\n","\n","try:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","except Exception:\n","    _pipq(\"torch\", \"torchvision\"); import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","# ---------- speed knobs ----------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = (device.type==\"cuda\")\n","IMG_SIZE    = 224\n","BATCH       = 32 if device.type==\"cuda\" else 8\n","NUM_WORKERS = 0   # Drive + multiprocessing often slows down\n","CAP         = 40  # frames per video (quick)\n","softmax = torch.nn.Softmax(dim=1)\n","\n","# ---------- list frames ----------\n","IMG_EXTS=(\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def list_imgs(d): return sorted([os.path.join(d,f) for f in os.listdir(d) if f.lower().endswith(IMG_EXTS)]) if os.path.isdir(d) else []\n","reals, fakes = list_imgs(REAL_DIR), list_imgs(FAKE_DIR)\n","assert len(reals) and len(fakes), f\"No images found. REAL={len(reals)} FAKE={len(fakes)}.\"\n","\n","def infer_video_name(p):\n","    stem=os.path.splitext(os.path.basename(p))[0]\n","    m=re.split(r\"_frame(\\d+)$\", stem)\n","    return m[0] if len(m)>1 and m[0] else re.sub(r\"[_\\\\-]\\\\d+$\",\"\",stem)\n","\n","def frame_index(p):\n","    m=re.search(r\"_frame(\\\\d+)\", os.path.basename(p))\n","    return int(m.group(1)) if m else 10**9\n","\n","def build_df(paths, label):\n","    rows=[{\"path\":p,\"video_name\":infer_video_name(p),\"idx\":frame_index(p),\"label\":label} for p in paths]\n","    return pd.DataFrame(rows).sort_values([\"video_name\",\"idx\"])\n","\n","df_sel = pd.concat([build_df(reals,0), build_df(fakes,1)], ignore_index=True)\n","# take first CAP frames per video\n","df_sel = df_sel.sort_values([\"video_name\",\"idx\"]).groupby(\"video_name\", as_index=False).head(CAP).reset_index(drop=True)\n","\n","# ---------- preprocessing ----------\n","IMN_MEAN = np.array([0.485,0.456,0.406], np.float32)\n","IMN_STD  = np.array([0.229,0.224,0.225], np.float32)\n","\n","def prep_rgb(path, out=IMG_SIZE):\n","    im = cv2.imread(path, cv2.IMREAD_COLOR)\n","    if im is None:\n","        im = cv2.cvtColor(np.array(Image.open(path).convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im, (out,out), interpolation=cv2.INTER_CUBIC).astype(np.float32)/255.0\n","    x = im.transpose(2,0,1)\n","    x = (x - IMN_MEAN[:,None,None]) / IMN_STD[:,None,None]\n","    return torch.from_numpy(x.astype(np.float32))\n","\n","class DSRGB(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, i):\n","        r=self.df.iloc[i]\n","        return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","# ---------- Capsule model (compact) ----------\n","class VggExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n","                try:\n","                    vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_FEATURES)\n","                except Exception:\n","                    vgg = models.vgg19(pretrained=True)\n","        self.vgg_1 = nn.Sequential(*list(vgg.features.children())[:19])\n","        self.vgg_1.eval()\n","    def forward(self, x):\n","        with torch.no_grad():\n","            return self.vgg_1(x)\n","\n","class StatsNet(nn.Module):\n","    def forward(self, x):\n","        B,C,H,W=x.shape\n","        x = x.view(B,C,H*W)\n","        mean = torch.mean(x, dim=2)\n","        std  = torch.std(x, dim=2)\n","        return torch.stack((mean, std), dim=1)  # [B,2,C]\n","\n","class View(nn.Module):\n","    def __init__(self, *shape): super().__init__(); self.shape = shape\n","    def forward(self, inp): return inp.view(self.shape)\n","\n","class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.NO_CAPS = 10\n","        self.capsules = nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(256, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","                nn.Conv2d(64, 16, 3, 1, 1),  nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n","                StatsNet(),                                 # [B,2,16]\n","                nn.Conv1d(2, 8, 5, 2, 2),  nn.BatchNorm1d(8),  # -> length 8\n","                nn.Conv1d(8, 1, 3, 1, 1), nn.BatchNorm1d(1),\n","                View(-1, 8),                                 # [B,8]\n","            ) for _ in range(self.NO_CAPS)\n","        ])\n","    def squash(self, t, dim):\n","        sn = (t**2).sum(dim=dim, keepdim=True)\n","        return (sn/(1.0+sn+1e-8)) * t / torch.sqrt(sn+1e-8)\n","    def forward(self, x):\n","        outs = [cap(x) for cap in self.capsules]   # list of [B,8]\n","        out  = torch.stack(outs, dim=-1)           # [B,8,10]\n","        return self.squash(out, dim=-1)\n","\n","class RoutingLayer(nn.Module):\n","    def __init__(self, n_in, n_out, d_in, d_out, iters=2):\n","        super().__init__()\n","        self.iters = iters\n","        self.route_weights = nn.Parameter(torch.randn(n_out, n_in, d_out, d_in)*0.1)\n","    def squash(self, t, dim):\n","        sn = (t**2).sum(dim=dim, keepdim=True)\n","        return (sn/(1.0+sn+1e-8)) * t / torch.sqrt(sn+1e-8)\n","    def forward(self, x):\n","        # x: [B, d_in, n_in]\n","        x = x.transpose(2,1)  # [B, n_in, d_in]\n","        priors = self.route_weights[:, None, :, :, :] @ x[None, :, :, :, None]  # [n_out,B,n_in,d_out,1]\n","        priors = priors.transpose(1,0)  # [B,n_out,n_in,d_out,1]\n","        logits = torch.zeros_like(priors)\n","        for i in range(self.iters):\n","            probs = torch.softmax(logits, dim=2)\n","            outputs = self.squash((probs*priors).sum(dim=2, keepdim=True), dim=3)  # [B,n_out,1,d_out,1]\n","            if i != self.iters-1:\n","                logits = logits + priors * outputs\n","        outputs = outputs.squeeze()            # [B,n_out,d_out]\n","        if outputs.ndim == 2: outputs = outputs.unsqueeze(0)\n","        return outputs.transpose(2,1).contiguous()  # [B,d_out,n_out]\n","\n","class CapsuleNet(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        self.vgg = VggExtractor()\n","        self.fea = FeatureExtractor()\n","        self.route = RoutingLayer(n_in=10, n_out=num_classes, d_in=8, d_out=4, iters=2)\n","        self.apply(self._init)\n","    def _init(self, m):\n","        if isinstance(m, (nn.Conv2d, nn.Conv1d)):\n","            nn.init.normal_(m.weight, 0.0, 0.02)\n","        if isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n","            nn.init.normal_(m.weight, 1.0, 0.02); nn.init.constant_(m.bias, 0.0)\n","    def forward(self, x):\n","        feat = self.vgg(x)            # [B,256,H',W']\n","        caps = self.fea(feat)         # [B,8,10]\n","        z = self.route(caps)          # [B,4,2]\n","        classes = torch.softmax(z, dim=-1)\n","        pred = classes.detach().mean(dim=1)   # [B,2]\n","        prob = torch.softmax(pred, dim=1)[:,1]\n","        return pred, prob\n","\n","# build & load weights quietly\n","model = CapsuleNet(num_classes=2)\n","def try_load_capsule_weights(model, ckpt, min_cover=0.25):\n","    ok=False; cover=0.0\n","    try:\n","        sd=torch.load(ckpt, map_location=\"cpu\")\n","        if isinstance(sd,dict):\n","            for k in (\"state_dict\",\"model\",\"net\",\"weights\",\"model_state\",\"ema_state_dict\"):\n","                if k in sd and isinstance(sd[k],dict): sd=sd[k]; break\n","        clean={}\n","        if isinstance(sd,dict):\n","            for k,v in sd.items():\n","                if not isinstance(k,str): continue\n","                k2=k\n","                for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\",\"vgg_ext.\",\"fea_ext.\",\"routing.\",\"routing_stats.\"):\n","                    if k2.startswith(pref): k2=k2[len(pref):]\n","                clean[k2]=v\n","            ms=model.state_dict()\n","            matched={k:v for k,v in clean.items() if k in ms and ms[k].shape==v.shape}\n","            cover=len(matched)/max(1,len(ms))\n","            if cover>=min_cover:\n","                ms.update(matched); model.load_state_dict(ms, strict=False); ok=True\n","    except Exception as e:\n","        print(\"[warn] weight load:\", e)\n","    return ok, cover\n","\n","weights_loaded, coverage = try_load_capsule_weights(model, CAPSULE_WEIGHTS, 0.25)\n","model = model.to(device).eval()\n","print(\"Capsule model loaded (FAST)\")\n","\n","# ---------- scoring (single pass, no TTA) ----------\n","class DSRGBCaps(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self,i):\n","        r=self.df.iloc[i]; return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","@torch.no_grad()\n","def score_frames(df):\n","    loader = DataLoader(DSRGBCaps(df), batch_size=BATCH, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n","    vnames, idxs, probs, labels = [], [], [], []\n","    for xb, yb, vb, ib in loader:\n","        xb = xb.to(device, non_blocking=(device.type==\"cuda\"))\n","        _, prob = model(xb)\n","        vnames += list(vb); idxs += list(ib)\n","        probs.append(prob.detach().cpu().numpy()); labels.append(np.array(yb))\n","    out = pd.DataFrame({\n","        \"video_name\": vnames,\n","        \"idx\": idxs,\n","        \"true_label\": np.where(np.concatenate(labels)==1,\"fake\",\"real\"),\n","        \"prob_fake\": np.concatenate(probs).astype(float),\n","    })\n","    return out.sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n","\n","df_scores = score_frames(df_sel)\n","\n","# ---------- per-video median aggregation & metrics ----------\n","def aggregate(df):\n","    rows=[]\n","    for (v,t), g in df.groupby([\"video_name\",\"true_label\"], sort=False):\n","        vals = g[\"prob_fake\"].to_numpy(dtype=float)\n","        rows.append((v, t, float(np.median(vals))))\n","    return pd.DataFrame(rows, columns=[\"video_name\",\"true_label\",\"score\"])\n","\n","def metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, _ = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","dfv = aggregate(df_scores)\n","y = (dfv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s = dfv[\"score\"].to_numpy(dtype=float)\n","auc, eer, ap = metrics(s, y)\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] FAST mode — device={device.type}, img={IMG_SIZE}, cap={CAP}, batch={BATCH}, workers={NUM_WORKERS}, weights_loaded={weights_loaded}, cover={coverage:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FMG9tQwPYQR1","executionInfo":{"status":"error","timestamp":1756580933203,"user_tz":-120,"elapsed":55343,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"836898ab-1439-477c-dccf-8d8f5aea67af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Capsule model loaded (FAST)\n"]},{"output_type":"error","ename":"ValueError","evalue":"Categorical categories must be unique","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3266929018.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;31m# ---------- per-video median aggregation & metrics ----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3266929018.py\u001b[0m in \u001b[0;36mscore_frames\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;34m\"prob_fake\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     })\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"video_name\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7181\u001b[0m                 ]\n\u001b[1;32m   7182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7183\u001b[0;31m             indexer = lexsort_indexer(\n\u001b[0m\u001b[1;32m   7184\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mlexsort_indexer\u001b[0;34m(keys, orders, na_position, key, codes_given)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;31m# we're inferring from values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, categories, ordered)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOrdered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36m_finalize\u001b[0;34m(self, categories, ordered, fastpath)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mvalidate_categories\u001b[0;34m(categories, fastpath)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Categorical categories must be unique\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategoricalIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Categorical categories must be unique"]}]},{"cell_type":"code","source":["# === FAST Capsule — patched scoring + metrics (no downloads) ===\n","# Reuses: model, df_sel, device, BATCH, NUM_WORKERS from your FAST cell.\n","\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# --- safety checks ---\n","if 'model' not in globals():\n","    raise SystemExit(\"Model not found. Run the FAST Capsule cell up to model creation first.\")\n","if 'df_sel' not in globals() or df_sel.empty:\n","    raise SystemExit(\"df_sel missing. Run the FAST Capsule cell that builds df_sel first.\")\n","\n","# --- dataset wrapper (reuse prep_rgb from your FAST cell) ---\n","class _DSCaps(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self,i):\n","        r=self.df.iloc[i]\n","        return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","@torch.no_grad()\n","def score_frames_fixed(df):\n","    loader = DataLoader(_DSCaps(df), batch_size=BATCH, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n","    vnames, idxs, probs, labels = [], [], [], []\n","    for xb, yb, vb, ib in loader:\n","        xb = xb.to(device, non_blocking=(device.type==\"cuda\"))\n","        _, prob = model(xb)\n","        vnames.extend([str(x) for x in vb])\n","        idxs.extend([int(x) for x in ib])\n","        probs.append(prob.detach().cpu().numpy())\n","        labels.append(yb.numpy())\n","\n","    labels_arr = np.concatenate(labels)\n","    probs_arr  = np.concatenate(probs).astype(float)\n","    true_lab   = np.where(labels_arr==1, \"fake\", \"real\").tolist()\n","\n","    out = pd.DataFrame({\n","        \"video_name\": vnames,\n","        \"idx\": idxs,\n","        \"true_label\": true_lab,\n","        \"prob_fake\": probs_arr,\n","    })\n","    # force plain dtypes (avoid Categoricals)\n","    out[\"video_name\"] = out[\"video_name\"].astype(str)\n","    out[\"idx\"] = out[\"idx\"].astype(np.int64)\n","    out[\"true_label\"] = out[\"true_label\"].astype(str)\n","    out[\"prob_fake\"] = out[\"prob_fake\"].astype(float)\n","    return out.sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n","\n","df_scores = score_frames_fixed(df_sel)\n","\n","# --- per-video median aggregation & metrics ---\n","def aggregate_median(df):\n","    rows=[]\n","    for (v,t), g in df.groupby([\"video_name\",\"true_label\"], sort=False):\n","        rows.append((v, t, float(np.median(g[\"prob_fake\"].to_numpy(dtype=float)))))\n","    return pd.DataFrame(rows, columns=[\"video_name\",\"true_label\",\"score\"])\n","\n","def metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, _ = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","dfv = aggregate_median(df_scores)\n","y = (dfv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s = dfv[\"score\"].to_numpy(dtype=float)\n","auc, eer, ap = metrics(s, y)\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] FAST patched — device={device.type}, frames_scored={len(df_scores)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw7hhLiVY1hu","executionInfo":{"status":"ok","timestamp":1756581069887,"user_tz":-120,"elapsed":39676,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"096312d4-0588-4b0a-fd57-cd0a7abb052c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AUC=0.5000 | EER=0.5000 | AP=0.5000\n","[info] FAST patched — device=cuda, frames_scored=2040\n"]}]},{"cell_type":"code","source":["# --- Capsule quick diagnostics on existing results ---\n","import numpy as np, pandas as pd\n","\n","if 'df_scores' not in globals() or df_scores.empty:\n","    raise SystemExit(\"No df_scores in memory — run the scoring cell first.\")\n","\n","print(\"weights_loaded present?\", 'weights_loaded' in globals())\n","if 'weights_loaded' in globals(): print(\"weights_loaded =\", weights_loaded)\n","\n","ps = pd.to_numeric(df_scores['prob_fake'], errors='coerce')\n","print(\"\\n[prob_fake stats]\\n\", ps.describe())\n","\n","near_mid = np.mean(np.abs(ps - 0.5) < 1e-2)\n","print(f\"share within 0.01 of 0.5: {near_mid:.3f}\")\n","\n","print(\"\\n[label counts]\\n\", df_scores['true_label'].value_counts())\n","print(\"\\n[per-video mean probs (first 10)]\\n\",\n","      df_scores.groupby('video_name')['prob_fake'].mean().head(10))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCrZW03_Zeiw","executionInfo":{"status":"ok","timestamp":1756581198017,"user_tz":-120,"elapsed":58,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"4ae93595-22f9-4dc4-e37d-3e0bc9814470"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["weights_loaded present? True\n","weights_loaded = False\n","\n","[prob_fake stats]\n"," count    2040.000000\n","mean        0.500001\n","std         0.000000\n","min         0.500001\n","25%         0.500001\n","50%         0.500001\n","75%         0.500001\n","max         0.500001\n","Name: prob_fake, dtype: float64\n","share within 0.01 of 0.5: 1.000\n","\n","[label counts]\n"," true_label\n","fake    1020\n","real    1020\n","Name: count, dtype: int64\n","\n","[per-video mean probs (first 10)]\n"," video_name\n","000_003    0.500001\n","010_005    0.500001\n","011_805    0.500001\n","012_026    0.500001\n","013_883    0.500001\n","014_790    0.500001\n","015_919    0.500001\n","016_209    0.500001\n","017_803    0.500001\n","018_019    0.500001\n","Name: prob_fake, dtype: float64\n"]}]},{"cell_type":"code","source":["# === FAST+STRONG Capsule re-score (flip TTA, 256px, 60 frames/video) ===\n","# Reuses your existing 'model'. No VGG downloads. Prints AUC | EER | AP.\n","\n","import numpy as np, pandas as pd, torch\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","import cv2\n","from PIL import Image\n","\n","# ---- safety: need model and df_sel or the real/fake dirs you used earlier\n","if 'model' not in globals():\n","    raise SystemExit(\"Capsule 'model' not found. Run your Capsule model cell first (up to model creation).\")\n","if 'df_sel' not in globals() or df_sel.empty:\n","    raise SystemExit(\"df_sel missing. Run the cell that builds df_sel from your dataset first.\")\n","\n","device = next(model.parameters()).device\n","IMG_SIZE = 256\n","CAP = 60\n","BATCH = 24 if device.type == \"cuda\" else 8\n","NUM_WORKERS = 0  # safer with Drive\n","\n","IMN_MEAN = np.array([0.485,0.456,0.406], np.float32)\n","IMN_STD  = np.array([0.229,0.224,0.225], np.float32)\n","\n","def _prep_rgb(path, out=IMG_SIZE):\n","    im = cv2.imread(path, cv2.IMREAD_COLOR)\n","    if im is None:\n","        im = cv2.cvtColor(np.array(Image.open(path).convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im, (out,out), interpolation=cv2.INTER_CUBIC).astype(np.float32)/255.0\n","    x = im.transpose(2,0,1)\n","    x = (x - IMN_MEAN[:,None,None]) / IMN_STD[:,None,None]\n","    return torch.from_numpy(x.astype(np.float32))\n","\n","# cap to 60 frames/video\n","df_cap = (df_sel.sort_values([\"video_name\",\"idx\"])\n","                .groupby(\"video_name\", as_index=False)\n","                .head(CAP).reset_index(drop=True))\n","\n","class _DS(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self,i):\n","        r=self.df.iloc[i]\n","        return _prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","@torch.no_grad()\n","def _forward_flip_tta(xb):\n","    # one forward + horizontal flip\n","    _, p1 = model(xb)\n","    _, p2 = model(torch.flip(xb, dims=[3]))\n","    return ((p1 + p2) / 2.0).detach().cpu().numpy()\n","\n","@torch.no_grad()\n","def rescore(df):\n","    loader = DataLoader(_DS(df), batch_size=BATCH, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n","    vnames, idxs, probs, labels = [], [], [], []\n","    for xb, yb, vb, ib in loader:\n","        xb = xb.to(device, non_blocking=(device.type==\"cuda\"))\n","        p = _forward_flip_tta(xb)\n","        vnames += list(vb); idxs += list(ib)\n","        probs.append(p); labels.append(yb.numpy())\n","    return pd.DataFrame({\n","        \"video_name\": vnames,\n","        \"idx\": idxs,\n","        \"true_label\": np.where(np.concatenate(labels)==1,\"fake\",\"real\"),\n","        \"prob_fake\": np.concatenate(probs).astype(float),\n","    }).sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n","\n","df_scores = rescore(df_cap)\n","\n","# auto orientation flip (if it helps per-video means)\n","avg = df_scores.groupby([\"video_name\",\"true_label\"], as_index=False)[\"prob_fake\"].mean()\n","y_avg = (avg[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_avg = avg[\"prob_fake\"].to_numpy(dtype=float)\n","try:\n","    if roc_auc_score(y_avg, 1.0 - s_avg) > roc_auc_score(y_avg, s_avg):\n","        df_scores[\"prob_fake\"] = 1.0 - df_scores[\"prob_fake\"]\n","except Exception:\n","    pass\n","\n","# median per-video + metrics\n","dv = df_scores.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"].median().rename(\"score\").reset_index()\n","y  = (dv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s  = dv[\"score\"].to_numpy(dtype=float)\n","\n","auc = roc_auc_score(y, s)\n","ap  = average_precision_score(y, s)\n","fpr, tpr, _ = roc_curve(y, s); fnr = 1 - tpr\n","i = int(np.nanargmin(np.abs(fnr - fpr)))\n","eer = float((fpr[i] + fnr[i]) / 2.0)\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] FAST+STRONG — device={device.type}, img={IMG_SIZE}, cap={CAP}, batch={BATCH}, frames_scored={len(df_scores)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"vPw7FmkLZkke","executionInfo":{"status":"error","timestamp":1756581281580,"user_tz":-120,"elapsed":58487,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"82faba1e-34a9-41d3-e9c7-159d9b418c50"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Categorical categories must be unique","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-245242460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     }).sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# auto orientation flip (if it helps per-video means)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-245242460.py\u001b[0m in \u001b[0;36mrescore\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;34m\"true_label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fake\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"real\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m\"prob_fake\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     }).sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mdf_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrescore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7181\u001b[0m                 ]\n\u001b[1;32m   7182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7183\u001b[0;31m             indexer = lexsort_indexer(\n\u001b[0m\u001b[1;32m   7184\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_position\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/sorting.py\u001b[0m in \u001b[0;36mlexsort_indexer\u001b[0;34m(keys, orders, na_position, key, codes_given)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 \u001b[0;31m# we're inferring from values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, categories, ordered)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOrdered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36m_finalize\u001b[0;34m(self, categories, ordered, fastpath)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/dtypes.py\u001b[0m in \u001b[0;36mvalidate_categories\u001b[0;34m(categories, fastpath)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Categorical categories must be unique\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCCategoricalIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Categorical categories must be unique"]}]},{"cell_type":"code","source":["# === Capsule (spatial) on balanced_frames_FF++ — prints ONLY: \"Capsule model loaded\" + AUC | EER | AP ===\n","# VGG19 feature extractor + Capsule head (DeepfakeBench-style), partial-safe weight load,\n","# flip-TTA, median/perc90/top10/trim10 aggregator sweep. Silences VGG download logs.\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","# ---------- paths ----------\n","import os, re, io, contextlib, warnings, numpy as np, pandas as pd, cv2\n","from PIL import Image\n","\n","ROOT = \"/content/drive/MyDrive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","REAL_DIR = f\"{ROOT}/balanced_frames_FF++/real\"\n","FAKE_DIR = f\"{ROOT}/balanced_frames_FF++/fake\"\n","CAPSULE_WEIGHTS = f\"{ROOT}/DeepfakeBench_weights/capsule_best.pth\"\n","\n","assert os.path.isdir(REAL_DIR) and os.path.isdir(FAKE_DIR), \"Check dataset folders.\"\n","assert os.path.isfile(CAPSULE_WEIGHTS), \"Missing capsule_best.pth.\"\n","\n","# ---------- deps ----------\n","def _pipq(*pkgs):\n","    import subprocess, sys as _sys\n","    subprocess.run([_sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs], check=True)\n","\n","try:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","except Exception:\n","    _pipq(\"torch\", \"torchvision\"); import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","\n","from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","# ---------- hardware / knobs ----------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = (device.type==\"cuda\")\n","IMG_SIZE    = 256\n","BATCH       = 24 if device.type==\"cuda\" else 8\n","NUM_WORKERS = 0    # Drive I/O -> keep 0 to avoid mp overhead\n","FRAME_CAP   = 60   # frames per video (tweak 40–120 depending on time)\n","softmax = torch.nn.Softmax(dim=1)\n","\n","# ---------- list frames ----------\n","IMG_EXTS=(\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def list_imgs(d): return sorted([os.path.join(d,f) for f in os.listdir(d) if f.lower().endswith(IMG_EXTS)]) if os.path.isdir(d) else []\n","reals, fakes = list_imgs(REAL_DIR), list_imgs(FAKE_DIR)\n","assert len(reals) and len(fakes), f\"No images found. REAL={len(reals)} FAKE={len(fakes)}.\"\n","\n","def infer_video_name(p):\n","    stem=os.path.splitext(os.path.basename(p))[0]\n","    m=re.split(r\"_frame(\\d+)$\", stem)\n","    return m[0] if len(m)>1 and m[0] else re.sub(r\"[_\\-]\\d+$\",\"\",stem)\n","\n","def frame_index(p):\n","    m=re.search(r\"_frame(\\d+)\", os.path.basename(p))\n","    return int(m.group(1)) if m else 10**9\n","\n","def build_df(paths, label):\n","    rows=[{\"path\":p,\"video_name\":infer_video_name(p),\"idx\":frame_index(p),\"label\":label} for p in paths]\n","    return pd.DataFrame(rows).sort_values([\"video_name\",\"idx\"])\n","\n","df_sel = pd.concat([build_df(reals,0), build_df(fakes,1)], ignore_index=True)\n","df_sel = df_sel.sort_values([\"video_name\",\"idx\"]).groupby(\"video_name\", as_index=False).head(FRAME_CAP).reset_index(drop=True)\n","\n","# ---------- preprocessing ----------\n","IMN_MEAN = np.array([0.485,0.456,0.406], np.float32)\n","IMN_STD  = np.array([0.229,0.224,0.225], np.float32)\n","\n","def prep_rgb(path, out=IMG_SIZE):\n","    im = cv2.imread(path, cv2.IMREAD_COLOR)\n","    if im is None:\n","        im = cv2.cvtColor(np.array(Image.open(path).convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im, (out,out), interpolation=cv2.INTER_CUBIC).astype(np.float32)/255.0\n","    x = im.transpose(2,0,1)\n","    x = (x - IMN_MEAN[:,None,None]) / IMN_STD[:,None,None]\n","    return torch.from_numpy(x.astype(np.float32))\n","\n","class DSRGB(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, i):\n","        r=self.df.iloc[i]\n","        return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","# ---------- Capsule model ----------\n","class VggExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n","                try:\n","                    vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_FEATURES)\n","                except Exception:\n","                    vgg = models.vgg19(pretrained=True)\n","        self.vgg_1 = nn.Sequential(*list(vgg.features.children())[:19])  # layers 0..18\n","        self.vgg_1.eval()\n","    def forward(self, x):\n","        with torch.no_grad():\n","            return self.vgg_1(x)\n","\n","class StatsNet(nn.Module):\n","    def forward(self, x):\n","        B,C,H,W=x.shape\n","        x=x.view(B,C,H*W)\n","        mean=torch.mean(x, dim=2)\n","        std =torch.std(x, dim=2)\n","        return torch.stack((mean, std), dim=1)  # [B,2,C]\n","\n","class View(nn.Module):\n","    def __init__(self, *shape): super().__init__(); self.shape=shape\n","    def forward(self, inp): return inp.view(self.shape)\n","\n","class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.NO_CAPS=10\n","        self.capsules=nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(256,64,3,1,1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","                nn.Conv2d(64,16,3,1,1),  nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n","                StatsNet(),                              # [B,2,16]\n","                nn.Conv1d(2,8,5,2,2), nn.BatchNorm1d(8),  # -> length 8\n","                nn.Conv1d(8,1,3,1,1), nn.BatchNorm1d(1),\n","                View(-1,8),                               # [B,8]\n","            ) for _ in range(self.NO_CAPS)\n","        ])\n","    def squash(self, t, dim):\n","        sn=(t**2).sum(dim=dim, keepdim=True)\n","        return (sn/(1.0+sn+1e-8)) * t / torch.sqrt(sn+1e-8)\n","    def forward(self, x):\n","        outs=[cap(x) for cap in self.capsules]  # list of [B,8]\n","        out=torch.stack(outs, dim=-1)           # [B,8,10]\n","        return self.squash(out, dim=-1)\n","\n","class RoutingLayer(nn.Module):\n","    def __init__(self, n_in, n_out, d_in, d_out, iters=2):\n","        super().__init__()\n","        self.iters=iters\n","        self.route_weights=nn.Parameter(torch.randn(n_out, n_in, d_out, d_in)*0.1)\n","    def squash(self, t, dim):\n","        sn=(t**2).sum(dim=dim, keepdim=True)\n","        return (sn/(1.0+sn+1e-8)) * t / torch.sqrt(sn+1e-8)\n","    def forward(self, x):\n","        # x: [B, d_in, n_in]\n","        x=x.transpose(2,1)  # [B, n_in, d_in]\n","        priors=self.route_weights[:,None,:,:,:] @ x[None,:,:,:,None]  # [n_out,B,n_in,d_out,1]\n","        priors=priors.transpose(1,0)  # [B,n_out,n_in,d_out,1]\n","        logits=torch.zeros_like(priors)\n","        for i in range(self.iters):\n","            probs=torch.softmax(logits, dim=2)\n","            outputs=self.squash((probs*priors).sum(dim=2, keepdim=True), dim=3)  # [B,n_out,1,d_out,1]\n","            if i!=self.iters-1:\n","                logits=logits + priors*outputs\n","        outputs=outputs.squeeze()  # [B,n_out,d_out]\n","        if outputs.ndim==2: outputs=outputs.unsqueeze(0)\n","        return outputs.transpose(2,1).contiguous()  # [B,d_out,n_out]\n","\n","class CapsuleNet(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        self.vgg=VggExtractor()\n","        self.fea=FeatureExtractor()\n","        self.route=RoutingLayer(n_in=10, n_out=num_classes, d_in=8, d_out=4, iters=2)\n","        self.apply(self._init)\n","    def _init(self, m):\n","        if isinstance(m, (nn.Conv2d, nn.Conv1d)):\n","            nn.init.normal_(m.weight, 0.0, 0.02)\n","        if isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n","            nn.init.normal_(m.weight, 1.0, 0.02); nn.init.constant_(m.bias, 0.0)\n","    def forward(self, x):\n","        feat=self.vgg(x)        # [B,256,H',W']\n","        caps=self.fea(feat)     # [B,8,10]\n","        z=self.route(caps)      # [B,4,2]\n","        classes=torch.softmax(z, dim=-1)  # [B,4,2]\n","        pred = classes.detach().mean(dim=1)  # [B,2]\n","        prob = torch.softmax(pred, dim=1)[:,1]\n","        return pred, prob\n","\n","# ---------- build model + load weights ----------\n","model = CapsuleNet(num_classes=2)\n","\n","def try_load_capsule_weights(model, ckpt, min_cover=0.25):\n","    ok=False; cover=0.0\n","    try:\n","        sd=torch.load(ckpt, map_location=\"cpu\")\n","        if isinstance(sd,dict):\n","            for k in (\"state_dict\",\"model\",\"net\",\"weights\",\"model_state\",\"ema_state_dict\"):\n","                if k in sd and isinstance(sd[k],dict): sd=sd[k]; break\n","        clean={}\n","        if isinstance(sd,dict):\n","            for k,v in sd.items():\n","                if not isinstance(k,str): continue\n","                k2=k\n","                for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\",\"vgg_ext.\",\"fea_ext.\",\"routing.\",\"routing_stats.\"):\n","                    if k2.startswith(pref): k2=k2[len(pref):]\n","                clean[k2]=v\n","            ms=model.state_dict()\n","            matched={k:v for k,v in clean.items() if k in ms and ms[k].shape==v.shape}\n","            cover=len(matched)/max(1,len(ms))\n","            if cover>=min_cover:\n","                ms.update(matched); model.load_state_dict(ms, strict=False); ok=True\n","    except Exception as e:\n","        print(\"[warn] weight load:\", e)\n","    return ok, cover\n","\n","weights_loaded, coverage = try_load_capsule_weights(model, CAPSULE_WEIGHTS, 0.25)\n","model = model.to(device).eval()\n","print(\"Capsule model loaded\")\n","\n","# ---------- TTA: horizontal flip ----------\n","@torch.no_grad()\n","def forward_tta(xb):\n","    _, p1 = model(xb)\n","    _, p2 = model(torch.flip(xb, dims=[3]))\n","    return ((p1 + p2) / 2.0)\n","\n","# ---------- scoring ----------\n","class DSRGBCaps(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self,i):\n","        r=self.df.iloc[i]; return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","@torch.no_grad()\n","def score_frames(df):\n","    loader = DataLoader(DSRGBCaps(df), batch_size=BATCH, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n","    vnames, idxs, probs, labels = [], [], [], []\n","    for xb, yb, vb, ib in loader:\n","        xb = xb.to(device, non_blocking=(device.type==\"cuda\"))\n","        prob = forward_tta(xb)\n","        vnames.extend([str(x) for x in vb])\n","        idxs.extend([int(x) for x in ib])\n","        probs.append(prob.detach().cpu().numpy())\n","        labels.append(np.asarray(yb))\n","    labels_arr = np.concatenate(labels)\n","    probs_arr  = np.concatenate(probs).astype(float)\n","    out = pd.DataFrame({\n","        \"video_name\": pd.Series(vnames, dtype=object),\n","        \"idx\":        pd.Series(idxs, dtype=np.int64),\n","        \"true_label\": pd.Series(np.where(labels_arr==1,\"fake\",\"real\"), dtype=object),\n","        \"prob_fake\":  pd.Series(probs_arr, dtype=np.float64),\n","    })\n","    # FORCE plain dtypes (prevents categorical issues)\n","    for c,dt in [(\"video_name\",str),(\"true_label\",str)]:\n","        out[c] = out[c].astype(dt)\n","    out[\"prob_fake\"] = out[\"prob_fake\"].astype(float)\n","    return out.sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n","\n","df_scores = score_frames(df_sel)\n","\n","# ---------- orientation auto-flip (if per-video means prefer 1-p) ----------\n","avg = df_scores.groupby([\"video_name\",\"true_label\"], as_index=False)[\"prob_fake\"].mean()\n","y_avg = (avg[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_avg = avg[\"prob_fake\"].to_numpy(dtype=float)\n","try:\n","    if roc_auc_score(y_avg, 1 - s_avg) > roc_auc_score(y_avg, s_avg):\n","        df_scores[\"prob_fake\"] = 1 - df_scores[\"prob_fake\"]\n","except Exception:\n","    pass\n","\n","# ---------- aggregation & metrics ----------\n","def qnp(v, q):\n","    v = np.asarray(v, dtype=float)\n","    try:    return float(np.quantile(v, q, method=\"linear\"))\n","    except TypeError:\n","            return float(np.quantile(v, q, interpolation=\"linear\"))\n","\n","def aggregate_numpy(df, how):\n","    rows=[]\n","    for (v,t), g in df.groupby([\"video_name\",\"true_label\"], sort=False):\n","        vals = g[\"prob_fake\"].to_numpy(dtype=float)\n","        n = vals.size\n","        if n==0: continue\n","        vs = np.sort(vals)\n","        if   how==\"median\":  score=float(np.median(vs))\n","        elif how==\"perc90\":  score=qnp(vs, 0.90)\n","        elif how==\"top10\":   score=float(np.mean(vs[-min(10,n):]))\n","        elif how==\"trim10\":\n","            k=int(0.1*n); lo=k; hi=max(n-k,1); score=float(np.mean(vs[lo:hi]))\n","        else: score=float(np.median(vs))\n","        rows.append((v,t,score))\n","    return pd.DataFrame(rows, columns=[\"video_name\",\"true_label\",\"score\"])\n","\n","def metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, _ = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","best=None; best_agg=None\n","for agg in (\"median\",\"perc90\",\"top10\",\"trim10\"):\n","    dfv = aggregate_numpy(df_scores, agg)\n","    if dfv.empty: continue\n","    y = (dfv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","    if len(np.unique(y))<2: continue\n","    s = dfv[\"score\"].to_numpy(dtype=float)\n","    cand = metrics(s, y)\n","    if (best is None) or (cand[0] > best[0]) or (cand[0]==best[0] and cand[1] < best[1]):\n","        best, best_agg = cand, agg\n","\n","auc, eer, ap = best\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] dataset='balanced_frames_FF++', device={device.type}, img={IMG_SIZE}, cap={FRAME_CAP}, \"\n","      f\"agg={best_agg}, tta=flip, weights_loaded={weights_loaded}, cover={coverage:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PB721_6Qarrd","executionInfo":{"status":"ok","timestamp":1756581579052,"user_tz":-120,"elapsed":65134,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"f28d1268-3a64-4621-c156-edee8ec09d32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Capsule model loaded\n","AUC=0.5000 | EER=0.5000 | AP=0.5000\n","[info] dataset='balanced_frames_FF++', device=cuda, img=256, cap=60, agg=median, tta=flip, weights_loaded=False, cover=0.00\n"]}]},{"cell_type":"code","source":["# === Capsule (balanced_frames_FF++) — robust weight load + quick rescore ===\n","# Fixes 0.50 by remapping CKPT keys to our module names, then rescoring quickly.\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","import os, re, io, contextlib, warnings, numpy as np, pandas as pd, cv2\n","from PIL import Image\n","\n","# ---------- paths ----------\n","ROOT = \"/content/drive/MyDrive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","REAL_DIR = f\"{ROOT}/balanced_frames_FF++/real\"\n","FAKE_DIR = f\"{ROOT}/balanced_frames_FF++/fake\"\n","CAPSULE_WEIGHTS = f\"{ROOT}/DeepfakeBench_weights/capsule_best.pth\"\n","assert os.path.isdir(REAL_DIR) and os.path.isdir(FAKE_DIR), \"Check dataset folders.\"\n","assert os.path.isfile(CAPSULE_WEIGHTS), \"Missing capsule_best.pth.\"\n","\n","# ---------- deps ----------\n","def _pipq(*pkgs):\n","    import subprocess, sys as _sys\n","    subprocess.run([_sys.executable, \"-m\", \"pip\", \"install\", \"-q\", *pkgs], check=True)\n","\n","try:\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","    from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","except Exception:\n","    _pipq(\"torch\",\"torchvision\",\"scikit-learn\")\n","    import torch, torch.nn as nn, torch.nn.functional as F\n","    from torch.utils.data import Dataset, DataLoader\n","    from torchvision import models\n","    from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.backends.cudnn.benchmark = (device.type==\"cuda\")\n","\n","# ---------- data prep ----------\n","IMG_EXTS=(\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")\n","def list_imgs(d): return sorted([os.path.join(d,f) for f in os.listdir(d) if f.lower().endswith(IMG_EXTS)]) if os.path.isdir(d) else []\n","def infer_video_name(p):\n","    stem=os.path.splitext(os.path.basename(p))[0]\n","    m=re.split(r\"_frame(\\d+)$\", stem)\n","    return m[0] if len(m)>1 and m[0] else re.sub(r\"[_\\-]\\d+$\",\"\",stem)\n","def frame_index(p):\n","    m=re.search(r\"_frame(\\d+)\", os.path.basename(p))\n","    return int(m.group(1)) if m else 10**9\n","def build_df(paths, label):\n","    rows=[{\"path\":p,\"video_name\":infer_video_name(p),\"idx\":frame_index(p),\"label\":label} for p in paths]\n","    return pd.DataFrame(rows).sort_values([\"video_name\",\"idx\"])\n","\n","reals, fakes = list_imgs(REAL_DIR), list_imgs(FAKE_DIR)\n","assert len(reals) and len(fakes), f\"No images found. REAL={len(reals)} FAKE={len(fakes)}.\"\n","FRAME_CAP = 60   # quick but decent\n","df_sel = pd.concat([build_df(reals,0), build_df(fakes,1)], ignore_index=True)\n","df_sel = df_sel.sort_values([\"video_name\",\"idx\"]).groupby(\"video_name\", as_index=False).head(FRAME_CAP).reset_index(drop=True)\n","\n","# ---------- preprocessing ----------\n","IMG_SIZE = 256\n","IMN_MEAN = np.array([0.485,0.456,0.406], np.float32)\n","IMN_STD  = np.array([0.229,0.224,0.225], np.float32)\n","def prep_rgb(path, out=IMG_SIZE):\n","    im = cv2.imread(path, cv2.IMREAD_COLOR)\n","    if im is None:\n","        im = cv2.cvtColor(np.array(Image.open(path).convert(\"RGB\")), cv2.COLOR_RGB2BGR)\n","    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n","    im = cv2.resize(im, (out,out), interpolation=cv2.INTER_CUBIC).astype(np.float32)/255.0\n","    x = im.transpose(2,0,1)\n","    x = (x - IMN_MEAN[:,None,None]) / IMN_STD[:,None,None]\n","    return torch.from_numpy(x.astype(np.float32))\n","\n","class DSRGB(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self,i):\n","        r=self.df.iloc[i]\n","        return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","# ---------- Capsule model (same as before) ----------\n","class VggExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        with warnings.catch_warnings():\n","            warnings.simplefilter(\"ignore\")\n","            with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):\n","                try:\n","                    vgg = models.vgg19(weights=models.VGG19_Weights.IMAGENET1K_FEATURES)\n","                except Exception:\n","                    vgg = models.vgg19(pretrained=True)\n","        self.vgg_1 = nn.Sequential(*list(vgg.features.children())[:19])  # 0..18\n","        self.vgg_1.eval()\n","    def forward(self, x):\n","        with torch.no_grad():\n","            return self.vgg_1(x)\n","\n","class StatsNet(nn.Module):\n","    def forward(self, x):\n","        B,C,H,W=x.shape\n","        x=x.view(B,C,H*W)\n","        mean=torch.mean(x, dim=2)\n","        std =torch.std(x, dim=2)\n","        return torch.stack((mean, std), dim=1)  # [B,2,C]\n","\n","class View(nn.Module):\n","    def __init__(self, *shape): super().__init__(); self.shape=shape\n","    def forward(self, inp): return inp.view(self.shape)\n","\n","class FeatureExtractor(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.NO_CAPS=10\n","        self.capsules=nn.ModuleList([\n","            nn.Sequential(\n","                nn.Conv2d(256,64,3,1,1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n","                nn.Conv2d(64,16,3,1,1),  nn.BatchNorm2d(16), nn.ReLU(inplace=True),\n","                StatsNet(),                               # [B,2,16]\n","                nn.Conv1d(2,8,5,2,2), nn.BatchNorm1d(8),  # -> length 8\n","                nn.Conv1d(8,1,3,1,1), nn.BatchNorm1d(1),\n","                View(-1,8),                               # [B,8]\n","            ) for _ in range(self.NO_CAPS)\n","        ])\n","    def squash(self, t, dim):\n","        sn=(t**2).sum(dim=dim, keepdim=True)\n","        return (sn/(1.0+sn+1e-8)) * t / torch.sqrt(sn+1e-8)\n","    def forward(self, x):\n","        outs=[cap(x) for cap in self.capsules]  # list of [B,8]\n","        out=torch.stack(outs, dim=-1)           # [B,8,10]\n","        return self.squash(out, dim=-1)\n","\n","class RoutingLayer(nn.Module):\n","    def __init__(self, n_in, n_out, d_in, d_out, iters=2):\n","        super().__init__()\n","        self.iters=iters\n","        self.route_weights=nn.Parameter(torch.randn(n_out, n_in, d_out, d_in)*0.1)\n","    def squash(self, t, dim):\n","        sn=(t**2).sum(dim=dim, keepdim=True)\n","        return (sn/(1.0+sn+1e-8)) * t / torch.sqrt(sn+1e-8)\n","    def forward(self, x):\n","        x=x.transpose(2,1)  # [B, n_in, d_in]\n","        priors=self.route_weights[:,None,:,:,:] @ x[None,:,:,:,None]  # [n_out,B,n_in,d_out,1]\n","        priors=priors.transpose(1,0)  # [B,n_out,n_in,d_out,1]\n","        logits=torch.zeros_like(priors)\n","        for i in range(self.iters):\n","            probs=torch.softmax(logits, dim=2)\n","            outputs=self.squash((probs*priors).sum(dim=2, keepdim=True), dim=3)\n","            if i!=self.iters-1:\n","                logits=logits + priors*outputs\n","        outputs=outputs.squeeze()\n","        if outputs.ndim==2: outputs=outputs.unsqueeze(0)\n","        return outputs.transpose(2,1).contiguous()  # [B,d_out,n_out]\n","\n","class CapsuleNet(nn.Module):\n","    def __init__(self, num_classes=2):\n","        super().__init__()\n","        self.vgg=VggExtractor()\n","        self.fea=FeatureExtractor()\n","        self.route=RoutingLayer(n_in=10, n_out=num_classes, d_in=8, d_out=4, iters=2)\n","        self.apply(self._init)\n","    def _init(self, m):\n","        if isinstance(m,(nn.Conv2d,nn.Conv1d)):\n","            nn.init.normal_(m.weight, 0.0, 0.02)\n","        if isinstance(m,(nn.BatchNorm2d,nn.BatchNorm1d)):\n","            nn.init.normal_(m.weight, 1.0, 0.02); nn.init.constant_(m.bias, 0.0)\n","    def forward(self, x):\n","        feat=self.vgg(x)        # [B,256,H',W']\n","        caps=self.fea(feat)     # [B,8,10]\n","        z=self.route(caps)      # [B,4,2]\n","        classes=torch.softmax(z, dim=-1)    # [B,4,2]\n","        pred = classes.detach().mean(dim=1) # [B,2]\n","        prob = torch.softmax(pred, dim=1)[:,1]\n","        return pred, prob\n","\n","model = CapsuleNet(num_classes=2).to(device).eval()\n","\n","# ---------- robust checkpoint remap ----------\n","def load_capsule_ckpt_strict_remap(model, ckpt_path, min_cover=0.25):\n","    sd = torch.load(ckpt_path, map_location=\"cpu\")\n","    if isinstance(sd, dict):\n","        for k in (\"state_dict\",\"model\",\"net\",\"weights\",\"model_state\",\"ema_state_dict\"):\n","            if k in sd and isinstance(sd[k], dict):\n","                sd = sd[k]; break\n","\n","    remap = {}\n","    for k,v in list(sd.items()) if isinstance(sd, dict) else []:\n","        if not isinstance(k,str): continue\n","        k2 = k\n","\n","        # strip common wrappers\n","        for pref in (\"module.\",\"model.\",\"net.\",\"backbone.\"):\n","            if k2.startswith(pref): k2 = k2[len(pref):]\n","\n","        # map deepfakebench names -> our module names\n","        if k2.startswith(\"vgg_ext.\"):\n","            k2 = \"vgg.\" + k2[len(\"vgg_ext.\"):]\n","        elif k2.startswith(\"fea_ext.\"):\n","            k2 = \"fea.\" + k2[len(\"fea_ext.\"):]\n","        elif k2.startswith(\"routing_stats.\"):\n","            k2 = \"route.\" + k2[len(\"routing_stats.\"):]\n","        elif k2.startswith(\"routing.\"):\n","            k2 = \"route.\" + k2[len(\"routing.\"):]\n","        # also handle bare 'vgg_1.' (seen in some dumps)\n","        elif k2.startswith(\"vgg_1.\"):\n","            k2 = \"vgg.\" + k2\n","\n","        remap[k2] = v\n","\n","    ms = model.state_dict()\n","    matched = {k:v for k,v in remap.items() if k in ms and ms[k].shape == v.shape}\n","    cover = len(matched) / max(1,len(ms))\n","    ok = cover >= min_cover\n","    if ok:\n","        ms.update(matched)\n","        model.load_state_dict(ms, strict=False)\n","    return ok, cover, matched.keys(), set(remap.keys()) - set(matched.keys())\n","\n","weights_loaded, coverage, matched_keys, missed_keys = load_capsule_ckpt_strict_remap(model, CAPSULE_WEIGHTS, min_cover=0.25)\n","\n","print(\"Capsule model loaded\")\n","\n","# ---------- scoring (flip TTA) ----------\n","BATCH, NUM_WORKERS = (24 if device.type==\"cuda\" else 8), 0\n","\n","@torch.no_grad()\n","def forward_tta(xb):\n","    _, p1 = model(xb)\n","    _, p2 = model(torch.flip(xb, dims=[3]))\n","    return ((p1 + p2) / 2.0)\n","\n","class DSCaps(Dataset):\n","    def __init__(self, df): self.df=df.reset_index(drop=True)\n","    def __len__(self): return len(self.df)\n","    def __getitem__(self, i):\n","        r=self.df.iloc[i]\n","        return prep_rgb(r[\"path\"]), int(r[\"label\"]), str(r[\"video_name\"]), int(r[\"idx\"])\n","\n","@torch.no_grad()\n","def score_frames(df):\n","    loader = DataLoader(DSCaps(df), batch_size=BATCH, shuffle=False,\n","                        num_workers=NUM_WORKERS, pin_memory=(device.type==\"cuda\"))\n","    vnames, idxs, probs, labels = [], [], [], []\n","    for xb, yb, vb, ib in loader:\n","        xb = xb.to(device, non_blocking=(device.type==\"cuda\"))\n","        p = forward_tta(xb).detach().cpu().numpy()\n","        vnames.extend([str(x) for x in vb])\n","        idxs.extend([int(x) for x in ib])\n","        probs.append(p)\n","        labels.append(np.asarray(yb))\n","    out = pd.DataFrame({\n","        \"video_name\": pd.Series(vnames, dtype=object),\n","        \"idx\":        pd.Series(idxs, dtype=np.int64),\n","        \"true_label\": pd.Series(np.where(np.concatenate(labels)==1,\"fake\",\"real\"), dtype=object),\n","        \"prob_fake\":  pd.Series(np.concatenate(probs).astype(float), dtype=np.float64),\n","    })\n","    # force plain dtypes\n","    out[\"video_name\"] = out[\"video_name\"].astype(str)\n","    out[\"true_label\"] = out[\"true_label\"].astype(str)\n","    out[\"prob_fake\"]  = out[\"prob_fake\"].astype(float)\n","    return out.sort_values([\"video_name\",\"idx\"]).reset_index(drop=True)\n","\n","df_scores = score_frames(df_sel)\n","\n","# ---------- auto orientation flip if it helps ----------\n","avg = df_scores.groupby([\"video_name\",\"true_label\"], as_index=False)[\"prob_fake\"].mean()\n","y_avg = (avg[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_avg = avg[\"prob_fake\"].to_numpy(dtype=float)\n","try:\n","    if roc_auc_score(y_avg, 1.0 - s_avg) > roc_auc_score(y_avg, s_avg):\n","        df_scores[\"prob_fake\"] = 1.0 - df_scores[\"prob_fake\"]\n","except Exception:\n","    pass\n","\n","# ---------- aggregation + metrics ----------\n","def qnp(v, q):\n","    v = np.asarray(v, dtype=float)\n","    try:    return float(np.quantile(v, q, method=\"linear\"))\n","    except TypeError:\n","            return float(np.quantile(v, q, interpolation=\"linear\"))\n","\n","def aggregate_numpy(df, how):\n","    rows=[]\n","    for (v,t), g in df.groupby([\"video_name\",\"true_label\"], sort=False):\n","        vals = g[\"prob_fake\"].to_numpy(dtype=float)\n","        n = vals.size\n","        if n==0: continue\n","        vs = np.sort(vals)\n","        if   how==\"median\":  score=float(np.median(vs))\n","        elif how==\"perc90\":  score=qnp(vs, 0.90)\n","        elif how==\"top10\":   score=float(np.mean(vs[-min(10,n):]))\n","        elif how==\"trim10\":\n","            k=int(0.1*n); lo=k; hi=max(n-k,1); score=float(np.mean(vs[lo:hi]))\n","        else: score=float(np.median(vs))\n","        rows.append((v,t,score))\n","    return pd.DataFrame(rows, columns=[\"video_name\",\"true_label\",\"score\"])\n","\n","def metrics(scores, labels):\n","    auc = roc_auc_score(labels, scores)\n","    ap  = average_precision_score(labels, scores)\n","    fpr, tpr, _ = roc_curve(labels, scores); fnr = 1 - tpr\n","    i = int(np.nanargmin(np.abs(fnr - fpr)))\n","    eer = float((fpr[i] + fnr[i]) / 2.0)\n","    return auc, eer, ap\n","\n","best=None; best_agg=None\n","for agg in (\"median\",\"perc90\",\"top10\",\"trim10\"):\n","    dfv = aggregate_numpy(df_scores, agg)\n","    if dfv.empty: continue\n","    y = (dfv[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","    if len(np.unique(y))<2: continue\n","    s = dfv[\"score\"].to_numpy(dtype=float)\n","    cand = metrics(s, y)\n","    if (best is None) or (cand[0] > best[0]) or (cand[0]==best[0] and cand[1] < best[1]):\n","        best, best_agg = cand, agg\n","\n","auc, eer, ap = best\n","print(f\"AUC={auc:.4f} | EER={eer:.4f} | AP={ap:.4f}\")\n","print(f\"[info] dataset='balanced_frames_FF++', device={device.type}, img={IMG_SIZE}, cap={FRAME_CAP}, \"\n","      f\"agg={best_agg}, tta=flip, weights_loaded={weights_loaded}, cover={coverage:.2f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pqc1ksx1bnqS","executionInfo":{"status":"ok","timestamp":1756581823126,"user_tz":-120,"elapsed":63968,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"fc4a5041-7c2a-418a-822e-747cb27767fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Capsule model loaded\n","AUC=0.6505 | EER=0.3725 | AP=0.7691\n","[info] dataset='balanced_frames_FF++', device=cuda, img=256, cap=60, agg=perc90, tta=flip, weights_loaded=True, cover=1.00\n"]}]},{"cell_type":"code","source":["# === Capsule — Large results table (balanced_frames_FF++) ===\n","# Requires: df_scores from your last Capsule run (the one that printed AUC/EER/AP)\n","\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_curve\n","\n","# Safety checks\n","if 'df_scores' not in globals() or df_scores.empty:\n","    raise SystemExit(\"No 'df_scores' found. Run the Capsule scoring cell first.\")\n","\n","DATASET_NAME  = \"balanced_frames_FF++\"\n","DETECTOR_NAME = \"Capsule\"\n","\n","# Clean frame-level results\n","df = df_scores.copy()\n","df[\"video_name\"] = df[\"video_name\"].astype(str)\n","df[\"true_label\"] = df[\"true_label\"].astype(str)\n","df[\"prob_fake\"]  = pd.to_numeric(df[\"prob_fake\"], errors=\"coerce\").astype(float)\n","df = df.dropna(subset=[\"prob_fake\"]).reset_index(drop=True)\n","\n","# ----- 1) Global thresholds -----\n","# Frame-level threshold via Youden's J\n","y_frame = (df[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_frame = df[\"prob_fake\"].to_numpy(dtype=float)\n","if len(np.unique(y_frame)) >= 2:\n","    fpr, tpr, thr = roc_curve(y_frame, s_frame)\n","    t_frame = float(thr[np.nanargmax(tpr - fpr)])\n","else:\n","    t_frame = 0.5\n","\n","# Per-video average threshold via Youden's J\n","avg_df = df.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"].mean().rename(\"avg_prob_fake\").reset_index()\n","y_avg = (avg_df[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_avg = avg_df[\"avg_prob_fake\"].to_numpy(dtype=float)\n","if len(np.unique(y_avg)) >= 2:\n","    fpr2, tpr2, thr2 = roc_curve(y_avg, s_avg)\n","    t_avg = float(thr2[np.nanargmax(tpr2 - fpr2)])\n","else:\n","    t_avg = 0.5\n","\n","# ----- 2) Frame-level predictions & counts -----\n","df[\"frame_pred\"] = np.where(df[\"prob_fake\"] >= t_frame, \"fake\", \"real\")\n","# n_frames, n_correct_frames, n_wrong_frames, frame_accuracy\n","cnts = df.groupby([\"video_name\",\"true_label\"], sort=False).apply(\n","    lambda g: pd.Series({\n","        \"n_frames\": int(len(g)),\n","        \"n_correct_frames\": int((g[\"frame_pred\"]==g[\"true_label\"]).sum()),\n","        \"n_wrong_frames\":   int((g[\"frame_pred\"]!=g[\"true_label\"]).sum()),\n","        \"frame_accuracy\":   float((g[\"frame_pred\"]==g[\"true_label\"]).mean())\n","    })\n",").reset_index()\n","\n","# ----- 3) Per-video avg/std + decisions (avg & majority) -----\n","stats = df.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"].agg(\n","    avg_prob_fake=\"mean\", std_prob_fake=\"std\"\n",").reset_index()\n","\n","# Average rule\n","stats[\"video_pred_by_avg\"]     = (stats[\"avg_prob_fake\"] >= t_avg).astype(int)          # 1=fake, 0=real\n","stats[\"video_correct_by_avg\"]  = ((stats[\"video_pred_by_avg\"]==1) & (stats[\"true_label\"]==\"fake\") |\n","                                  (stats[\"video_pred_by_avg\"]==0) & (stats[\"true_label\"]==\"real\")).astype(int)\n","\n","# Majority rule from frame predictions\n","maj = df.groupby(\"video_name\", sort=False)[\"frame_pred\"].agg(\n","    lambda a: 1 if (a==\"fake\").sum() >= (a.size - (a==\"fake\").sum()) else 0\n",").rename(\"video_pred_by_majority\").reset_index()\n","\n","# Merge majority with ground truth and correctness\n","maj = maj.merge(df.groupby(\"video_name\", sort=False)[\"true_label\"].first().reset_index(), on=\"video_name\", how=\"left\")\n","maj[\"video_correct_by_majority\"] = ((maj[\"video_pred_by_majority\"]==1) & (maj[\"true_label\"]==\"fake\") |\n","                                    (maj[\"video_pred_by_majority\"]==0) & (maj[\"true_label\"]==\"real\")).astype(int)\n","\n","# ----- 4) Assemble final table -----\n","table_capsule_ffpp = (\n","    stats.merge(cnts, on=[\"video_name\",\"true_label\"], how=\"left\")\n","         .merge(maj[[\"video_name\",\"video_pred_by_majority\",\"video_correct_by_majority\"]],\n","                on=\"video_name\", how=\"left\")\n","         .assign(\n","             dataset=DATASET_NAME,\n","             detector=DETECTOR_NAME,\n","             # tidy numeric formatting\n","             avg_prob_fake=lambda d: d[\"avg_prob_fake\"].astype(float),\n","             std_prob_fake=lambda d: d[\"std_prob_fake\"].fillna(0.0).astype(float),\n","             n_frames=lambda d: d[\"n_frames\"].astype(int),\n","             n_correct_frames=lambda d: d[\"n_correct_frames\"].astype(int),\n","             n_wrong_frames=lambda d: d[\"n_wrong_frames\"].astype(int),\n","             frame_accuracy=lambda d: d[\"frame_accuracy\"].astype(float),\n","             video_pred_by_avg=lambda d: d[\"video_pred_by_avg\"].astype(int),\n","             video_correct_by_avg=lambda d: d[\"video_correct_by_avg\"].astype(int),\n","             video_pred_by_majority=lambda d: d[\"video_pred_by_majority\"].astype(int),\n","             video_correct_by_majority=lambda d: d[\"video_correct_by_majority\"].astype(int),\n","         )[[\n","             \"dataset\",\"detector\",\"video_name\",\"true_label\",\n","             \"n_frames\",\"n_correct_frames\",\"n_wrong_frames\",\"frame_accuracy\",\n","             \"avg_prob_fake\",\"std_prob_fake\",\n","             \"video_pred_by_avg\",\"video_correct_by_avg\",\n","             \"video_pred_by_majority\",\"video_correct_by_majority\"\n","         ]]\n","         .sort_values([\"true_label\",\"video_name\"], kind=\"stable\")\n","         .reset_index(drop=True)\n",")\n","\n","# ----- 5) Display all rows, no column breaks -----\n","pd.set_option(\"display.max_rows\", 100000)\n","pd.set_option(\"display.max_columns\", 1000)\n","pd.set_option(\"display.width\", 10000)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","\n","display(table_capsule_ffpp)\n","print(f\"[rows]={len(table_capsule_ffpp)} | thresholds: t_frame={t_frame:.3f}, t_avg={t_avg:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Yatqyi8Vdl2O","executionInfo":{"status":"ok","timestamp":1756582278141,"user_tz":-120,"elapsed":1124,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"8ea593f5-89bb-4ad1-faae-e53272f51dd5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-33641027.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n","  cnts = df.groupby([\"video_name\",\"true_label\"], sort=False).apply(\n"]},{"output_type":"display_data","data":{"text/plain":["                  dataset detector                             video_name true_label  n_frames  n_correct_frames  n_wrong_frames  frame_accuracy  avg_prob_fake  std_prob_fake  video_pred_by_avg  video_correct_by_avg  video_pred_by_majority  video_correct_by_majority\n","0    balanced_frames_FF++  Capsule                                000_003       fake        20                20               0            1.00       0.605013       0.002602                  1                     1                       1                          1\n","1    balanced_frames_FF++  Capsule                                010_005       fake        20                 0              20            0.00       0.500555       0.030406                  0                     0                       0                          0\n","2    balanced_frames_FF++  Capsule                                011_805       fake        20                 3              17            0.15       0.570437       0.031841                  0                     0                       0                          0\n","3    balanced_frames_FF++  Capsule                                012_026       fake        20                 0              20            0.00       0.491209       0.041621                  0                     0                       0                          0\n","4    balanced_frames_FF++  Capsule                                013_883       fake        20                19               1            0.95       0.607141       0.005542                  1                     1                       1                          1\n","5    balanced_frames_FF++  Capsule                                014_790       fake        20                13               7            0.65       0.594129       0.016836                  1                     1                       1                          1\n","6    balanced_frames_FF++  Capsule                                015_919       fake        20                20               0            1.00       0.606428       0.003373                  1                     1                       1                          1\n","7    balanced_frames_FF++  Capsule                                016_209       fake        20                 0              20            0.00       0.515260       0.025184                  0                     0                       0                          0\n","8    balanced_frames_FF++  Capsule                                017_803       fake        20                 4              16            0.20       0.510247       0.054078                  0                     0                       0                          0\n","9    balanced_frames_FF++  Capsule                                018_019       fake        20                 2              18            0.10       0.549537       0.039455                  0                     0                       0                          0\n","10   balanced_frames_FF++  Capsule                                019_018       fake        20                20               0            1.00       0.605912       0.002826                  1                     1                       1                          1\n","11   balanced_frames_FF++  Capsule                                020_344       fake        20                 8              12            0.40       0.586296       0.015548                  0                     0                       0                          0\n","12   balanced_frames_FF++  Capsule                                021_312       fake        20                20               0            1.00       0.609469       0.000775                  1                     1                       1                          1\n","13   balanced_frames_FF++  Capsule                                022_489       fake        20                19               1            0.95       0.597894       0.001960                  1                     1                       1                          1\n","14   balanced_frames_FF++  Capsule                                023_923       fake        20                 0              20            0.00       0.438824       0.033234                  0                     0                       0                          0\n","15   balanced_frames_FF++  Capsule                                024_073       fake        20                 0              20            0.00       0.425719       0.032743                  0                     0                       0                          0\n","16   balanced_frames_FF++  Capsule                                025_067       fake        20                15               5            0.75       0.598002       0.006743                  1                     1                       1                          1\n","17   balanced_frames_FF++  Capsule                                026_012       fake        20                16               4            0.80       0.600672       0.014544                  1                     1                       1                          1\n","18   balanced_frames_FF++  Capsule                                027_009       fake        20                 0              20            0.00       0.519891       0.029209                  0                     0                       0                          0\n","19   balanced_frames_FF++  Capsule                                028_068       fake        20                 0              20            0.00       0.481397       0.042163                  0                     0                       0                          0\n","20   balanced_frames_FF++  Capsule                                029_048       fake        20                 0              20            0.00       0.420327       0.021655                  0                     0                       0                          0\n","21   balanced_frames_FF++  Capsule                                030_193       fake        20                20               0            1.00       0.605804       0.002763                  1                     1                       1                          1\n","22   balanced_frames_FF++  Capsule                                031_163       fake        20                19               1            0.95       0.606558       0.003448                  1                     1                       1                          1\n","23   balanced_frames_FF++  Capsule                                032_944       fake        20                 0              20            0.00       0.497355       0.012459                  0                     0                       0                          0\n","24   balanced_frames_FF++  Capsule                                033_097       fake        20                16               4            0.80       0.583143       0.052994                  0                     0                       1                          1\n","25   balanced_frames_FF++  Capsule                                034_590       fake        20                19               1            0.95       0.604454       0.005882                  1                     1                       1                          1\n","26   balanced_frames_FF++  Capsule                                035_036       fake        20                17               3            0.85       0.599140       0.007971                  1                     1                       1                          1\n","27   balanced_frames_FF++  Capsule                                036_035       fake        20                 0              20            0.00       0.443994       0.029702                  0                     0                       0                          0\n","28   balanced_frames_FF++  Capsule                                037_072       fake        20                 0              20            0.00       0.486414       0.029251                  0                     0                       0                          0\n","29   balanced_frames_FF++  Capsule                                038_125       fake        20                 0              20            0.00       0.503542       0.039580                  0                     0                       0                          0\n","30   balanced_frames_FF++  Capsule                                039_058       fake        20                 8              12            0.40       0.592239       0.012831                  1                     1                       0                          0\n","31   balanced_frames_FF++  Capsule                                040_997       fake        20                20               0            1.00       0.608665       0.000552                  1                     1                       1                          1\n","32   balanced_frames_FF++  Capsule                                041_063       fake        20                 9              11            0.45       0.584924       0.019410                  0                     0                       0                          0\n","33   balanced_frames_FF++  Capsule                                042_084       fake        20                 1              19            0.05       0.502083       0.056336                  0                     0                       0                          0\n","34   balanced_frames_FF++  Capsule                                043_110       fake        20                20               0            1.00       0.608970       0.000927                  1                     1                       1                          1\n","35   balanced_frames_FF++  Capsule                                044_945       fake        20                 1              19            0.05       0.478208       0.045544                  0                     0                       0                          0\n","36   balanced_frames_FF++  Capsule                                045_889       fake        20                11               9            0.55       0.592704       0.011058                  1                     1                       1                          1\n","37   balanced_frames_FF++  Capsule                                046_904       fake        20                 0              20            0.00       0.489231       0.019240                  0                     0                       0                          0\n","38   balanced_frames_FF++  Capsule                                047_862       fake        20                15               5            0.75       0.596472       0.010766                  1                     1                       1                          1\n","39   balanced_frames_FF++  Capsule                                048_029       fake        20                 0              20            0.00       0.513313       0.026715                  0                     0                       0                          0\n","40   balanced_frames_FF++  Capsule                                049_946       fake        20                 4              16            0.20       0.575603       0.021378                  0                     0                       0                          0\n","41   balanced_frames_FF++  Capsule                                050_059       fake        20                 0              20            0.00       0.480856       0.027570                  0                     0                       0                          0\n","42   balanced_frames_FF++  Capsule                                051_332       fake        20                16               4            0.80       0.592942       0.017276                  1                     1                       1                          1\n","43   balanced_frames_FF++  Capsule                                052_108       fake        20                18               2            0.90       0.600997       0.005403                  1                     1                       1                          1\n","44   balanced_frames_FF++  Capsule                                053_095       fake        20                 0              20            0.00       0.502825       0.022627                  0                     0                       0                          0\n","45   balanced_frames_FF++  Capsule                                054_071       fake        20                20               0            1.00       0.607449       0.000397                  1                     1                       1                          1\n","46   balanced_frames_FF++  Capsule                                055_147       fake        20                19               1            0.95       0.603974       0.006120                  1                     1                       1                          1\n","47   balanced_frames_FF++  Capsule                                056_996       fake        20                20               0            1.00       0.606480       0.002156                  1                     1                       1                          1\n","48   balanced_frames_FF++  Capsule                                057_070       fake        20                 6              14            0.30       0.571658       0.028070                  0                     0                       0                          0\n","49   balanced_frames_FF++  Capsule                                058_039       fake        20                19               1            0.95       0.607670       0.005487                  1                     1                       1                          1\n","50   balanced_frames_FF++  Capsule                                059_050       fake        20                 0              20            0.00       0.509727       0.035841                  0                     0                       0                          0\n","51   balanced_frames_FF++  Capsule     04__walking_outside_cafe_disgusted       real        20                20               0            1.00       0.562468       0.014136                  0                     1                       0                          1\n","52   balanced_frames_FF++  Capsule                    05__exit_phone_room       real        20                20               0            1.00       0.580709       0.010539                  0                     1                       0                          1\n","53   balanced_frames_FF++  Capsule                      05__hugging_happy       real        20                20               0            1.00       0.486344       0.015996                  0                     1                       0                          1\n","54   balanced_frames_FF++  Capsule                        05__kitchen_pan       real        20                 5              15            0.25       0.580043       0.053692                  0                     1                       1                          0\n","55   balanced_frames_FF++  Capsule                      05__kitchen_still       real        20                 8              12            0.40       0.594336       0.009170                  1                     0                       1                          0\n","56   balanced_frames_FF++  Capsule       05__outside_talking_pan_laughing       real        20                20               0            1.00       0.574561       0.011707                  0                     1                       0                          1\n","57   balanced_frames_FF++  Capsule     05__outside_talking_still_laughing       real        20                20               0            1.00       0.574557       0.003099                  0                     1                       0                          1\n","58   balanced_frames_FF++  Capsule                05__podium_speech_happy       real        20                20               0            1.00       0.568871       0.011566                  0                     1                       0                          1\n","59   balanced_frames_FF++  Capsule               05__talking_against_wall       real        20                20               0            1.00       0.546996       0.004001                  0                     1                       0                          1\n","60   balanced_frames_FF++  Capsule               05__walk_down_hall_angry       real        20                20               0            1.00       0.588390       0.003108                  0                     1                       0                          1\n","61   balanced_frames_FF++  Capsule  05__walking_down_street_outside_angry       real        20                20               0            1.00       0.510302       0.022801                  0                     1                       0                          1\n","62   balanced_frames_FF++  Capsule     05__walking_outside_cafe_disgusted       real        20                20               0            1.00       0.530916       0.014783                  0                     1                       0                          1\n","63   balanced_frames_FF++  Capsule                    06__exit_phone_room       real        20                20               0            1.00       0.587951       0.007030                  0                     1                       0                          1\n","64   balanced_frames_FF++  Capsule                      06__hugging_happy       real        20                20               0            1.00       0.470809       0.012944                  0                     1                       0                          1\n","65   balanced_frames_FF++  Capsule                        06__kitchen_pan       real        20                18               2            0.90       0.547419       0.042714                  0                     1                       0                          1\n","66   balanced_frames_FF++  Capsule                      06__kitchen_still       real        20                20               0            1.00       0.543733       0.018871                  0                     1                       0                          1\n","67   balanced_frames_FF++  Capsule       06__outside_talking_pan_laughing       real        20                20               0            1.00       0.495384       0.036088                  0                     1                       0                          1\n","68   balanced_frames_FF++  Capsule     06__outside_talking_still_laughing       real        20                20               0            1.00       0.516060       0.022880                  0                     1                       0                          1\n","69   balanced_frames_FF++  Capsule                06__podium_speech_happy       real        20                20               0            1.00       0.572009       0.012877                  0                     1                       0                          1\n","70   balanced_frames_FF++  Capsule               06__talking_against_wall       real        20                20               0            1.00       0.552244       0.012355                  0                     1                       0                          1\n","71   balanced_frames_FF++  Capsule                06__talking_angry_couch       real        20                18               2            0.90       0.579901       0.015638                  0                     1                       0                          1\n","72   balanced_frames_FF++  Capsule               06__walk_down_hall_angry       real        20                20               0            1.00       0.587768       0.007728                  0                     1                       0                          1\n","73   balanced_frames_FF++  Capsule      06__walking_and_outside_surprised       real        20                20               0            1.00       0.542592       0.027051                  0                     1                       0                          1\n","74   balanced_frames_FF++  Capsule   06__walking_down_indoor_hall_disgust       real        20                20               0            1.00       0.522911       0.029614                  0                     1                       0                          1\n","75   balanced_frames_FF++  Capsule  06__walking_down_street_outside_angry       real        20                20               0            1.00       0.512704       0.029732                  0                     1                       0                          1\n","76   balanced_frames_FF++  Capsule     06__walking_outside_cafe_disgusted       real        20                20               0            1.00       0.483654       0.045258                  0                     1                       0                          1\n","77   balanced_frames_FF++  Capsule                    07__exit_phone_room       real        20                20               0            1.00       0.569330       0.017922                  0                     1                       0                          1\n","78   balanced_frames_FF++  Capsule                      07__hugging_happy       real        20                20               0            1.00       0.489804       0.018129                  0                     1                       0                          1\n","79   balanced_frames_FF++  Capsule                        07__kitchen_pan       real        20                 5              15            0.25       0.583590       0.041862                  0                     1                       1                          0\n","80   balanced_frames_FF++  Capsule                      07__kitchen_still       real        20                11               9            0.55       0.592218       0.010159                  0                     1                       0                          1\n","81   balanced_frames_FF++  Capsule       07__outside_talking_pan_laughing       real        20                20               0            1.00       0.555866       0.023705                  0                     1                       0                          1\n","82   balanced_frames_FF++  Capsule     07__outside_talking_still_laughing       real        20                20               0            1.00       0.565580       0.010305                  0                     1                       0                          1\n","83   balanced_frames_FF++  Capsule                07__podium_speech_happy       real        20                20               0            1.00       0.584048       0.013211                  0                     1                       0                          1\n","84   balanced_frames_FF++  Capsule                07__secret_conversation       real        20                20               0            1.00       0.531330       0.025215                  0                     1                       0                          1\n","85   balanced_frames_FF++  Capsule               07__talking_against_wall       real        20                18               2            0.90       0.586821       0.012685                  0                     1                       0                          1\n","86   balanced_frames_FF++  Capsule                07__talking_angry_couch       real        20                 5              15            0.25       0.597824       0.006461                  1                     0                       1                          0\n","87   balanced_frames_FF++  Capsule               07__walk_down_hall_angry       real        20                20               0            1.00       0.587614       0.006137                  0                     1                       0                          1\n","88   balanced_frames_FF++  Capsule  07__walking_down_street_outside_angry       real        20                20               0            1.00       0.528529       0.027899                  0                     1                       0                          1\n","89   balanced_frames_FF++  Capsule     07__walking_outside_cafe_disgusted       real        20                20               0            1.00       0.536387       0.010603                  0                     1                       0                          1\n","90   balanced_frames_FF++  Capsule                    08__exit_phone_room       real        20                14               6            0.70       0.585257       0.012268                  0                     1                       0                          1\n","91   balanced_frames_FF++  Capsule                        08__kitchen_pan       real        20                 7              13            0.35       0.570341       0.062514                  0                     1                       1                          0\n","92   balanced_frames_FF++  Capsule                      08__kitchen_still       real        20                10              10            0.50       0.589392       0.019594                  0                     1                       1                          0\n","93   balanced_frames_FF++  Capsule       08__outside_talking_pan_laughing       real        20                19               1            0.95       0.573961       0.015534                  0                     1                       0                          1\n","94   balanced_frames_FF++  Capsule     08__outside_talking_still_laughing       real        20                20               0            1.00       0.577623       0.008736                  0                     1                       0                          1\n","95   balanced_frames_FF++  Capsule                08__podium_speech_happy       real        20                20               0            1.00       0.539182       0.024233                  0                     1                       0                          1\n","96   balanced_frames_FF++  Capsule               08__talking_against_wall       real        20                20               0            1.00       0.470117       0.018052                  0                     1                       0                          1\n","97   balanced_frames_FF++  Capsule               08__walk_down_hall_angry       real        20                19               1            0.95       0.583057       0.009109                  0                     1                       0                          1\n","98   balanced_frames_FF++  Capsule  08__walking_down_street_outside_angry       real        20                20               0            1.00       0.507433       0.022968                  0                     1                       0                          1\n","99   balanced_frames_FF++  Capsule     08__walking_outside_cafe_disgusted       real        20                20               0            1.00       0.550768       0.010884                  0                     1                       0                          1\n","100  balanced_frames_FF++  Capsule                    09__exit_phone_room       real        20                20               0            1.00       0.576848       0.013440                  0                     1                       0                          1\n","101  balanced_frames_FF++  Capsule                        09__kitchen_pan       real        20                 3              17            0.15       0.585147       0.047001                  0                     1                       1                          0"],"text/html":["\n","  <div id=\"df-859f0b67-0826-44bd-a0b1-f609d587a18f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dataset</th>\n","      <th>detector</th>\n","      <th>video_name</th>\n","      <th>true_label</th>\n","      <th>n_frames</th>\n","      <th>n_correct_frames</th>\n","      <th>n_wrong_frames</th>\n","      <th>frame_accuracy</th>\n","      <th>avg_prob_fake</th>\n","      <th>std_prob_fake</th>\n","      <th>video_pred_by_avg</th>\n","      <th>video_correct_by_avg</th>\n","      <th>video_pred_by_majority</th>\n","      <th>video_correct_by_majority</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>000_003</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.605013</td>\n","      <td>0.002602</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>010_005</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.500555</td>\n","      <td>0.030406</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>011_805</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>17</td>\n","      <td>0.15</td>\n","      <td>0.570437</td>\n","      <td>0.031841</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>012_026</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.491209</td>\n","      <td>0.041621</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>013_883</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.607141</td>\n","      <td>0.005542</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>014_790</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>13</td>\n","      <td>7</td>\n","      <td>0.65</td>\n","      <td>0.594129</td>\n","      <td>0.016836</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>015_919</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.606428</td>\n","      <td>0.003373</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>016_209</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.515260</td>\n","      <td>0.025184</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>017_803</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>0.20</td>\n","      <td>0.510247</td>\n","      <td>0.054078</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>018_019</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>2</td>\n","      <td>18</td>\n","      <td>0.10</td>\n","      <td>0.549537</td>\n","      <td>0.039455</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>019_018</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.605912</td>\n","      <td>0.002826</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>020_344</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>12</td>\n","      <td>0.40</td>\n","      <td>0.586296</td>\n","      <td>0.015548</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>021_312</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.609469</td>\n","      <td>0.000775</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>022_489</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.597894</td>\n","      <td>0.001960</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>023_923</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.438824</td>\n","      <td>0.033234</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>024_073</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.425719</td>\n","      <td>0.032743</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>025_067</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>0.75</td>\n","      <td>0.598002</td>\n","      <td>0.006743</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>026_012</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.80</td>\n","      <td>0.600672</td>\n","      <td>0.014544</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>027_009</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.519891</td>\n","      <td>0.029209</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>028_068</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.481397</td>\n","      <td>0.042163</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>029_048</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.420327</td>\n","      <td>0.021655</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>030_193</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.605804</td>\n","      <td>0.002763</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>031_163</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.606558</td>\n","      <td>0.003448</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>032_944</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.497355</td>\n","      <td>0.012459</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>033_097</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.80</td>\n","      <td>0.583143</td>\n","      <td>0.052994</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>034_590</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.604454</td>\n","      <td>0.005882</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>035_036</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>3</td>\n","      <td>0.85</td>\n","      <td>0.599140</td>\n","      <td>0.007971</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>036_035</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.443994</td>\n","      <td>0.029702</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>037_072</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.486414</td>\n","      <td>0.029251</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>038_125</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.503542</td>\n","      <td>0.039580</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>039_058</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>12</td>\n","      <td>0.40</td>\n","      <td>0.592239</td>\n","      <td>0.012831</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>040_997</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.608665</td>\n","      <td>0.000552</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>041_063</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>9</td>\n","      <td>11</td>\n","      <td>0.45</td>\n","      <td>0.584924</td>\n","      <td>0.019410</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>042_084</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>0.05</td>\n","      <td>0.502083</td>\n","      <td>0.056336</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>043_110</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.608970</td>\n","      <td>0.000927</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>044_945</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>19</td>\n","      <td>0.05</td>\n","      <td>0.478208</td>\n","      <td>0.045544</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>045_889</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>0.55</td>\n","      <td>0.592704</td>\n","      <td>0.011058</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>046_904</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.489231</td>\n","      <td>0.019240</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>047_862</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>15</td>\n","      <td>5</td>\n","      <td>0.75</td>\n","      <td>0.596472</td>\n","      <td>0.010766</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>048_029</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.513313</td>\n","      <td>0.026715</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>049_946</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>0.20</td>\n","      <td>0.575603</td>\n","      <td>0.021378</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>050_059</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.480856</td>\n","      <td>0.027570</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>051_332</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>0.80</td>\n","      <td>0.592942</td>\n","      <td>0.017276</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>052_108</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>0.90</td>\n","      <td>0.600997</td>\n","      <td>0.005403</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>053_095</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.502825</td>\n","      <td>0.022627</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>054_071</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.607449</td>\n","      <td>0.000397</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>055_147</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.603974</td>\n","      <td>0.006120</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>056_996</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.606480</td>\n","      <td>0.002156</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>057_070</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>6</td>\n","      <td>14</td>\n","      <td>0.30</td>\n","      <td>0.571658</td>\n","      <td>0.028070</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>058_039</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.607670</td>\n","      <td>0.005487</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>059_050</td>\n","      <td>fake</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>0.00</td>\n","      <td>0.509727</td>\n","      <td>0.035841</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>04__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.562468</td>\n","      <td>0.014136</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__exit_phone_room</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.580709</td>\n","      <td>0.010539</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__hugging_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.486344</td>\n","      <td>0.015996</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__kitchen_pan</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>0.25</td>\n","      <td>0.580043</td>\n","      <td>0.053692</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__kitchen_still</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>8</td>\n","      <td>12</td>\n","      <td>0.40</td>\n","      <td>0.594336</td>\n","      <td>0.009170</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.574561</td>\n","      <td>0.011707</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.574557</td>\n","      <td>0.003099</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.568871</td>\n","      <td>0.011566</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__talking_against_wall</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.546996</td>\n","      <td>0.004001</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.588390</td>\n","      <td>0.003108</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.510302</td>\n","      <td>0.022801</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.530916</td>\n","      <td>0.014783</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__exit_phone_room</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.587951</td>\n","      <td>0.007030</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__hugging_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.470809</td>\n","      <td>0.012944</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__kitchen_pan</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>0.90</td>\n","      <td>0.547419</td>\n","      <td>0.042714</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__kitchen_still</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.543733</td>\n","      <td>0.018871</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.495384</td>\n","      <td>0.036088</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.516060</td>\n","      <td>0.022880</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.572009</td>\n","      <td>0.012877</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__talking_against_wall</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.552244</td>\n","      <td>0.012355</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__talking_angry_couch</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>0.90</td>\n","      <td>0.579901</td>\n","      <td>0.015638</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.587768</td>\n","      <td>0.007728</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_and_outside_surprised</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.542592</td>\n","      <td>0.027051</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_down_indoor_hall_disgust</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.522911</td>\n","      <td>0.029614</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.512704</td>\n","      <td>0.029732</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.483654</td>\n","      <td>0.045258</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__exit_phone_room</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.569330</td>\n","      <td>0.017922</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__hugging_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.489804</td>\n","      <td>0.018129</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__kitchen_pan</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>0.25</td>\n","      <td>0.583590</td>\n","      <td>0.041862</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__kitchen_still</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>11</td>\n","      <td>9</td>\n","      <td>0.55</td>\n","      <td>0.592218</td>\n","      <td>0.010159</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.555866</td>\n","      <td>0.023705</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.565580</td>\n","      <td>0.010305</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.584048</td>\n","      <td>0.013211</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__secret_conversation</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.531330</td>\n","      <td>0.025215</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__talking_against_wall</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>0.90</td>\n","      <td>0.586821</td>\n","      <td>0.012685</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__talking_angry_couch</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>5</td>\n","      <td>15</td>\n","      <td>0.25</td>\n","      <td>0.597824</td>\n","      <td>0.006461</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.587614</td>\n","      <td>0.006137</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.528529</td>\n","      <td>0.027899</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.536387</td>\n","      <td>0.010603</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__exit_phone_room</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>14</td>\n","      <td>6</td>\n","      <td>0.70</td>\n","      <td>0.585257</td>\n","      <td>0.012268</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__kitchen_pan</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>7</td>\n","      <td>13</td>\n","      <td>0.35</td>\n","      <td>0.570341</td>\n","      <td>0.062514</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__kitchen_still</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>10</td>\n","      <td>10</td>\n","      <td>0.50</td>\n","      <td>0.589392</td>\n","      <td>0.019594</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.573961</td>\n","      <td>0.015534</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.577623</td>\n","      <td>0.008736</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.539182</td>\n","      <td>0.024233</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__talking_against_wall</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.470117</td>\n","      <td>0.018052</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>19</td>\n","      <td>1</td>\n","      <td>0.95</td>\n","      <td>0.583057</td>\n","      <td>0.009109</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.507433</td>\n","      <td>0.022968</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.550768</td>\n","      <td>0.010884</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>09__exit_phone_room</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>20</td>\n","      <td>0</td>\n","      <td>1.00</td>\n","      <td>0.576848</td>\n","      <td>0.013440</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>09__kitchen_pan</td>\n","      <td>real</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>17</td>\n","      <td>0.15</td>\n","      <td>0.585147</td>\n","      <td>0.047001</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-859f0b67-0826-44bd-a0b1-f609d587a18f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-859f0b67-0826-44bd-a0b1-f609d587a18f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-859f0b67-0826-44bd-a0b1-f609d587a18f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-9de9ea42-a778-4fae-8e21-e935d5544a67\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9de9ea42-a778-4fae-8e21-e935d5544a67')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-9de9ea42-a778-4fae-8e21-e935d5544a67 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_d0c9000c-5d71-4944-bbb5-dda1c33abff8\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('table_capsule_ffpp')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d0c9000c-5d71-4944-bbb5-dda1c33abff8 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('table_capsule_ffpp');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"table_capsule_ffpp","summary":"{\n  \"name\": \"table_capsule_ffpp\",\n  \"rows\": 102,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_frames_FF++\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"detector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Capsule\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 102,\n        \"samples\": [\n          \"039_058\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"real\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 20,\n        \"max\": 20,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_correct_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n_wrong_frames\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frame_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.40716053709844846,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_prob_fake\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04831798269853806,\n        \"min\": 0.4203271999955177,\n        \"max\": 0.6094687938690185,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          0.5922393560409546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std_prob_fake\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014561363054758645,\n        \"min\": 0.00039741169626300186,\n        \"max\": 0.06251362382420404,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          0.01283096537839981\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_pred_by_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_correct_by_avg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_pred_by_majority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_correct_by_majority\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[rows]=102 | thresholds: t_frame=0.595, t_avg=0.592\n"]}]},{"cell_type":"code","source":["# Save the Capsule large table CSV to Drive/Capsule results FF++\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","import os\n","\n","# Pick the correct Drive root\n","ROOT = \"/content/drive/MyDrive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","OUT_DIR = os.path.join(ROOT, \"Capsule results FF++\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","DEST = os.path.join(OUT_DIR, \"capsule_ffpp_large_table.csv\")\n","\n","# Require the table from the previous cell\n","if 'table_capsule_ffpp' not in globals() or table_capsule_ffpp.empty:\n","    raise SystemExit(\"No 'table_capsule_ffpp' found. Run the large-table cell first.\")\n","\n","table_capsule_ffpp.to_csv(DEST, index=False)\n","print(f\"[saved] {DEST}  (rows={len(table_capsule_ffpp)})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CyOxPjBwd8Oy","executionInfo":{"status":"ok","timestamp":1756582369418,"user_tz":-120,"elapsed":2097,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"d3b3e675-fe87-4c16-9cac-5473a3076c3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[saved] /content/drive/MyDrive/Capsule results FF++/capsule_ffpp_large_table.csv  (rows=102)\n"]}]},{"cell_type":"code","source":["# === Capsule — Small results table (balanced_frames_FF++) ===\n","# Columns: dataset, detector, video_name, true_label, correctly_predicted (yes/no)\n","# Uses the same avg-score Youden J thresholding as the large table.\n","\n","import numpy as np, pandas as pd\n","from sklearn.metrics import roc_curve\n","\n","# Safety\n","if 'df_scores' not in globals() or df_scores.empty:\n","    raise SystemExit(\"No 'df_scores' found. Run the Capsule scoring cell first.\")\n","\n","DATASET_NAME  = \"balanced_frames_FF++\"\n","DETECTOR_NAME = \"Capsule\"\n","\n","# Clean frame-level results\n","df = df_scores.copy()\n","df[\"video_name\"] = df[\"video_name\"].astype(str)\n","df[\"true_label\"] = df[\"true_label\"].astype(str)\n","df[\"prob_fake\"]  = pd.to_numeric(df[\"prob_fake\"], errors=\"coerce\").astype(float)\n","df = df.dropna(subset=[\"prob_fake\"]).reset_index(drop=True)\n","\n","# Per-video average prob\n","avg_df = df.groupby([\"video_name\",\"true_label\"], sort=False)[\"prob_fake\"].mean().rename(\"avg_prob_fake\").reset_index()\n","\n","# Global threshold on video-level averages (Youden J)\n","y_avg = (avg_df[\"true_label\"]==\"fake\").astype(int).to_numpy()\n","s_avg = avg_df[\"avg_prob_fake\"].to_numpy(dtype=float)\n","if len(np.unique(y_avg)) >= 2:\n","    fpr, tpr, thr = roc_curve(y_avg, s_avg)\n","    t_avg = float(thr[np.nanargmax(tpr - fpr)])\n","else:\n","    t_avg = 0.5\n","\n","# Video prediction by average\n","avg_df[\"video_pred_by_avg\"] = (avg_df[\"avg_prob_fake\"] >= t_avg).map({True:\"fake\", False:\"real\"})\n","avg_df[\"correctly_predicted (yes or no)\"] = np.where(\n","    avg_df[\"video_pred_by_avg\"] == avg_df[\"true_label\"], \"yes\", \"no\"\n",")\n","\n","small_table_capsule_ffpp = (\n","    avg_df[[\"video_name\",\"true_label\",\"correctly_predicted (yes or no)\"]]\n","    .assign(dataset=DATASET_NAME, detector=DETECTOR_NAME)\n","    [[\"dataset\",\"detector\",\"video_name\",\"true_label\",\"correctly_predicted (yes or no)\"]]\n","    .sort_values([\"true_label\",\"video_name\"], kind=\"stable\")\n","    .reset_index(drop=True)\n",")\n","\n","# Show all rows, no column breaks\n","pd.set_option(\"display.max_rows\", 100000)\n","pd.set_option(\"display.max_columns\", 1000)\n","pd.set_option(\"display.width\", 10000)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","\n","display(small_table_capsule_ffpp)\n","print(f\"[rows]={len(small_table_capsule_ffpp)} | t_avg={t_avg:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"y2cnXx9seQg9","executionInfo":{"status":"ok","timestamp":1756582450618,"user_tz":-120,"elapsed":49,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"39476ba9-007a-43d6-b4cf-ab5ba154feb8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["                  dataset detector                             video_name true_label correctly_predicted (yes or no)\n","0    balanced_frames_FF++  Capsule                                000_003       fake                             yes\n","1    balanced_frames_FF++  Capsule                                010_005       fake                              no\n","2    balanced_frames_FF++  Capsule                                011_805       fake                              no\n","3    balanced_frames_FF++  Capsule                                012_026       fake                              no\n","4    balanced_frames_FF++  Capsule                                013_883       fake                             yes\n","5    balanced_frames_FF++  Capsule                                014_790       fake                             yes\n","6    balanced_frames_FF++  Capsule                                015_919       fake                             yes\n","7    balanced_frames_FF++  Capsule                                016_209       fake                              no\n","8    balanced_frames_FF++  Capsule                                017_803       fake                              no\n","9    balanced_frames_FF++  Capsule                                018_019       fake                              no\n","10   balanced_frames_FF++  Capsule                                019_018       fake                             yes\n","11   balanced_frames_FF++  Capsule                                020_344       fake                              no\n","12   balanced_frames_FF++  Capsule                                021_312       fake                             yes\n","13   balanced_frames_FF++  Capsule                                022_489       fake                             yes\n","14   balanced_frames_FF++  Capsule                                023_923       fake                              no\n","15   balanced_frames_FF++  Capsule                                024_073       fake                              no\n","16   balanced_frames_FF++  Capsule                                025_067       fake                             yes\n","17   balanced_frames_FF++  Capsule                                026_012       fake                             yes\n","18   balanced_frames_FF++  Capsule                                027_009       fake                              no\n","19   balanced_frames_FF++  Capsule                                028_068       fake                              no\n","20   balanced_frames_FF++  Capsule                                029_048       fake                              no\n","21   balanced_frames_FF++  Capsule                                030_193       fake                             yes\n","22   balanced_frames_FF++  Capsule                                031_163       fake                             yes\n","23   balanced_frames_FF++  Capsule                                032_944       fake                              no\n","24   balanced_frames_FF++  Capsule                                033_097       fake                              no\n","25   balanced_frames_FF++  Capsule                                034_590       fake                             yes\n","26   balanced_frames_FF++  Capsule                                035_036       fake                             yes\n","27   balanced_frames_FF++  Capsule                                036_035       fake                              no\n","28   balanced_frames_FF++  Capsule                                037_072       fake                              no\n","29   balanced_frames_FF++  Capsule                                038_125       fake                              no\n","30   balanced_frames_FF++  Capsule                                039_058       fake                             yes\n","31   balanced_frames_FF++  Capsule                                040_997       fake                             yes\n","32   balanced_frames_FF++  Capsule                                041_063       fake                              no\n","33   balanced_frames_FF++  Capsule                                042_084       fake                              no\n","34   balanced_frames_FF++  Capsule                                043_110       fake                             yes\n","35   balanced_frames_FF++  Capsule                                044_945       fake                              no\n","36   balanced_frames_FF++  Capsule                                045_889       fake                             yes\n","37   balanced_frames_FF++  Capsule                                046_904       fake                              no\n","38   balanced_frames_FF++  Capsule                                047_862       fake                             yes\n","39   balanced_frames_FF++  Capsule                                048_029       fake                              no\n","40   balanced_frames_FF++  Capsule                                049_946       fake                              no\n","41   balanced_frames_FF++  Capsule                                050_059       fake                              no\n","42   balanced_frames_FF++  Capsule                                051_332       fake                             yes\n","43   balanced_frames_FF++  Capsule                                052_108       fake                             yes\n","44   balanced_frames_FF++  Capsule                                053_095       fake                              no\n","45   balanced_frames_FF++  Capsule                                054_071       fake                             yes\n","46   balanced_frames_FF++  Capsule                                055_147       fake                             yes\n","47   balanced_frames_FF++  Capsule                                056_996       fake                             yes\n","48   balanced_frames_FF++  Capsule                                057_070       fake                              no\n","49   balanced_frames_FF++  Capsule                                058_039       fake                             yes\n","50   balanced_frames_FF++  Capsule                                059_050       fake                              no\n","51   balanced_frames_FF++  Capsule     04__walking_outside_cafe_disgusted       real                             yes\n","52   balanced_frames_FF++  Capsule                    05__exit_phone_room       real                             yes\n","53   balanced_frames_FF++  Capsule                      05__hugging_happy       real                             yes\n","54   balanced_frames_FF++  Capsule                        05__kitchen_pan       real                             yes\n","55   balanced_frames_FF++  Capsule                      05__kitchen_still       real                              no\n","56   balanced_frames_FF++  Capsule       05__outside_talking_pan_laughing       real                             yes\n","57   balanced_frames_FF++  Capsule     05__outside_talking_still_laughing       real                             yes\n","58   balanced_frames_FF++  Capsule                05__podium_speech_happy       real                             yes\n","59   balanced_frames_FF++  Capsule               05__talking_against_wall       real                             yes\n","60   balanced_frames_FF++  Capsule               05__walk_down_hall_angry       real                             yes\n","61   balanced_frames_FF++  Capsule  05__walking_down_street_outside_angry       real                             yes\n","62   balanced_frames_FF++  Capsule     05__walking_outside_cafe_disgusted       real                             yes\n","63   balanced_frames_FF++  Capsule                    06__exit_phone_room       real                             yes\n","64   balanced_frames_FF++  Capsule                      06__hugging_happy       real                             yes\n","65   balanced_frames_FF++  Capsule                        06__kitchen_pan       real                             yes\n","66   balanced_frames_FF++  Capsule                      06__kitchen_still       real                             yes\n","67   balanced_frames_FF++  Capsule       06__outside_talking_pan_laughing       real                             yes\n","68   balanced_frames_FF++  Capsule     06__outside_talking_still_laughing       real                             yes\n","69   balanced_frames_FF++  Capsule                06__podium_speech_happy       real                             yes\n","70   balanced_frames_FF++  Capsule               06__talking_against_wall       real                             yes\n","71   balanced_frames_FF++  Capsule                06__talking_angry_couch       real                             yes\n","72   balanced_frames_FF++  Capsule               06__walk_down_hall_angry       real                             yes\n","73   balanced_frames_FF++  Capsule      06__walking_and_outside_surprised       real                             yes\n","74   balanced_frames_FF++  Capsule   06__walking_down_indoor_hall_disgust       real                             yes\n","75   balanced_frames_FF++  Capsule  06__walking_down_street_outside_angry       real                             yes\n","76   balanced_frames_FF++  Capsule     06__walking_outside_cafe_disgusted       real                             yes\n","77   balanced_frames_FF++  Capsule                    07__exit_phone_room       real                             yes\n","78   balanced_frames_FF++  Capsule                      07__hugging_happy       real                             yes\n","79   balanced_frames_FF++  Capsule                        07__kitchen_pan       real                             yes\n","80   balanced_frames_FF++  Capsule                      07__kitchen_still       real                             yes\n","81   balanced_frames_FF++  Capsule       07__outside_talking_pan_laughing       real                             yes\n","82   balanced_frames_FF++  Capsule     07__outside_talking_still_laughing       real                             yes\n","83   balanced_frames_FF++  Capsule                07__podium_speech_happy       real                             yes\n","84   balanced_frames_FF++  Capsule                07__secret_conversation       real                             yes\n","85   balanced_frames_FF++  Capsule               07__talking_against_wall       real                             yes\n","86   balanced_frames_FF++  Capsule                07__talking_angry_couch       real                              no\n","87   balanced_frames_FF++  Capsule               07__walk_down_hall_angry       real                             yes\n","88   balanced_frames_FF++  Capsule  07__walking_down_street_outside_angry       real                             yes\n","89   balanced_frames_FF++  Capsule     07__walking_outside_cafe_disgusted       real                             yes\n","90   balanced_frames_FF++  Capsule                    08__exit_phone_room       real                             yes\n","91   balanced_frames_FF++  Capsule                        08__kitchen_pan       real                             yes\n","92   balanced_frames_FF++  Capsule                      08__kitchen_still       real                             yes\n","93   balanced_frames_FF++  Capsule       08__outside_talking_pan_laughing       real                             yes\n","94   balanced_frames_FF++  Capsule     08__outside_talking_still_laughing       real                             yes\n","95   balanced_frames_FF++  Capsule                08__podium_speech_happy       real                             yes\n","96   balanced_frames_FF++  Capsule               08__talking_against_wall       real                             yes\n","97   balanced_frames_FF++  Capsule               08__walk_down_hall_angry       real                             yes\n","98   balanced_frames_FF++  Capsule  08__walking_down_street_outside_angry       real                             yes\n","99   balanced_frames_FF++  Capsule     08__walking_outside_cafe_disgusted       real                             yes\n","100  balanced_frames_FF++  Capsule                    09__exit_phone_room       real                             yes\n","101  balanced_frames_FF++  Capsule                        09__kitchen_pan       real                             yes"],"text/html":["\n","  <div id=\"df-4c6a859d-1398-44fd-9c11-4258b0668efa\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dataset</th>\n","      <th>detector</th>\n","      <th>video_name</th>\n","      <th>true_label</th>\n","      <th>correctly_predicted (yes or no)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>000_003</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>010_005</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>011_805</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>012_026</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>013_883</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>014_790</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>015_919</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>016_209</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>017_803</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>018_019</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>019_018</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>020_344</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>021_312</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>022_489</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>023_923</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>024_073</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>025_067</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>026_012</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>027_009</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>028_068</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>029_048</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>030_193</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>031_163</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>032_944</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>033_097</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>034_590</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>035_036</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>036_035</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>037_072</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>038_125</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>039_058</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>040_997</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>041_063</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>042_084</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>043_110</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>044_945</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>045_889</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>046_904</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>047_862</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>048_029</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>049_946</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>050_059</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>051_332</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>052_108</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>053_095</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>054_071</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>055_147</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>056_996</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>057_070</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>058_039</td>\n","      <td>fake</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>059_050</td>\n","      <td>fake</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>04__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__exit_phone_room</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__hugging_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__kitchen_pan</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__kitchen_still</td>\n","      <td>real</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__talking_against_wall</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>05__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__exit_phone_room</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__hugging_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__kitchen_pan</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__kitchen_still</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__talking_against_wall</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__talking_angry_couch</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_and_outside_surprised</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_down_indoor_hall_disgust</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>06__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__exit_phone_room</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__hugging_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__kitchen_pan</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__kitchen_still</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__secret_conversation</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__talking_against_wall</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__talking_angry_couch</td>\n","      <td>real</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>07__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__exit_phone_room</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__kitchen_pan</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__kitchen_still</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__outside_talking_pan_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__outside_talking_still_laughing</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__podium_speech_happy</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__talking_against_wall</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__walk_down_hall_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__walking_down_street_outside_angry</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>08__walking_outside_cafe_disgusted</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>09__exit_phone_room</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>balanced_frames_FF++</td>\n","      <td>Capsule</td>\n","      <td>09__kitchen_pan</td>\n","      <td>real</td>\n","      <td>yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c6a859d-1398-44fd-9c11-4258b0668efa')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-4c6a859d-1398-44fd-9c11-4258b0668efa button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-4c6a859d-1398-44fd-9c11-4258b0668efa');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-60f94e5e-85cb-42ef-a1db-ba874c3a9d9d\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60f94e5e-85cb-42ef-a1db-ba874c3a9d9d')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-60f94e5e-85cb-42ef-a1db-ba874c3a9d9d button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_33bb8e0d-5b0f-433e-9bea-4dedd7d72f19\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('small_table_capsule_ffpp')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_33bb8e0d-5b0f-433e-9bea-4dedd7d72f19 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('small_table_capsule_ffpp');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"small_table_capsule_ffpp","summary":"{\n  \"name\": \"small_table_capsule_ffpp\",\n  \"rows\": 102,\n  \"fields\": [\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"balanced_frames_FF++\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"detector\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Capsule\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 102,\n        \"samples\": [\n          \"039_058\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"real\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correctly_predicted (yes or no)\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[rows]=102 | t_avg=0.592\n"]}]},{"cell_type":"code","source":["# Save the Capsule small table CSV to Drive/Capsule results FF++\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","import os\n","\n","# Drive root & folder\n","ROOT = \"/content/drive/MyDrive\" if os.path.isdir(\"/content/drive/MyDrive\") else \"/content/drive/My Drive\"\n","OUT_DIR = os.path.join(ROOT, \"Capsule results FF++\")\n","os.makedirs(OUT_DIR, exist_ok=True)\n","DEST = os.path.join(OUT_DIR, \"capsule_ffpp_small_table.csv\")\n","\n","# Require the small table from the previous cell\n","if 'small_table_capsule_ffpp' not in globals() or small_table_capsule_ffpp.empty:\n","    raise SystemExit(\"No 'small_table_capsule_ffpp' found. Run the small-table cell first.\")\n","\n","small_table_capsule_ffpp.to_csv(DEST, index=False)\n","print(f\"[saved] {DEST}  (rows={len(small_table_capsule_ffpp)})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"48r-QVU0edma","executionInfo":{"status":"ok","timestamp":1756582506641,"user_tz":-120,"elapsed":2520,"user":{"displayName":"Vishnumaya","userId":"01919615312035119785"}},"outputId":"e64df8eb-c512-4994-cfb6-329135471ea2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[saved] /content/drive/MyDrive/Capsule results FF++/capsule_ffpp_small_table.csv  (rows=102)\n"]}]}]}